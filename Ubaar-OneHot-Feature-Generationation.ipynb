{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>SourceState_آذربایجان شرقی</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleType_treili</th>\n",
       "      <th>vehicleOption_bari</th>\n",
       "      <th>vehicleOption_hichkodam</th>\n",
       "      <th>vehicleOption_kafi</th>\n",
       "      <th>vehicleOption_kompressi</th>\n",
       "      <th>vehicleOption_labehdar</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>36.473089</td>\n",
       "      <td>52.349822</td>\n",
       "      <td>184.0</td>\n",
       "      <td>35.700109</td>\n",
       "      <td>51.399743</td>\n",
       "      <td>199.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1834.976428</td>\n",
       "      <td>1909.359717</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>35.704176</td>\n",
       "      <td>51.400280</td>\n",
       "      <td>331.0</td>\n",
       "      <td>37.275731</td>\n",
       "      <td>49.584392</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1848.294458</td>\n",
       "      <td>1835.204644</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45277</th>\n",
       "      <td>35.699924</td>\n",
       "      <td>51.396715</td>\n",
       "      <td>447.0</td>\n",
       "      <td>32.665899</td>\n",
       "      <td>51.663805</td>\n",
       "      <td>285.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1687.644636</td>\n",
       "      <td>1834.858819</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>30.199563</td>\n",
       "      <td>53.182966</td>\n",
       "      <td>809.0</td>\n",
       "      <td>35.699078</td>\n",
       "      <td>51.401589</td>\n",
       "      <td>525.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1834.989335</td>\n",
       "      <td>1606.102332</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>27.180941</td>\n",
       "      <td>56.277756</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>34.643252</td>\n",
       "      <td>50.877469</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1762.560980</td>\n",
       "      <td>1529.682365</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destinationLatitude  destinationLongitude  distanceKM  sourceLatitude  \\\n",
       "39085            36.473089             52.349822       184.0       35.700109   \n",
       "30892            35.704176             51.400280       331.0       37.275731   \n",
       "45277            35.699924             51.396715       447.0       32.665899   \n",
       "16398            30.199563             53.182966       809.0       35.699078   \n",
       "13653            27.180941             56.277756      1144.0       34.643252   \n",
       "\n",
       "       sourceLongitude  taxiDurationMin  weight       source  destination  \\\n",
       "39085        51.399743            199.0   21.00  1834.976428  1909.359717   \n",
       "30892        49.584392            254.0    1.67  1848.294458  1835.204644   \n",
       "45277        51.663805            285.0   19.00  1687.644636  1834.858819   \n",
       "16398        51.401589            525.0    4.00  1834.989335  1606.102332   \n",
       "13653        50.877469            750.0    2.00  1762.560980  1529.682365   \n",
       "\n",
       "       SourceState_آذربایجان شرقی           ...             \\\n",
       "39085                           0           ...              \n",
       "30892                           0           ...              \n",
       "45277                           0           ...              \n",
       "16398                           0           ...              \n",
       "13653                           0           ...              \n",
       "\n",
       "       vehicleType_treili  vehicleOption_bari  vehicleOption_hichkodam  \\\n",
       "39085                   1                   0                        0   \n",
       "30892                   0                   0                        0   \n",
       "45277                   1                   0                        0   \n",
       "16398                   0                   0                        0   \n",
       "13653                   0                   0                        0   \n",
       "\n",
       "       vehicleOption_kafi  vehicleOption_kompressi  vehicleOption_labehdar  \\\n",
       "39085                   1                        0                       0   \n",
       "30892                   0                        0                       0   \n",
       "45277                   0                        0                       0   \n",
       "16398                   0                        0                       0   \n",
       "13653                   0                        0                       0   \n",
       "\n",
       "       vehicleOption_mosaghaf_chadori  vehicleOption_mosaghaf_felezi  \\\n",
       "39085                               0                              0   \n",
       "30892                               1                              0   \n",
       "45277                               0                              0   \n",
       "16398                               1                              0   \n",
       "13653                               1                              0   \n",
       "\n",
       "       vehicleOption_transit_chadori  vehicleOption_yakhchali  \n",
       "39085                              0                        0  \n",
       "30892                              0                        0  \n",
       "45277                              1                        0  \n",
       "16398                              0                        0  \n",
       "13653                              0                        0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "min_price = min(all_data['price'])\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "train_1, train_2 = train_test_split(train, test_size=0.5)\n",
    "\n",
    "X = train.drop(['ID','price'],axis=1)\n",
    "y = train.price\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "GBoost_1 = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                     max_depth=10, max_features='sqrt',\n",
    "                                     min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "GBoost_2 = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                     max_depth=10, max_features='sqrt',\n",
    "                                     min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "GBoost_1.fit(train_1.drop(['ID','price'],axis=1), train_1.price)\n",
    "GBoost_2.fit(train_2.drop(['ID','price'],axis=1), train_2.price)\n",
    "\n",
    "train_1['y_gboost'] = GBoost_2.predict(train_1.drop(['ID','price'],axis=1))\n",
    "train_2['y_gboost'] = GBoost_1.predict(train_2.drop(['ID','price'],axis=1))\n",
    "\n",
    "train_gboost = pd.concat([train_1, train_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins')\n",
    "train_gboost.head()\n",
    "\n",
    "# 5.85 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gboost_1, train_gboost_2 = train_test_split(train_gboost, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "xgb_1 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                         learning_rate=0.05, max_depth=10, \n",
    "                         min_child_weight=1.7817, n_estimators=2200,\n",
    "                         reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "xgb_2 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                         learning_rate=0.05, max_depth=10, \n",
    "                         min_child_weight=1.7817, n_estimators=2200,\n",
    "                         reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "xgb_1.fit(train_gboost_1.drop(['ID','price','y_gboost'],axis=1), train_gboost_1.price)\n",
    "xgb_2.fit(train_gboost_2.drop(['ID','price','y_gboost'],axis=1), train_gboost_2.price)\n",
    "\n",
    "train_gboost_1['y_xgb'] = xgb_2.predict(train_gboost_1.drop(['ID','price','y_gboost'],axis=1))\n",
    "train_gboost_2['y_xgb'] = xgb_1.predict(train_gboost_2.drop(['ID','price','y_gboost'],axis=1))\n",
    "\n",
    "train_xgb = pd.concat([train_gboost_1, train_gboost_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins')\n",
    "train_xgb.head()\n",
    "\n",
    "# 8.20 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_1, train_xgb_2 = train_test_split(train_xgb, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "bag_1 = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "bag_2 = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "\n",
    "bag_1.fit(train_xgb_1.drop(['ID','price','y_gboost','y_xgb'],axis=1), train_xgb_1.price)\n",
    "bag_2.fit(train_xgb_2.drop(['ID','price','y_gboost','y_xgb'],axis=1), train_xgb_2.price)\n",
    "\n",
    "train_xgb_1['y_bag'] = bag_2.predict(train_xgb_1.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "train_xgb_2['y_bag'] = bag_1.predict(train_xgb_2.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "\n",
    "train_bag = pd.concat([train_xgb_1, train_xgb_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins' )\n",
    "train_bag.head()\n",
    "\n",
    "# 10.23 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag.to_pickle('dataFrames/train_OneHotEncoding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_bag_1, train_bag_2 = train_test_split(train_bag, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_1 = KNeighborsClassifier(2)\n",
    "knn_2 = KNeighborsClassifier(2)\n",
    "\n",
    "knn_1.fit(train_bag_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1), train_bag_1.price)\n",
    "knn_2.fit(train_bag_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1), train_bag_2.price)\n",
    "\n",
    "train_bag_1['y_knn'] = knn_2.predict(train_bag_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "train_bag_2['y_knn'] = knn_1.predict(train_bag_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "\n",
    "train_knn = pd.concat([train_bag_1, train_bag_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins' )\n",
    "\n",
    "train_knn.to_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_knn.head()\n",
    "\n",
    "# 0.11 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knn = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_knn_1, train_knn_2 = train_test_split(train_knn, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dec_1 = DecisionTreeRegressor(max_depth=10)\n",
    "dec_2 = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "dec_1.fit(train_knn_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1), train_knn_1.price)\n",
    "dec_2.fit(train_knn_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1), train_knn_2.price)\n",
    "\n",
    "train_knn_1['y_dec'] = dec_2.predict(train_knn_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "train_knn_2['y_dec'] = dec_1.predict(train_knn_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "\n",
    "train_dec = pd.concat([train_knn_1, train_knn_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins' )\n",
    "\n",
    "train_dec.to_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_dec.head()\n",
    "\n",
    "# 0.01 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dec = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_dec_1, train_dec_2 = train_test_split(train_dec, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lgb_1 = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                          learning_rate=0.05, n_estimators=15000,\n",
    "                          max_bin = 1000, bagging_fraction = 0.6,\n",
    "                          bagging_freq = 5, feature_fraction = 0.25,\n",
    "                          feature_fraction_seed=9, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "lgb_2 = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                          learning_rate=0.05, n_estimators=15000,\n",
    "                          max_bin = 1000, bagging_fraction = 0.6,\n",
    "                          bagging_freq = 5, feature_fraction = 0.25,\n",
    "                          feature_fraction_seed=9, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "lgb_1.fit(train_dec_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn', 'y_dec'],axis=1), train_dec_1.price)\n",
    "lgb_2.fit(train_dec_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn', 'y_dec'],axis=1), train_dec_2.price)\n",
    "\n",
    "train_dec_1['y_lgb'] = lgb_2.predict(train_dec_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn', 'y_dec'],axis=1))\n",
    "train_dec_2['y_lgb'] = lgb_1.predict(train_dec_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn', 'y_dec'],axis=1))\n",
    "\n",
    "train_lgb = pd.concat([train_dec_1, train_dec_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) + ' mins' )\n",
    "\n",
    "train_lgb.to_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "train_lgb.head()\n",
    "\n",
    "# 2.26 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "GBoost = GradientBoostingRegressor(n_estimators=2200, learning_rate=0.05,\n",
    "                                   max_depth=10, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=10, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "bag   = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "knn   = KNeighborsClassifier(2)\n",
    "dec   = DecisionTreeRegressor(max_depth=10)\n",
    "lgb_m = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                       learning_rate=0.05, n_estimators=15000,\n",
    "                       max_bin = 1000, bagging_fraction = 0.6,\n",
    "                       bagging_freq = 5, feature_fraction = 0.25,\n",
    "                       feature_fraction_seed=9, bagging_seed=20,\n",
    "                       min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "GBoost.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "xgb_model.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "bag.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "knn.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "dec.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "lgb_m.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "\n",
    "\n",
    "\n",
    "test['y_gboost'] = GBoost.predict(test.drop(['ID','price'],axis=1))\n",
    "test['y_xgb']    = xgb_model.predict(test.drop(['ID','price','y_gboost'],axis=1))\n",
    "test['y_bag']    = bag.predict(test.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "test['y_knn']    = knn.predict(test.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "test['y_dec']    = dec.predict(test.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "test['y_lgb']    = lgb_m.predict(test.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn', 'y_dec'],axis=1))\n",
    "\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ), \"mins\" )\n",
    "\n",
    "\n",
    "test.to_pickle('dataFrames/test_OneHotEncoding.pkl')\n",
    "test.head()\n",
    "\n",
    "# 25.04 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = pd.read_pickle('dataFrames/test_OneHotEncoding.pkl')\n",
    "train = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "      <th>y_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010571124</td>\n",
       "      <td>35.579635</td>\n",
       "      <td>53.384990</td>\n",
       "      <td>684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.297213</td>\n",
       "      <td>59.607970</td>\n",
       "      <td>446.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2163.603184</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.516722e+06</td>\n",
       "      <td>2.403949e+06</td>\n",
       "      <td>2603010.0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>3.997050e+06</td>\n",
       "      <td>2.469241e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031704713</td>\n",
       "      <td>29.605761</td>\n",
       "      <td>52.533588</td>\n",
       "      <td>931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.704695</td>\n",
       "      <td>51.405194</td>\n",
       "      <td>614.0</td>\n",
       "      <td>19.14</td>\n",
       "      <td>1835.406773</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003544e+07</td>\n",
       "      <td>1.027378e+07</td>\n",
       "      <td>9555599.0</td>\n",
       "      <td>8767000.0</td>\n",
       "      <td>1.022329e+07</td>\n",
       "      <td>1.077080e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10040911649</td>\n",
       "      <td>36.299593</td>\n",
       "      <td>59.612010</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.948490</td>\n",
       "      <td>55.583875</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1497.901500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.128578e+07</td>\n",
       "      <td>1.877921e+07</td>\n",
       "      <td>17803149.0</td>\n",
       "      <td>8687000.0</td>\n",
       "      <td>1.300000e+07</td>\n",
       "      <td>2.163461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047106840</td>\n",
       "      <td>35.248298</td>\n",
       "      <td>58.457567</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.339066</td>\n",
       "      <td>52.075970</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1840.316141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.052077e+06</td>\n",
       "      <td>1.795059e+06</td>\n",
       "      <td>2396458.0</td>\n",
       "      <td>2170000.0</td>\n",
       "      <td>2.772043e+06</td>\n",
       "      <td>1.919848e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10050126039</td>\n",
       "      <td>34.636832</td>\n",
       "      <td>50.874888</td>\n",
       "      <td>281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.579577</td>\n",
       "      <td>53.394403</td>\n",
       "      <td>181.0</td>\n",
       "      <td>23.50</td>\n",
       "      <td>1899.750273</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.822093e+06</td>\n",
       "      <td>5.748156e+06</td>\n",
       "      <td>7099862.0</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>5.984402e+06</td>\n",
       "      <td>5.194802e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  destinationLatitude  destinationLongitude  distanceKM  price  \\\n",
       "0  10010571124            35.579635             53.384990       684.0    NaN   \n",
       "1  10031704713            29.605761             52.533588       931.0    NaN   \n",
       "2  10040911649            36.299593             59.612010      1469.0    NaN   \n",
       "3  10047106840            35.248298             58.457567       745.0    NaN   \n",
       "4  10050126039            34.636832             50.874888       281.0    NaN   \n",
       "\n",
       "   sourceLatitude  sourceLongitude  taxiDurationMin  weight       source  \\\n",
       "0       36.297213        59.607970            446.0    2.33  2163.603184   \n",
       "1       35.704695        51.405194            614.0   19.14  1835.406773   \n",
       "2       26.948490        55.583875           1009.0   22.00  1497.901500   \n",
       "3       35.339066        52.075970            496.0    2.50  1840.316141   \n",
       "4       35.579577        53.394403            181.0   23.50  1899.750273   \n",
       "\n",
       "       ...       vehicleOption_mosaghaf_chadori  \\\n",
       "0      ...                                    1   \n",
       "1      ...                                    0   \n",
       "2      ...                                    0   \n",
       "3      ...                                    0   \n",
       "4      ...                                    0   \n",
       "\n",
       "   vehicleOption_mosaghaf_felezi  vehicleOption_transit_chadori  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              1                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   vehicleOption_yakhchali      y_gboost         y_xgb       y_bag      y_knn  \\\n",
       "0                        0  2.516722e+06  2.403949e+06   2603010.0  2200000.0   \n",
       "1                        0  1.003544e+07  1.027378e+07   9555599.0  8767000.0   \n",
       "2                        0  2.128578e+07  1.877921e+07  17803149.0  8687000.0   \n",
       "3                        0  2.052077e+06  1.795059e+06   2396458.0  2170000.0   \n",
       "4                        0  5.822093e+06  5.748156e+06   7099862.0  1900000.0   \n",
       "\n",
       "          y_dec         y_lgb  \n",
       "0  3.997050e+06  2.469241e+06  \n",
       "1  1.022329e+07  1.077080e+07  \n",
       "2  1.300000e+07  2.163461e+07  \n",
       "3  2.772043e+06  1.919848e+06  \n",
       "4  5.984402e+06  5.194802e+06  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow combination  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 128\n",
    "TRAIN_EPOCHS        = 1200\n",
    "\n",
    "HIDDEN_LAYER_1_SIZE = 512\n",
    "HIDDEN_LAYER_2_SIZE = 512\n",
    "HIDDEN_LAYER_3_SIZE = 16\n",
    "lr                  = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gboost_feat = tf.feature_column.numeric_column(\"y_gboost\")\n",
    "y_xgb_feat    = tf.feature_column.numeric_column(\"y_xgb\")\n",
    "y_bag_feat    = tf.feature_column.numeric_column(\"y_bag\")\n",
    "y_knn_feat    = tf.feature_column.numeric_column(\"y_knn\")\n",
    "y_dec_feat    = tf.feature_column.numeric_column(\"y_dec\")\n",
    "y_lgb_feat    = tf.feature_column.numeric_column(\"y_lgb\")\n",
    "\n",
    "source_lat_feat         = tf.feature_column.numeric_column(\"sourceLatitude\") \n",
    "source_long_feat        = tf.feature_column.numeric_column(\"sourceLongitude\") \n",
    "destin_lat_feat         = tf.feature_column.numeric_column(\"destinationLatitude\") \n",
    "destin_long_feat        = tf.feature_column.numeric_column(\"destinationLongitude\") \n",
    "\n",
    "distance_feat = tf.feature_column.numeric_column(\"distanceKM\")\n",
    "taximin_feat  = tf.feature_column.numeric_column(\"taxiDurationMin\")\n",
    "weight_feat   = tf.feature_column.numeric_column(\"weight\")\n",
    "\n",
    "source_feat   = tf.feature_column.numeric_column(\"source\")\n",
    "destin_feat   = tf.feature_column.numeric_column(\"destination\")\n",
    "\n",
    "feature_columns = {y_gboost_feat, y_xgb_feat, y_bag_feat, y_knn_feat, y_dec_feat, y_lgb_feat, \n",
    "                   source_lat_feat, source_long_feat , destin_lat_feat, destin_long_feat, \n",
    "                   distance_feat, taximin_feat, weight_feat, source_feat, destin_feat}\n",
    "\n",
    "#feature_columns = {y_gboost_feat, y_xgb_feat, y_bag_feat, y_knn_feat, y_dec_feat, y_lgb_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(features, labels, mode, params, config):\n",
    "    input_layer = tf.feature_column.input_layer(features=features, \n",
    "                                                feature_columns=feature_columns)\n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    x = tf.layers.dense(inputs=input_layer,\n",
    "                        units=HIDDEN_LAYER_1_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"first_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dropout(inputs=x,name=\"first_dropout\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_2_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"second_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_3_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"third_fully_connected_layer\")\n",
    "\n",
    "    predictions = tf.contrib.layers.fully_connected(inputs=x, num_outputs=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT :\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss)\n",
    "    else:\n",
    "        #loss = tf.losses.absolute_difference(labels=labels,\n",
    "        #                                    predictions=predictions)\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, \n",
    "                                      global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss, \n",
    "                                          train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, pred = False):\n",
    "        \n",
    "    useful_fueatures = [\n",
    "        np.array(df[\"y_gboost\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_xgb\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_bag\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_knn\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_dec\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_lgb\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"distanceKM\"].values, dtype=np.float32),\n",
    "        np.array(df[\"taxiDurationMin\"].values, dtype=np.float32),\n",
    "        np.array(df[\"weight\"].values, dtype=np.float32),\n",
    "        #np.array(df[\"date_ids\"].values, dtype=np.int32),\n",
    "        #np.array(df[\"SourceState_ids\"].values, dtype=np.int32),\n",
    "        #np.array(df[\"destinationState_ids\"].values, dtype=np.int32),\n",
    "        #np.array(df[\"vehicleType_ids\"].values, dtype=np.int32),\n",
    "        #np.array(df[\"vehicleOption_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"source\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination\"].values, dtype=np.float32),\n",
    "        #np.array(df[\"destination_tuple_ids\"].values, dtype=np.int32),\n",
    "        #np.array(df[\"source_tuple_ids\"].values, dtype=np.int32)\n",
    "    ]\n",
    "\n",
    "    if pred: \n",
    "        train_number = 1\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        useful_fueatures.append(np.array(df[\"price\"].values, dtype=np.float32))\n",
    "        train_number = TRAIN_EPOCHS\n",
    "        batch_number = BATCH_SIZE\n",
    "        \n",
    "    A = tf.train.slice_input_producer(\n",
    "        tensor_list=useful_fueatures,\n",
    "        num_epochs=train_number,\n",
    "        shuffle= not pred,\n",
    "        capacity=BATCH_SIZE * 5\n",
    "    )\n",
    "    \n",
    "    y_gboost              = A[0]\n",
    "    y_xgb                 = A[1]\n",
    "    y_bag                 = A[2]\n",
    "    y_knn                 = A[3]\n",
    "    y_dec                 = A[4]\n",
    "    y_lgb                 = A[5]\n",
    "    sourceLatitude        = A[6]\n",
    "    sourceLongitude       = A[7]\n",
    "    destinationLatitude   = A[8]\n",
    "    destinationLongitude  = A[9]\n",
    "    distanceKM            = A[10]\n",
    "    taxiDurationMin       = A[11] \n",
    "    weight                = A[12]\n",
    "    #date_ids              = A[13]\n",
    "    #SourceState_ids       = A[14]\n",
    "    #destinationState_ids  = A[15]\n",
    "    #vehicleType_ids       = A[16]\n",
    "    #vehicleOption_ids     = A[17]\n",
    "    source                = A[13]\n",
    "    destination           = A[14] \n",
    "    #destination_tuple_ids = A[20] \n",
    "    #source_tuple_ids      = A[21] \n",
    "    \n",
    "    # Created a dict out of sliced input producers\n",
    "    dataset_dict = dict(\n",
    "        y_gboost=y_gboost,\n",
    "        y_xgb=y_xgb,\n",
    "        y_bag=y_bag,\n",
    "        y_knn=y_knn,\n",
    "        y_dec=y_dec,\n",
    "        y_lgb=y_lgb,\n",
    "        sourceLatitude=sourceLatitude,\n",
    "        sourceLongitude=sourceLongitude,\n",
    "        destinationLatitude=destinationLatitude,\n",
    "        destinationLongitude=destinationLongitude, \n",
    "        distanceKM=distanceKM,\n",
    "        taxiDurationMin=taxiDurationMin,\n",
    "        weight=weight,\n",
    "        #date_ids=date_ids,\n",
    "        #SourceState_ids=SourceState_ids,\n",
    "        #destinationState_ids=destinationState_ids,\n",
    "        #vehicleType_ids=vehicleType_ids,\n",
    "        #vehicleOption_ids=vehicleOption_ids,\n",
    "        source=source, \n",
    "        destination=destination,\n",
    "        #destination_tuple_ids=destination_tuple_ids,\n",
    "        #source_tuple_ids=source_tuple_ids,\n",
    "    )\n",
    "\n",
    "    if not pred:\n",
    "        dataset_dict['labels'] = A[15]\n",
    "            \n",
    "    batch_dict = tf.train.batch(\n",
    "        dataset_dict,\n",
    "        batch_number,\n",
    "   )\n",
    "\n",
    "    if pred == False:\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, tf.reshape(batch_labels, [-1, 1]) \n",
    "    else:\n",
    "        return batch_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "      <th>y_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40689</th>\n",
       "      <td>10602550191</td>\n",
       "      <td>34.319566</td>\n",
       "      <td>47.078555</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>19000000.0</td>\n",
       "      <td>27.474105</td>\n",
       "      <td>52.603738</td>\n",
       "      <td>859.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1445.240621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.001315e+07</td>\n",
       "      <td>20377512.00</td>\n",
       "      <td>20693972.0</td>\n",
       "      <td>4290000.0</td>\n",
       "      <td>1.883525e+07</td>\n",
       "      <td>2.214366e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28663</th>\n",
       "      <td>59022077023</td>\n",
       "      <td>35.699056</td>\n",
       "      <td>51.402792</td>\n",
       "      <td>911.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>29.617603</td>\n",
       "      <td>51.652078</td>\n",
       "      <td>661.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>1529.810740</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.602654e+06</td>\n",
       "      <td>7494018.50</td>\n",
       "      <td>4657211.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>4.240625e+06</td>\n",
       "      <td>7.224867e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19042</th>\n",
       "      <td>74752147720</td>\n",
       "      <td>27.182853</td>\n",
       "      <td>56.273862</td>\n",
       "      <td>980.0</td>\n",
       "      <td>10338000.0</td>\n",
       "      <td>32.801625</td>\n",
       "      <td>51.689466</td>\n",
       "      <td>667.0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>1695.498480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.197673e+06</td>\n",
       "      <td>9348608.00</td>\n",
       "      <td>9439628.0</td>\n",
       "      <td>8305000.0</td>\n",
       "      <td>9.854376e+06</td>\n",
       "      <td>1.029661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21837</th>\n",
       "      <td>76223312658</td>\n",
       "      <td>32.673139</td>\n",
       "      <td>51.670482</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2320000.0</td>\n",
       "      <td>34.136752</td>\n",
       "      <td>50.566116</td>\n",
       "      <td>142.0</td>\n",
       "      <td>11.30</td>\n",
       "      <td>1726.162961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.536652e+06</td>\n",
       "      <td>2578700.75</td>\n",
       "      <td>2509670.0</td>\n",
       "      <td>2320000.0</td>\n",
       "      <td>2.347938e+06</td>\n",
       "      <td>3.293571e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35006</th>\n",
       "      <td>74609642925</td>\n",
       "      <td>35.699332</td>\n",
       "      <td>51.395552</td>\n",
       "      <td>935.0</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>30.435378</td>\n",
       "      <td>49.111278</td>\n",
       "      <td>659.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1494.720310</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.737643e+07</td>\n",
       "      <td>17874336.00</td>\n",
       "      <td>17712615.0</td>\n",
       "      <td>16650000.0</td>\n",
       "      <td>1.878682e+07</td>\n",
       "      <td>1.692893e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  destinationLatitude  destinationLongitude  distanceKM  \\\n",
       "40689  10602550191            34.319566             47.078555      1172.0   \n",
       "28663  59022077023            35.699056             51.402792       911.0   \n",
       "19042  74752147720            27.182853             56.273862       980.0   \n",
       "21837  76223312658            32.673139             51.670482       200.0   \n",
       "35006  74609642925            35.699332             51.395552       935.0   \n",
       "\n",
       "            price  sourceLatitude  sourceLongitude  taxiDurationMin  weight  \\\n",
       "40689  19000000.0       27.474105        52.603738            859.0   22.00   \n",
       "28663   8000000.0       29.617603        51.652078            661.0    5.35   \n",
       "19042  10338000.0       32.801625        51.689466            667.0   23.61   \n",
       "21837   2320000.0       34.136752        50.566116            142.0   11.30   \n",
       "35006  18000000.0       30.435378        49.111278            659.0   22.00   \n",
       "\n",
       "            source      ...       vehicleOption_mosaghaf_chadori  \\\n",
       "40689  1445.240621      ...                                    0   \n",
       "28663  1529.810740      ...                                    0   \n",
       "19042  1695.498480      ...                                    0   \n",
       "21837  1726.162961      ...                                    0   \n",
       "35006  1494.720310      ...                                    0   \n",
       "\n",
       "       vehicleOption_mosaghaf_felezi  vehicleOption_transit_chadori  \\\n",
       "40689                              0                              0   \n",
       "28663                              0                              0   \n",
       "19042                              0                              0   \n",
       "21837                              0                              0   \n",
       "35006                              0                              0   \n",
       "\n",
       "       vehicleOption_yakhchali      y_gboost        y_xgb       y_bag  \\\n",
       "40689                        0  2.001315e+07  20377512.00  20693972.0   \n",
       "28663                        0  5.602654e+06   7494018.50   4657211.0   \n",
       "19042                        0  9.197673e+06   9348608.00   9439628.0   \n",
       "21837                        0  2.536652e+06   2578700.75   2509670.0   \n",
       "35006                        0  1.737643e+07  17874336.00  17712615.0   \n",
       "\n",
       "            y_knn         y_dec         y_lgb  \n",
       "40689   4290000.0  1.883525e+07  2.214366e+07  \n",
       "28663   6000000.0  4.240625e+06  7.224867e+06  \n",
       "19042   8305000.0  9.854376e+06  1.029661e+07  \n",
       "21837   2320000.0  2.347938e+06  3.293571e+06  \n",
       "35006  16650000.0  1.878682e+07  1.692893e+07  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpo0dro1xw\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpo0dro1xw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c304ad550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpo0dro1xw/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8928477, step = 1\n",
      "INFO:tensorflow:global_step/sec: 51.0054\n",
      "INFO:tensorflow:loss = 0.1670513, step = 101 (1.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0545\n",
      "INFO:tensorflow:loss = 0.16246572, step = 201 (1.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9658\n",
      "INFO:tensorflow:loss = 0.17398131, step = 301 (1.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.9164\n",
      "INFO:tensorflow:loss = 0.16998205, step = 401 (1.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.0636\n",
      "INFO:tensorflow:loss = 0.15469486, step = 501 (1.885 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpo0dro1xw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15033391.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c304ad208>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "estimator_val = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator_val.train(input_fn=lambda: input_fn(X_train), steps=600)#TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpo0dro1xw/model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.70474557722731"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val   = list(estimator_val.predict(input_fn = lambda: input_fn(X_val, pred=True)))\n",
    "y_preds_val       = [int(x) for x in predictions_val]\n",
    "mean_absolute_precision_error(y_preds_val, X_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp3mq22du1\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp3mq22du1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a291c0748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp3mq22du1/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.9024897, step = 1\n",
      "INFO:tensorflow:global_step/sec: 52.0463\n",
      "INFO:tensorflow:loss = 0.17032763, step = 101 (1.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6622\n",
      "INFO:tensorflow:loss = 0.18262921, step = 201 (1.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.1827\n",
      "INFO:tensorflow:loss = 0.15667431, step = 301 (1.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.9986\n",
      "INFO:tensorflow:loss = 0.16508597, step = 401 (1.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7387\n",
      "INFO:tensorflow:loss = 0.16284315, step = 501 (1.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6097\n",
      "INFO:tensorflow:loss = 0.15631491, step = 601 (1.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5632\n",
      "INFO:tensorflow:loss = 0.17438824, step = 701 (1.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.0562\n",
      "INFO:tensorflow:loss = 0.17397363, step = 801 (1.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.814\n",
      "INFO:tensorflow:loss = 0.16380352, step = 901 (1.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7281\n",
      "INFO:tensorflow:loss = 0.14431942, step = 1001 (1.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7416\n",
      "INFO:tensorflow:loss = 0.17233485, step = 1101 (1.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp3mq22du1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1621139.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a291c0550>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator.train(input_fn=lambda: input_fn(train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions   = list(estimator.predict(input_fn = lambda: input_fn(test, pred=True)))\n",
    "y_preds_test   = [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission32.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submission 19 with loss of 15.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
