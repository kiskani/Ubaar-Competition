{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import datetime\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import model_selection \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge, LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mape_fuc(labels, preds):\n",
    "    return np.mean(np.abs((preds - labels)/(labels))) * 100\n",
    "\n",
    "mape_score = make_scorer(mape_fuc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49557, 86)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "# Remove NANs\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "# Remove outliers\n",
    "data.drop([28098])\n",
    "THRESHOLD = 4.5e7\n",
    "Aa = data[data.price > THRESHOLD]\n",
    "data = data.drop(Aa.index.tolist())\n",
    "\n",
    "specific_cols = ['distanceKM', 'taxiDurationMin', 'weight']\n",
    "removed_indices = []\n",
    "for col in specific_cols:\n",
    "    df = data['price']/data[col]\n",
    "    A = df[~df.isin([np.nan, np.inf, -np.inf])]\n",
    "    B = (A - np.mean(A)) / np.std(A)\n",
    "    V = B[B > 5]\n",
    "    removed_indices.extend(V.index.tolist())\n",
    "data = data.drop(set(removed_indices))\n",
    "\n",
    "# Fill test NANs\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "feat_cols  = train.drop(['ID','price'],axis=1).columns.tolist()\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleType_treili</th>\n",
       "      <th>vehicleOption_bari</th>\n",
       "      <th>vehicleOption_hichkodam</th>\n",
       "      <th>vehicleOption_kafi</th>\n",
       "      <th>vehicleOption_kompressi</th>\n",
       "      <th>vehicleOption_labehdar</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88142929797</td>\n",
       "      <td>29.600574</td>\n",
       "      <td>52.537114</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>15300000.0</td>\n",
       "      <td>36.666045</td>\n",
       "      <td>48.489706</td>\n",
       "      <td>751.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1777.925742</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30842979862</td>\n",
       "      <td>34.644923</td>\n",
       "      <td>50.876092</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>32.323951</td>\n",
       "      <td>50.855412</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1643.847846</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54262798716</td>\n",
       "      <td>31.819508</td>\n",
       "      <td>49.865235</td>\n",
       "      <td>310.0</td>\n",
       "      <td>3742000.0</td>\n",
       "      <td>32.575448</td>\n",
       "      <td>51.581011</td>\n",
       "      <td>292.0</td>\n",
       "      <td>14.97</td>\n",
       "      <td>1680.274542</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64071173752</td>\n",
       "      <td>35.703801</td>\n",
       "      <td>51.398824</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>35.029685</td>\n",
       "      <td>48.085763</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1684.429131</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68088966447</td>\n",
       "      <td>36.730367</td>\n",
       "      <td>53.965480</td>\n",
       "      <td>756.0</td>\n",
       "      <td>8870000.0</td>\n",
       "      <td>31.586965</td>\n",
       "      <td>54.449607</td>\n",
       "      <td>573.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1719.897831</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  destinationLatitude  destinationLongitude  distanceKM  \\\n",
       "0  88142929797            29.600574             52.537114      1092.0   \n",
       "1  30842979862            34.644923             50.876092       414.0   \n",
       "2  54262798716            31.819508             49.865235       310.0   \n",
       "3  64071173752            35.703801             51.398824       391.0   \n",
       "4  68088966447            36.730367             53.965480       756.0   \n",
       "\n",
       "        price  sourceLatitude  sourceLongitude  taxiDurationMin  weight  \\\n",
       "0  15300000.0       36.666045        48.489706            751.0   20.00   \n",
       "1   1800000.0       32.323951        50.855412            264.0    2.50   \n",
       "2   3742000.0       32.575448        51.581011            292.0   14.97   \n",
       "3   1300000.0       35.029685        48.085763            271.0    2.50   \n",
       "4   8870000.0       31.586965        54.449607            573.0   15.00   \n",
       "\n",
       "        source           ...             vehicleType_treili  \\\n",
       "0  1777.925742           ...                              1   \n",
       "1  1643.847846           ...                              0   \n",
       "2  1680.274542           ...                              0   \n",
       "3  1684.429131           ...                              0   \n",
       "4  1719.897831           ...                              0   \n",
       "\n",
       "   vehicleOption_bari  vehicleOption_hichkodam  vehicleOption_kafi  \\\n",
       "0                   0                        0                   1   \n",
       "1                   0                        0                   0   \n",
       "2                   0                        0                   0   \n",
       "3                   0                        0                   0   \n",
       "4                   1                        0                   0   \n",
       "\n",
       "   vehicleOption_kompressi  vehicleOption_labehdar  \\\n",
       "0                        0                       0   \n",
       "1                        0                       0   \n",
       "2                        1                       0   \n",
       "3                        0                       0   \n",
       "4                        0                       0   \n",
       "\n",
       "   vehicleOption_mosaghaf_chadori  vehicleOption_mosaghaf_felezi  \\\n",
       "0                               0                              0   \n",
       "1                               0                              1   \n",
       "2                               0                              0   \n",
       "3                               0                              1   \n",
       "4                               0                              0   \n",
       "\n",
       "   vehicleOption_transit_chadori  vehicleOption_yakhchali  \n",
       "0                              0                        0  \n",
       "1                              0                        0  \n",
       "2                              0                        0  \n",
       "3                              0                        0  \n",
       "4                              0                        0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg1 = Ridge()#random_state=5)\n",
    "knn1 = KNeighborsClassifier(2)\n",
    "lass1 = Lasso(fit_intercept = True)#, random_state=5)\n",
    "entf1 = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9))#, random_state=5))\n",
    "\n",
    "xgb1 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,nthread = -1)\n",
    "#                        random_state =5 , \n",
    "\n",
    "gbst1 = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber')#, random_state = 5)\n",
    "\n",
    "lgb1  = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.005, n_estimators=120000, #random_state= 5, \n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "bag1 = BaggingRegressor(n_estimators=600, max_samples=1.0, max_features=0.9,verbose=1)# random_state=5, \n",
    "\n",
    "dec1 = DecisionTreeRegressor(criterion='mae', splitter='best', max_depth=16, min_samples_split=20,\n",
    "                             min_samples_leaf=10, min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                             max_leaf_nodes=None, min_impurity_decrease=0.0, #random_state=5,\n",
    "                             min_impurity_split=None, presort=False)\n",
    "\n",
    "rfst1 = RandomForestRegressor(n_estimators=20, criterion='mae', \n",
    "                              max_depth=4, max_features='sqrt',\n",
    "                              min_samples_leaf=5, min_samples_split =3)#, random_state = 5)\n",
    "\n",
    "adbst1 = AdaBoostRegressor(n_estimators=1, learning_rate=0.01, loss='linear')#, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_all = { \"Gboost\": gbst1, \"xgb\": xgb1, \"bagging\": bag1, \"lgbm\": lgb1, \"dec_tree\": dec1, \"Random_forest\": rfst1,\n",
    "          \"knn\": knn1, \"elasticNet\": entf1, \"ridge\": rdg1, \"lasso\": lass1, \"AdaBoost\": adbst1}\n",
    "\n",
    "models_base  = {\"knn       \": knn1,   \"elasticNet\": entf1, \"ridge     \": rdg1, \"lasso     \": lass1\n",
    "               ,\"AdaBoost  \": adbst1, \"dec_tree  \": dec1,  \"lgbm      \": lgb1, \"RndmForest\": rfst1 \n",
    "               ,\"bagging   \": bag1,   \"xgb       \": xgb1,  \"Gboost    \": gbst1 \n",
    "               }\n",
    "\n",
    "models_final = {\"knn       \": knn1,   \"elasticNet\": entf1, \"ridge     \": rdg1, \"lasso     \": lass1\n",
    "               ,\"AdaBoost  \": adbst1, \"dec_tree  \": dec1,  \"lgbm      \": lgb1, \"RndmForest\": rfst1 \n",
    "               ,\"bagging   \": bag1,   \"xgb       \": xgb1,  \"Gboost    \": gbst1 \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = []\n",
    "\n",
    "for model_name in models_base:\n",
    "    model1 = models_base[model_name]\n",
    "    model2 = models_base[model_name]\n",
    "    \n",
    "    pred_cols.append('y_' + model_name)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Started training    \" + model_name + \"        at time: \", datetime.datetime.now())\n",
    "    \n",
    "    train1, train2 = train_test_split(train, test_size=0.5)\n",
    "    \n",
    "    model1.fit(train1.drop(['ID','price'],axis=1), train1.price)\n",
    "    model2.fit(train2.drop(['ID','price'],axis=1), train2.price)\n",
    "    \n",
    "    train2['y_' + model_name] = model1.predict(train2.drop(['ID','price'],axis=1))\n",
    "    train1['y_' + model_name] = model2.predict(train1.drop(['ID','price'],axis=1))\n",
    "    \n",
    "    train = pd.concat([train1, train2])\n",
    "    print(\"Done training       \" +model_name, '       in %.2f' % float((time.time() - start_time)/60 ) +\" mins\")\n",
    "    \n",
    "train.to_pickle('dataFrames/updated_train_June_22.pkl')\n",
    "\n",
    "# Results with random_state=5 \n",
    "#Started training    knn               at time:  2018-06-21 17:40:03.117144\n",
    "#Done training       knn               in 0.11 mins\n",
    "#Started training    elasticNet        at time:  2018-06-21 17:40:09.494914\n",
    "#Done training       elasticNet        in 0.02 mins\n",
    "#Started training    ridge             at time:  2018-06-21 17:40:10.439206\n",
    "#Done training       ridge             in 0.00 mins\n",
    "#Started training    lasso             at time:  2018-06-21 17:40:10.728227\n",
    "#Done training       lasso             in 0.13 mins\n",
    "#Started training    AdaBoost          at time:  2018-06-21 17:40:18.251842\n",
    "#Done training       AdaBoost          in 0.01 mins\n",
    "#Started training    dec_tree          at time:  2018-06-21 17:40:18.692906\n",
    "#Done training       dec_tree          in 4.10 mins\n",
    "#Started training    lgbm              at time:  2018-06-21 17:44:24.569371\n",
    "#Done training       lgbm              in 26.13 mins\n",
    "#Started training    RndmForest        at time:  2018-06-21 18:10:32.619772\n",
    "#Done training       RndmForest        in 3.93 mins\n",
    "#Started training    bagging           at time:  2018-06-21 18:14:28.656966\n",
    "#Done training       bagging           in 10.20 mins\n",
    "#Started training    xgb               at time:  2018-06-21 18:24:40.703583\n",
    "#Done training       xgb               in 40.93 mins\n",
    "#Started training    Gboost            at time:  2018-06-21 19:06:57.921625\n",
    "#Done training       Gboost            in 26.36 mins\n",
    "\n",
    "\n",
    "# Results without random_state set \n",
    "#Started training    knn               at time:  2018-06-22 02:40:50.818880\n",
    "#Done training       knn               in 0.11 mins\n",
    "#Started training    elasticNet        at time:  2018-06-22 02:40:57.468835\n",
    "#Done training       elasticNet        in 0.01 mins\n",
    "#Started training    ridge             at time:  2018-06-22 02:40:58.343920\n",
    "#Done training       ridge             in 0.01 mins\n",
    "#Started training    lasso             at time:  2018-06-22 02:40:58.683624\n",
    "#Done training       lasso             in 0.13 mins\n",
    "#Started training    AdaBoost          at time:  2018-06-22 02:41:06.314617\n",
    "#Done training       AdaBoost          in 0.01 mins\n",
    "#Started training    dec_tree          at time:  2018-06-22 02:41:06.767423\n",
    "#Done training       dec_tree          in 4.05 mins\n",
    "#Started training    lgbm              at time:  2018-06-22 02:45:09.520694\n",
    "#Done training       lgbm              in 24.48 mins\n",
    "#Started training    RndmForest        at time:  2018-06-22 03:09:38.057324\n",
    "#Done training       RndmForest        in 3.74 mins\n",
    "#Started training    bagging           at time:  2018-06-22 03:13:22.515465\n",
    "#Done training       bagging           in 9.86 mins\n",
    "#Started training    xgb               at time:  2018-06-22 03:23:14.246388\n",
    "#Done training       xgb               in 38.54 mins\n",
    "#Started training    Gboost            at time:  2018-06-22 04:01:46.897449\n",
    "#Done training       Gboost            in 23.86 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = pd.read_pickle('dataFrames/updated_train_June_22.pkl')\n",
    "\n",
    "for model_name in models_base:\n",
    "    model = models_base[model_name]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"Started adding    \" + model_name + \"        to the test data at time: \", datetime.datetime.now() )\n",
    "    \n",
    "    model.fit(train[feat_cols] , train.price)\n",
    "    test['y_' + model_name] = model.predict(test[feat_cols])\n",
    "\n",
    "    print(\"Done adding       \" +model_name, '       to the test data in %.2f' % float((time.time() - start_time)/60 ) +\" mins\")\n",
    "    \n",
    "test.to_pickle('dataFrames/updated_test_June_22.pkl')\n",
    "\n",
    "# Results with random_state=5 \n",
    "#Started adding    knn               to the test data at time:  2018-06-21 19:38:28.442436\n",
    "#Done adding       knn               to the test data in 0.04 mins\n",
    "#Started adding    elasticNet        to the test data at time:  2018-06-21 19:38:30.695390\n",
    "#Done adding       elasticNet        to the test data in 0.02 mins\n",
    "#Started adding    ridge             to the test data at time:  2018-06-21 19:38:31.623906\n",
    "#Done adding       ridge             to the test data in 0.00 mins\n",
    "#Started adding    lasso             to the test data at time:  2018-06-21 19:38:31.771744\n",
    "#Done adding       lasso             to the test data in 0.12 mins\n",
    "#Started adding    AdaBoost          to the test data at time:  2018-06-21 19:38:38.948664\n",
    "#Done adding       AdaBoost          to the test data in 0.01 mins\n",
    "#Started adding    dec_tree          to the test data at time:  2018-06-21 19:38:39.335052\n",
    "#Done adding       dec_tree          to the test data in 7.59 mins\n",
    "#Started adding    lgbm              to the test data at time:  2018-06-21 19:46:14.511570\n",
    "#Done adding       lgbm              to the test data in 13.24 mins\n",
    "#Started adding    RndmForest        to the test data at time:  2018-06-21 19:59:28.829603\n",
    "#Done adding       RndmForest        to the test data in 9.03 mins\n",
    "#Started adding    bagging           to the test data at time:  2018-06-21 20:08:30.364155\n",
    "#Done adding       bagging           to the test data in 5.77 mins\n",
    "#Started adding    xgb               to the test data at time:  2018-06-21 20:14:16.633645\n",
    "#Done adding       xgb               to the test data in 32.06 mins\n",
    "#Started adding    Gboost            to the test data at time:  2018-06-21 20:46:20.278354\n",
    "#Done adding       Gboost            to the test data in 30.96 mins\n",
    "\n",
    "\n",
    "# Results without random_state set \n",
    "#Started adding    knn               to the test data at time:  2018-06-22 04:25:38.845725\n",
    "#Done adding       knn               to the test data in 0.04 mins\n",
    "#Started adding    elasticNet        to the test data at time:  2018-06-22 04:25:41.066799\n",
    "#Done adding       elasticNet        to the test data in 0.01 mins\n",
    "#Started adding    ridge             to the test data at time:  2018-06-22 04:25:41.954959\n",
    "#Done adding       ridge             to the test data in 0.00 mins\n",
    "#Started adding    lasso             to the test data at time:  2018-06-22 04:25:42.074074\n",
    "#Done adding       lasso             to the test data in 0.12 mins\n",
    "#Started adding    AdaBoost          to the test data at time:  2018-06-22 04:25:49.228870\n",
    "#Done adding       AdaBoost          to the test data in 0.01 mins\n",
    "#Started adding    dec_tree          to the test data at time:  2018-06-22 04:25:49.595628\n",
    "#Done adding       dec_tree          to the test data in 7.34 mins\n",
    "#Started adding    lgbm              to the test data at time:  2018-06-22 04:33:09.923394\n",
    "#Done adding       lgbm              to the test data in 12.15 mins\n",
    "#Started adding    RndmForest        to the test data at time:  2018-06-22 04:45:18.979901\n",
    "#Done adding       RndmForest        to the test data in 8.15 mins\n",
    "#Started adding    bagging           to the test data at time:  2018-06-22 04:53:28.114233\n",
    "#Done adding       bagging           to the test data in 5.62 mins\n",
    "#Started adding    xgb               to the test data at time:  2018-06-22 04:59:05.126341\n",
    "#Done adding       xgb               to the test data in 31.17 mins\n",
    "#Started adding    Gboost            to the test data at time:  2018-06-22 05:30:15.310855\n",
    "#Done adding       Gboost            to the test data in 30.37 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = pd.read_pickle('dataFrames/updated_train_June_22.pkl')\n",
    "\n",
    "X_all = train.drop(['ID','price'],axis=1)\n",
    "y_all = train.price\n",
    "for model_name in models_final:\n",
    "    model = models_final[model_name]\n",
    "    X = X_all.drop(['y_' + model_name], axis=1)\n",
    "    start_time = time.time()\n",
    "    print(\"Started training the final model,    \" + model_name + \"        at time: \", datetime.datetime.now())\n",
    "    score = model_selection.cross_val_score(model, X, y_all, scoring=mape_score, cv = 3)\n",
    "    print(\"Done training the final model,       \" +model_name, '       in %.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score.mean())\n",
    "\n",
    "# Results with random_state=5 \n",
    "#Started training the final model,    knn               at time:  2018-06-21 21:44:26.142029\n",
    "#Done training the final model,       knn               in 0.21 mins, score=  6.19\n",
    "#Started training the final model,    elasticNet        at time:  2018-06-21 21:44:38.991180\n",
    "#Done training the final model,       elasticNet        in 0.13 mins, score=  6.75\n",
    "#Started training the final model,    ridge             at time:  2018-06-21 21:44:46.841943\n",
    "#Done training the final model,       ridge             in 0.01 mins, score=  4.54\n",
    "#Started training the final model,    lasso             at time:  2018-06-21 21:44:47.179869\n",
    "#Done training the final model,       lasso             in 0.27 mins, score=  4.54\n",
    "#Started training the final model,    AdaBoost          at time:  2018-06-21 21:45:03.127976\n",
    "#Done training the final model,       AdaBoost          in 0.02 mins, score=  16.75\n",
    "#Started training the final model,    dec_tree          at time:  2018-06-21 21:45:04.065791\n",
    "#Done training the final model,       dec_tree          in 12.48 mins, score=  4.32\n",
    "#Started training the final model,    lgbm              at time:  2018-06-21 21:57:32.929486\n",
    "#Done training the final model,       lgbm              in 39.12 mins, score=  5.15\n",
    "#Started training the final model,    RndmForest        at time:  2018-06-21 22:36:39.860109\n",
    "#Done training the final model,       RndmForest        in 10.39 mins, score=  14.57\n",
    "#Started training the final model,    bagging           at time:  2018-06-21 22:47:03.556538\n",
    "#Done training the final model,       bagging           in 22.74 mins, score=  4.41\n",
    "#Started training the final model,    xgb               at time:  2018-06-21 23:09:48.032251\n",
    "#Done training the final model,       xgb               in 79.95 mins, score=  4.93\n",
    "#Started training the final model,    Gboost            at time:  2018-06-22 00:29:44.866651\n",
    "#Done training the final model,       Gboost            in 52.85 mins, score=  5.36\n",
    "\n",
    "\n",
    "# Results without random_state set \n",
    "#Started training the final model,    knn               at time:  2018-06-22 06:00:37.899922\n",
    "#Done training the final model,       knn               in 0.21 mins, score=  6.15\n",
    "#Started training the final model,    elasticNet        at time:  2018-06-22 06:00:50.245410\n",
    "#Done training the final model,       elasticNet        in 0.14 mins, score=  6.70\n",
    "#Started training the final model,    ridge             at time:  2018-06-22 06:00:58.689795\n",
    "#Done training the final model,       ridge             in 0.00 mins, score=  4.52\n",
    "#Started training the final model,    lasso             at time:  2018-06-22 06:00:58.939183\n",
    "#Done training the final model,       lasso             in 0.27 mins, score=  4.53\n",
    "#Started training the final model,    AdaBoost          at time:  2018-06-22 06:01:14.859141\n",
    "#Done training the final model,       AdaBoost          in 0.02 mins, score=  16.99\n",
    "#Started training the final model,    dec_tree          at time:  2018-06-22 06:01:15.808657\n",
    "#Done training the final model,       dec_tree          in 12.17 mins, score=  4.30\n",
    "#Started training the final model,    lgbm              at time:  2018-06-22 06:13:25.991858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = pd.read_pickle('dataFrames/updated_train_June_22.pkl')\n",
    "test       = pd.read_pickle('dataFrames/updated_test_June_22.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_final_model = 'dec_tree  '\n",
    "selected_final_model = 'bagging   '\n",
    "selected_final_model = 'ridge     '\n",
    "\n",
    "X      = train.drop(['ID','price', 'y_'+selected_final_model], axis=1)\n",
    "y      = train.price\n",
    "X_test = test.drop(['ID','price', 'y_'+selected_final_model], axis=1)\n",
    "\n",
    "model  = models_final[selected_final_model]\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Started fitting the selected final model,    \" + selected_final_model +\\\n",
    "      \"        at time: \", datetime.datetime.now())\n",
    "model.fit(X, y)\n",
    "y_pred_test = model.predict(X_test)\n",
    "print(\"Done fitting the selected final model,       \" + selected_final_model, \\\n",
    "      '       in %.2f' % float((time.time() - start_time)/60 ) +\" mins\")\n",
    "\n",
    "# Results with random_state=5 \n",
    "#Started fitting the selected final model,    dec_tree          at time:  2018-06-22 01:25:39.366947\n",
    "#Done fitting the selected final model,       dec_tree          in 9.59 mins \n",
    "# dec_tree resulted in a final public leaderboard score of 16.50   =====> submission69.csv\n",
    "\n",
    "#Started fitting the selected final model,    bagging           at time:  2018-06-22 01:44:57.771315\n",
    "#Done fitting the selected final model,       bagging           in 12.72 mins\n",
    "# bagging  resulted in a final public leaderboard score of 16.51   =====> submission70.csv\n",
    "\n",
    "#Started fitting the selected final model,    ridge             at time:  2018-06-22 02:00:34.867528\n",
    "#Done fitting the selected final model,       ridge             in 0.00 mins\n",
    "# ridge    resulted in a final public leaderboard score of 16.34   =====> submission71.csv\n",
    "\n",
    "\n",
    "# Results without random_state set \n",
    "#Started fitting the selected final model,    ridge             at time:  2018-06-22 09:20:03.496934\n",
    "#Done fitting the selected final model,       ridge             in 0.00 mins\n",
    "# ridge    resulted in a final public leaderboard score of 16.32   =====> submission72.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preventing overfitting in augmenting test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train          = pd.read_pickle('dataFrames/updated_train_June_22.pkl')\n",
    "#train1, train2 = train_test_split(train, test_size=0.8)\n",
    "\n",
    "#for model_name in models_base:\n",
    "#    model = models_base[model_name]\n",
    "#    \n",
    "#    start_time = time.time()\n",
    "#    print(\"Started adding    \" + model_name + \"        to the test data at time: \", datetime.datetime.now() )\n",
    "#    \n",
    "#    model.fit(train1[feat_cols] , train1.price)\n",
    "#    test['y_' + model_name] = model.predict(test[feat_cols])\n",
    "#\n",
    "#    print(\"Done adding       \" +model_name, '       to the test data in %.2f' % float((time.time() - start_time)/60 ) +\" mins\")\n",
    "#    \n",
    "#test.to_pickle('dataFrames/updated_test_June_22_with_splitting_train_data.pkl')\n",
    "\n",
    "#Started adding    knn               to the test data at time:  2018-06-22 12:44:01.855999\n",
    "#Done adding       knn               to the test data in 0.02 mins\n",
    "#Started adding    elasticNet        to the test data at time:  2018-06-22 12:44:03.149277\n",
    "#Done adding       elasticNet        to the test data in 0.00 mins\n",
    "#Started adding    ridge             to the test data at time:  2018-06-22 12:44:03.328871\n",
    "#Done adding       ridge             to the test data in 0.00 mins\n",
    "#Started adding    lasso             to the test data at time:  2018-06-22 12:44:03.381281\n",
    "#Done adding       lasso             to the test data in 0.02 mins\n",
    "#Started adding    AdaBoost          to the test data at time:  2018-06-22 12:44:04.307421\n",
    "#Done adding       AdaBoost          to the test data in 0.00 mins\n",
    "#Started adding    dec_tree          to the test data at time:  2018-06-22 12:44:04.396390\n",
    "#Done adding       dec_tree          to the test data in 0.28 mins\n",
    "#Started adding    lgbm              to the test data at time:  2018-06-22 12:44:21.483120\n",
    "#Done adding       lgbm              to the test data in 11.24 mins\n",
    "#Started adding    RndmForest        to the test data at time:  2018-06-22 12:55:36.140693\n",
    "#Done adding       RndmForest        to the test data in 0.31 mins\n",
    "#Started adding    bagging           to the test data at time:  2018-06-22 12:55:54.811298\n",
    "#Done adding       bagging           to the test data in 0.95 mins\n",
    "#Started adding    xgb               to the test data at time:  2018-06-22 12:56:51.752518\n",
    "#Done adding       xgb               to the test data in 6.75 mins\n",
    "#Started adding    Gboost            to the test data at time:  2018-06-22 13:03:36.976831\n",
    "#Done adding       Gboost            to the test data in 5.15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all = train2.drop(['ID','price'],axis=1)\n",
    "#y_all = train2.price\n",
    "#for model_name in models_final:\n",
    "#    model = models_final[model_name]\n",
    "#    X = X_all.drop(['y_' + model_name], axis=1)\n",
    "#    start_time = time.time()\n",
    "#    print(\"Started training the final model,    \" + model_name + \"        at time: \", datetime.datetime.now())\n",
    "#    score = model_selection.cross_val_score(model, X, y_all, scoring=mape_score, cv = 3)\n",
    "#    print(\"Done training the final model,       \" +model_name, '       in %.2f' % float((time.time() - start_time)/60) +\" mins, score= \", '%.2f' % score.mean())\n",
    "    \n",
    "#Started training the final model,    knn               at time:  2018-06-22 13:12:05.399169\n",
    "#Done training the final model,       knn               in 0.15 mins, score=  6.25\n",
    "#Started training the final model,    elasticNet        at time:  2018-06-22 13:12:14.505529\n",
    "#Done training the final model,       elasticNet        in 0.11 mins, score=  6.69\n",
    "#Started training the final model,    ridge             at time:  2018-06-22 13:12:20.873534\n",
    "#Done training the final model,       ridge             in 0.00 mins, score=  4.22\n",
    "#Started training the final model,    lasso             at time:  2018-06-22 13:12:21.000378\n",
    "#Done training the final model,       lasso             in 0.22 mins, score=  4.22\n",
    "#Started training the final model,    AdaBoost          at time:  2018-06-22 13:12:33.962768\n",
    "#Done training the final model,       AdaBoost          in 0.01 mins, score=  16.81\n",
    "#Started training the final model,    dec_tree          at time:  2018-06-22 13:12:34.672086\n",
    "#Done training the final model,       dec_tree          in 7.91 mins, score=  4.08\n",
    "#Started training the final model,    lgbm              at time:  2018-06-22 13:20:29.435804    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_final_model = 'dec_tree  '\n",
    "#selected_final_model = 'bagging   '\n",
    "#selected_final_model = 'ridge     '\n",
    "\n",
    "#X      = train.drop(['ID','price', 'y_'+selected_final_model], axis=1)\n",
    "#y      = train.price\n",
    "#X_test = test.drop(['ID','price', 'y_'+selected_final_model], axis=1)\n",
    "\n",
    "#model  = models_final[selected_final_model]\n",
    "\n",
    "#start_time = time.time()\n",
    "#print(\"Started fitting the selected final model,    \" + selected_final_model +\\\n",
    "#      \"        at time: \", datetime.datetime.now())\n",
    "#model.fit(X, y)\n",
    "#y_pred_test = model.predict(X_test)\n",
    "#print(\"Done fitting the selected final model,       \" + selected_final_model, \\\n",
    "#      '       in %.2f' % float((time.time() - start_time)/60 ) +\" mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission73.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(y_pred_test.shape[0]):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_pred_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
