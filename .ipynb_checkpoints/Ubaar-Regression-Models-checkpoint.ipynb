{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "#from scipy.special import boxcox1p\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "from mlxtend.regressor import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def normalize_column(col):\n",
    "#    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "#def scale_minmax(col):\n",
    "#    return (col-col.min())/(col.max()-col.min())\n",
    "\n",
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>SourceState_ids</th>\n",
       "      <th>destinationState_ids</th>\n",
       "      <th>vehicleType_ids</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>36.473089</td>\n",
       "      <td>52.349822</td>\n",
       "      <td>184.0</td>\n",
       "      <td>35.700109</td>\n",
       "      <td>51.399743</td>\n",
       "      <td>199.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>124</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1410</td>\n",
       "      <td>1774</td>\n",
       "      <td>1834.976428</td>\n",
       "      <td>1909.359717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>35.704176</td>\n",
       "      <td>51.400280</td>\n",
       "      <td>331.0</td>\n",
       "      <td>37.275731</td>\n",
       "      <td>49.584392</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>118</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1926</td>\n",
       "      <td>1515</td>\n",
       "      <td>1848.294458</td>\n",
       "      <td>1835.204644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45277</th>\n",
       "      <td>35.699924</td>\n",
       "      <td>51.396715</td>\n",
       "      <td>447.0</td>\n",
       "      <td>32.665899</td>\n",
       "      <td>51.663805</td>\n",
       "      <td>285.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>801</td>\n",
       "      <td>1515</td>\n",
       "      <td>1687.644636</td>\n",
       "      <td>1834.858819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>30.199563</td>\n",
       "      <td>53.182966</td>\n",
       "      <td>809.0</td>\n",
       "      <td>35.699078</td>\n",
       "      <td>51.401589</td>\n",
       "      <td>525.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1410</td>\n",
       "      <td>463</td>\n",
       "      <td>1834.989335</td>\n",
       "      <td>1606.102332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>27.180941</td>\n",
       "      <td>56.277756</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>34.643252</td>\n",
       "      <td>50.877469</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1176</td>\n",
       "      <td>72</td>\n",
       "      <td>1762.560980</td>\n",
       "      <td>1529.682365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       destinationLatitude  destinationLongitude  distanceKM  sourceLatitude  \\\n",
       "39085            36.473089             52.349822       184.0       35.700109   \n",
       "30892            35.704176             51.400280       331.0       37.275731   \n",
       "45277            35.699924             51.396715       447.0       32.665899   \n",
       "16398            30.199563             53.182966       809.0       35.699078   \n",
       "13653            27.180941             56.277756      1144.0       34.643252   \n",
       "\n",
       "       sourceLongitude  taxiDurationMin  weight  date_ids  SourceState_ids  \\\n",
       "39085        51.399743            199.0   21.00       124                7   \n",
       "30892        49.584392            254.0    1.67       118               29   \n",
       "45277        51.663805            285.0   19.00        83                3   \n",
       "16398        51.401589            525.0    4.00       151                7   \n",
       "13653        50.877469            750.0    2.00        85               17   \n",
       "\n",
       "       destinationState_ids  vehicleType_ids  vehicleOption_ids  \\\n",
       "39085                    19                3                  2   \n",
       "30892                     7                1                  5   \n",
       "45277                     7                3                  7   \n",
       "16398                    15                1                  5   \n",
       "13653                    21                1                  5   \n",
       "\n",
       "       source_tuple_ids  destination_tuple_ids       source  destination  \n",
       "39085              1410                   1774  1834.976428  1909.359717  \n",
       "30892              1926                   1515  1848.294458  1835.204644  \n",
       "45277               801                   1515  1687.644636  1834.858819  \n",
       "16398              1410                    463  1834.989335  1606.102332  \n",
       "13653              1176                     72  1762.560980  1529.682365  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "\n",
    "min_price = min(all_data['price'])\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "BUCKET_LATI = 1000\n",
    "BUCKET_LONG = 1000\n",
    "\n",
    "min_source_lat  = min(all_data['sourceLatitude'])\n",
    "min_destin_lat  = min(all_data['destinationLatitude'])\n",
    "min_lat         = min(min_destin_lat, min_source_lat)\n",
    "\n",
    "min_source_long = min(all_data['sourceLongitude'])\n",
    "min_destin_long = min(all_data['destinationLongitude'])\n",
    "min_long        = min(min_destin_long, min_source_long)\n",
    "\n",
    "max_source_lat  = max(all_data['sourceLatitude'])\n",
    "max_destin_lat  = max(all_data['destinationLatitude'])\n",
    "max_lat         = max(max_destin_lat, max_source_lat)\n",
    "\n",
    "max_source_long = max(all_data['sourceLongitude'])\n",
    "max_destin_long = max(all_data['destinationLongitude'])\n",
    "max_long        = max(max_destin_long, max_source_long)\n",
    "\n",
    "d_lati = (max_lat - min_lat)/BUCKET_LATI\n",
    "d_long = (max_long - min_long)/BUCKET_LONG\n",
    "\n",
    "destin_lati_bucket = (all_data['destinationLatitude']  // d_lati).as_matrix().astype(int)\n",
    "destin_long_bucket = (all_data['destinationLongitude'] // d_long).as_matrix().astype(int)\n",
    "\n",
    "all_data['destination_tuple'] = tuple(zip(destin_lati_bucket,destin_long_bucket))\n",
    "\n",
    "source_lati_bucket = (all_data['sourceLatitude']  // d_lati).as_matrix().astype(int)\n",
    "source_long_bucket = (all_data['sourceLongitude'] // d_long).as_matrix().astype(int)\n",
    "\n",
    "all_data['source_tuple'] = tuple(zip(source_lati_bucket,source_long_bucket))\n",
    "\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', \n",
    "                    'vehicleOption', 'source_tuple', 'destination_tuple']\n",
    "\n",
    "all_data = all_data.copy()\n",
    "categorical_var_encoders = {}\n",
    "for var in categorical_vars:\n",
    "    le = preprocessing.LabelEncoder().fit(all_data[var])\n",
    "    all_data[var + '_ids']  = le.transform(all_data[var])\n",
    "    all_data[var + '_ids']  = all_data[var + '_ids'].astype('int32')\n",
    "    all_data.pop(var)\n",
    "    categorical_var_encoders[var] = le\n",
    "\n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "#categorical_var_encoders['SourceState'].classes_\n",
    "    \n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "X = train.drop(['ID','price'],axis=1)\n",
    "y = train.price\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBF = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                          learning_rate=0.05, n_estimators=15000,\n",
    "                          max_bin = 1000, bagging_fraction = 0.6,\n",
    "                          bagging_freq = 5, feature_fraction = 0.25,\n",
    "                          feature_fraction_seed=9, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "GBSTF = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state =5)\n",
    "\n",
    "XGBF = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=1.7817, n_estimators=2200,\n",
    "                        reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                        subsample=0.5213, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "\n",
    "BAGF = BaggingRegressor(n_estimators=100, max_samples=1.0, max_features=1.0, random_state=5, verbose=1)\n",
    "DECF  = DecisionTreeRegressor(max_depth=15)\n",
    "RFSTF = RandomForestRegressor(n_estimators=20, criterion='mae', \n",
    "                              max_depth=4, max_features='sqrt',\n",
    "                              min_samples_leaf=5, min_samples_split =3, random_state = 42)\n",
    "\n",
    "KNNF = KNeighborsClassifier(2)\n",
    "LASSF = Lasso(fit_intercept = True)\n",
    "ABSTF = AdaBoostRegressor(n_estimators=1000, learning_rate=0.05, loss='linear', random_state=5)\n",
    "\n",
    "SVRF = SVR()\n",
    "RDGF = Ridge()\n",
    "ENTF = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=3))\n",
    "\n",
    "models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF, \"dec_tree\": DECF, \"Random_forest\": RFSTF,\n",
    "          \"knn\": KNNF, \"elasticNet\": ENTF, \"ridge\": RDGF, \"lasso\": LASSF, \"AdaBoost\": ABSTF, \"SVR\": SVRF}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_cols = X_train.columns.tolist()\n",
    "    X_val['y_' + model_name] = model.predict(X_val[train_cols])\n",
    "    #stackedset = pd.concat([stackedset, pd.DataFrame(y_pred, columns=[model_name])], axis=1)\n",
    "    score = mean_absolute_precision_error(X_val['y_' + model_name], y_val)\n",
    "    print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "\n",
    "X_val.to_pickle('dataFrames/X_val.pkl')\n",
    "# Gboost,        4.35 mins, score=  17.21\n",
    "# xgb,           1.99 mins, score=  18.17\n",
    "# bagging,       0.67 mins, score=  19.14\n",
    "# lgbm,          1.07 mins, score=  20.03\n",
    "# dec_tree,      0.01 mins, score=  23.41\n",
    "# Random_forest, 4.58 mins, score=  30.52\n",
    "# knn,           0.00 mins, score=  32.04\n",
    "# elasticNet,    0.00 mins, score=  38.47 \n",
    "# ridge,         0.00 mins, score=  40.90\n",
    "# lasso,         0.02 mins, score=  40.91 \n",
    "# AdaBoost,      0.77 mins, score=  57.33 \n",
    "# SVR,           0.63 mins, score=  72.84 \n",
    "# KernelRidge and LinearRegression() take more than 1 hour to run! Don't Run them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "clf_ridge = GridSearchCV(ridge, {'alpha': [1e-3,1e-2,1e-1,1,1e1,1e2,1e3]}, verbose=1)\n",
    "\n",
    "clf_ridge.fit(X_train,y_train)\n",
    "print(clf_ridge.best_params_)\n",
    "get_score(clf_ridge,X_val,y_val)\n",
    "# 40.78025846231952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "clf_lasso = GridSearchCV(lasso, {'alpha': [1e-3,1e-2,1e-1,1,1e1,1e2,1e3]}, verbose=1)\n",
    "clf_lasso.fit(X_train,y_train)\n",
    "print(clf_lasso.best_params_)\n",
    "get_score(clf_lasso,X_val,y_val)\n",
    "# {'alpha': 100.0}\n",
    "# 40.78453998923231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lassolars  =  linear_model.LassoLars(alpha = 2)\n",
    "reg_lassolars.fit(X_train, y_train)\n",
    "get_score(reg_lassolars,X_val,y_val)\n",
    "# 40.775030093207896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dec_tree = DecisionTreeRegressor(max_depth=10, criterion = 'mae', max_features='sqrt',\n",
    "                                     random_state=5, min_samples_leaf = 12, min_samples_split = 2)\n",
    "reg_dec_tree.fit(X_train, y_train)\n",
    "get_score(reg_dec_tree,X_val,y_val)\n",
    "# 26.002284134401865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dec_tree = DecisionTreeRegressor()\n",
    "\n",
    "#clf_dec_tree = GridSearchCV(dec_tree, \n",
    "#                            {'criterion' : ['mae'], \n",
    "#                             'max_depth' : [2,4,6,8,10,12,14,16,18,20,22,24],\n",
    "#                             'min_samples_split' : [2,4,6,8,10], \n",
    "#                             'min_samples_leaf' : [2,4,6,8,10,12,14,16,18,20,22,24],\n",
    "#                             'max_features' : ['sqrt'], \n",
    "#                             'random_state' : [5]\n",
    "#                            }, verbose=1)\n",
    "#clf_dec_tree.fit(X_train,y_train)\n",
    "#print(clf_dec_tree.best_params_)\n",
    "#get_score(clf_dec_tree,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally intensive \n",
    "#KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "#KRR.fit(X_train, y_train)\n",
    "#get_score(KRR,X_val,y_val)\n",
    "\n",
    "# score = 33.473933712491295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very computationally expensive\n",
    "#BAYSR = BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, \n",
    "#                      compute_score=True, fit_intercept=True, normalize=True)\n",
    "#BAYSR.fit(X_train, y_train)\n",
    "#get_score(BAYSR,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_pickle('dataFrames/X_val.pkl')\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm', 'y_dec_tree', 'y_Random_forest', 'y_knn',\n",
    "             'y_elasticNet', 'y_ridge', 'y_lasso', 'y_AdaBoost', 'y_SVR']\n",
    "\n",
    "best_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm']\n",
    "best_pred = X_val[list(best_cols)]\n",
    "best_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pred_cols:\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.scatter(y_val, X_val[col])\n",
    "    plt.title('Price vs '+ col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing self stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(itertools.product([0, 1], repeat= len(best_cols)))\n",
    "\n",
    "opt_comb  = lst[0]\n",
    "opt_score = 1e500000\n",
    "\n",
    "for i in range(1,len(lst)):\n",
    "    A = lst[2**(len(best_cols))-i]\n",
    "    selected_cols = []\n",
    "    for i in range(len(best_cols)):\n",
    "        if A[i]:\n",
    "            selected_cols.append(best_cols[i])\n",
    "    Xstack = np.array(best_pred[selected_cols])\n",
    "    l1_stacked  = Lasso(alpha = 0.0001,fit_intercept = True)\n",
    "    l1_stacked.fit(Xstack, y_val)\n",
    "    l1_score = get_score(l1_stacked, Xstack, y_val)\n",
    "    \n",
    "    if l1_score < opt_score:\n",
    "        opt_score = l1_score\n",
    "        opt_comb = lst[i]\n",
    "    print(i, '%.2f' % l1_score, A )\n",
    "print(\"optimal choice: \", '%.2f' % opt_score, opt_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = lst[2**(len(best_cols))-1]\n",
    "selected_cols = []\n",
    "for i in range(len(best_cols)):\n",
    "    if A[i]:\n",
    "        selected_cols.append(best_cols[i])\n",
    "Xstack = np.array(best_pred[selected_cols])\n",
    "print(selected_cols)\n",
    "y_mean = np.mean(Xstack,axis=1)\n",
    "mean_absolute_precision_error(y_mean,y_val)\n",
    "\n",
    "# ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm']\n",
    "# 17.522228479312353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prod_avg = (Xstack[:,0]*Xstack[:,1]*Xstack[:,2]*Xstack[:,3])**(1.0/4.0)\n",
    "mean_absolute_precision_error(y_prod_avg,y_val)\n",
    "\n",
    "# 17.415549371458187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing stackingRegressor\n",
    "\n",
    "Look at the following link: https://www.kaggle.com/laurenstc/top-2-of-leaderboard-advanced-fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBF = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                          learning_rate=0.05, n_estimators=15000,\n",
    "                          max_bin = 1000, bagging_fraction = 0.6,\n",
    "                          bagging_freq = 5, feature_fraction = 0.25,\n",
    "                          feature_fraction_seed=9, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "GBSTF = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state =5)\n",
    "\n",
    "XGBF = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=1.7817, n_estimators=2200,\n",
    "                        reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                        subsample=0.5213, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "\n",
    "BAGF  = BaggingRegressor(n_estimators=100, max_samples=1.0, max_features=1.0, random_state=5, verbose=1)\n",
    "DECF  = DecisionTreeRegressor(max_depth=15)\n",
    "KNNF  = KNeighborsClassifier(2)\n",
    "LASSF = Lasso(fit_intercept = True)\n",
    "RDGF  = Ridge()\n",
    "ENTF  = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=3))\n",
    "\n",
    "models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF, \"dec_tree\": DECF, \n",
    "          \"knn\": KNNF, \"elasticNet\": ENTF, \"ridge\": RDGF, \"lasso\": LASSF}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_cols = X_train.columns.tolist()\n",
    "    X_val['y_' + model_name] = model.predict(X_val[train_cols])\n",
    "    score = mean_absolute_precision_error(X_val['y_' + model_name], y_val)\n",
    "    print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [XGBF, BAGF, LGBF]\n",
    "stregr     = StackingRegressor(regressors=regressors, meta_regressor=GBSTF)\n",
    "start_time = time.time()\n",
    "stregr.fit(X_train, y_train)\n",
    "y_pred = stregr.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stackingRegressor model\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "# stackingRegressor model 6.27 mins, score=  18.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [XGBF, BAGF, LGBF, DECF, KNNF, LASSF, RDGF, ENTF]\n",
    "stregr     = StackingRegressor(regressors=regressors, meta_regressor=GBSTF)\n",
    "start_time = time.time()\n",
    "stregr.fit(X_train, y_train)\n",
    "y_pred = stregr.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stackingRegressor model\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "# stackingRegressor model 7.62 mins, score=  19.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressors = [GBSTF, XGBF, BAGF, LGBF]\n",
    "#stregr     = StackingRegressor(regressors=regressors, meta_regressor=LASSF)\n",
    "\n",
    "#params = {'xgbregressor__n_estimators': [2000],#[100, 200, 500, 1000],\n",
    "#          'xgbregressor__max_depth': [8],#[2,4,8,16],\n",
    "#          'meta-gradientboostingregressor__n_estimators': [2000],#[100, 200, 500, 1000],\n",
    "#          'meta-gradientboostingregressor__max_depth': [48],#[2,4,8,16],\n",
    "#          'baggingregressor__base_estimator': [KNeighborsRegressor()]}#, DecisionTreeRegressor()]}\n",
    "\n",
    "#grid = GridSearchCV(estimator=stregr, \n",
    "#                    param_grid=params, \n",
    "#                    cv=3,\n",
    "#                    refit=True)\n",
    "#grid.fit(X_train, y_train)\n",
    "#print(grid.best_params_)\n",
    "#get_score(grid,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing another stacking method\n",
    "\n",
    "Look at the following link:\n",
    "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaged base models class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "averaged_models = AveragingModels(models = (XGBF, GBSTF, BAGF))\n",
    "averaged_models.fit(X_train, y_train)\n",
    "y_pred = averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"Average models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# Average models 7.45 mins, score=  17.54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Averaged models Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                #instance.fit(X[train_index], y[train_index])\n",
    "                instance.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "stacked_averaged_models  = StackingAveragedModels(base_models = (XGBF, BAGF), meta_model = GBSTF)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "y_pred = stacked_averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stacking Averaged models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# stacking Averaged models 13.63 mins, score=  18.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a new model for each Vehicle Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vTypes = set(all_data['vehicleType_ids'])\n",
    "all_vType     = {}\n",
    "final_models  = {}\n",
    "\n",
    "for i in vTypes:\n",
    "    tmp_vType = all_data[all_data['vehicleType_ids'] == i]\n",
    "    #tmp_vType = tmp_vType.drop(['vehicleType_ids'], axis=1)\n",
    "    all_vType[i] = tmp_vType\n",
    "    start_time = time.time()\n",
    "    vType_train = tmp_vType[tmp_vType['price'].notnull()]\n",
    "    vType_test  = tmp_vType[tmp_vType['price'].isnull()].drop(['price'], axis=1)\n",
    "    X = vType_train.drop(['ID','price', 'vehicleType_ids'],axis=1)\n",
    "    y = vType_train['price']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    if i != 1:\n",
    "        minSampleLeaf = 20 \n",
    "    else:\n",
    "        minSampleLeaf = 15\n",
    "    \n",
    "    if i != 3:\n",
    "        nEstimators = 1000\n",
    "        minSampleSplit = 4\n",
    "    else:\n",
    "        nEstimators = 1500\n",
    "        minSampleSplit = 2\n",
    "    \n",
    "    GBoost = GradientBoostingRegressor(learning_rate=0.1, max_features='sqrt', loss='huber',\n",
    "                                       min_samples_leaf=minSampleLeaf, min_samples_split=minSampleSplit, \n",
    "                                       n_estimators=nEstimators, max_depth=8, alpha = 0.7)\n",
    "    \n",
    "    GBoost.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"%.2f\" % float((time.time() - start_time)/60 ) +\" mins, vType: \",i, \", items: \", tmp_vType.shape[0],\n",
    "          \", loss: \", \"%.2f\" % get_score(GBoost,X_val,y_val))\n",
    "    \n",
    "    GB_Final = GradientBoostingRegressor(learning_rate=0.1, max_features='sqrt', loss='huber',\n",
    "                                         min_samples_leaf=minSampleLeaf, min_samples_split=minSampleSplit, \n",
    "                                         n_estimators=nEstimators, max_depth=8, alpha = 0.7)\n",
    "    \n",
    "    GB_Final.fit(X,y)\n",
    "    final_models[i] = GB_Final  \n",
    "    \n",
    "    #clf_GBoost = GridSearchCV(GBoost, \n",
    "    #                      {\n",
    "    #                       'min_samples_split': [2,4],\n",
    "    #                       'n_estimators': [1000,1500], \n",
    "    #                       'max_depth': [4,8],\n",
    "    #                       'min_samples_leaf': [20,15],\n",
    "    #                      },  verbose=2)\n",
    "\n",
    "    #clf_GBoost.fit(X_train,y_train)\n",
    "    #, best model: \", GBoost.get_params)# clf_GBoost.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission15.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")        \n",
    "    \n",
    "    for i in final_models.keys():\n",
    "        tmp_test0            = test[test['vehicleType_ids']==i]\n",
    "        tmp_test1            = tmp_test0.drop(['ID', 'price', 'vehicleType_ids'], axis=1)\n",
    "        tmp_model            = final_models[i]\n",
    "        tmp_test0['y_pred']  = tmp_model.predict(tmp_test1)\n",
    "    \n",
    "        for j in range(tmp_test0.shape[0]):\n",
    "            y_pred_test = tmp_test0.iloc[j]['y_pred'] \n",
    "            if y_pred_test < 0:\n",
    "                y_pred_test = min_price \n",
    "            outputfile.write(str(int(tmp_test0.iloc[j]['ID'] ))+\",\"+str(int(np.ceil(y_pred_test)))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a new model for each Vehicle Type and Vehicle Option ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats2 = all_data[['vehicleType_ids', 'vehicleOption_ids']].as_matrix().tolist()\n",
    "all_cats2 = [(x[0],x[1]) for x in all_cats2 ]\n",
    "all_cats2 = set(all_cats2)\n",
    "all_data_cat2 = {}\n",
    "\n",
    "for item in all_cats2:\n",
    "    tmp_data1 = all_data[all_data['vehicleType_ids'] == item[0]]\n",
    "    tmp_data2 = tmp_data1[tmp_data1['vehicleOption_ids'] == item[1]]\n",
    "    tmp_data = tmp_data2.drop(['vehicleType_ids', 'vehicleOption_ids'], axis=1)\n",
    "    all_data_cat2[item] = tmp_data\n",
    "    #print(item, tmp_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cat_shape2 = {}\n",
    "for x in all_data_cat2.keys():\n",
    "    \n",
    "    cat_df2    = all_data_cat2[x]\n",
    "    cat_train2 = cat_df2[cat_df2['price'].notnull()]\n",
    "    cat_test2  = cat_df2[cat_df2['price'].isnull()].drop(['price'], axis=1)\n",
    "    \n",
    "    all_data_cat_shape2[x] = (cat_train2.shape[0], cat_test2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sum = pd.DataFrame() \n",
    "for item in  [(1,6)]: # all_cats2: \n",
    "    start_time = time.time()\n",
    "    \n",
    "    cat_df2    = all_data_cat2[item]\n",
    "    cat_train2 = cat_df2[cat_df2['price'].notnull()]\n",
    "    cat_test2  = cat_df2[cat_df2['price'].isnull()].drop(['price'], axis=1)\n",
    "\n",
    "    X = cat_train2.drop(['ID','price'],axis=1)\n",
    "    y = cat_train2['price']\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #gboost_base = GradientBoostingRegressor()\n",
    "    #GBoost      = GridSearchCV(gboost_base,\n",
    "    #                   {'max_depth': [2,4,6,8,10,12],\n",
    "    #                    'n_estimators': [50,100,200,500,1000]}, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=2000, learning_rate=0.05,\n",
    "                                       max_depth=6, max_features='sqrt',\n",
    "                                       min_samples_leaf=8, min_samples_split=4, \n",
    "                                       loss='huber', random_state =5)\n",
    "\n",
    "    GBoost.fit(X_train, y_train)\n",
    "    #print(GBoost.best_params_)\n",
    "    #'destinationLatitude','destinationLongitude','sourceLatitude','sourceLongitude',\n",
    "    print(item, cat_df2.shape[0], \"%.2f\" % get_score(GBoost,X_val,y_val),\n",
    "          \"%.2f\" % float((time.time() - start_time)/60 )) \n",
    "\n",
    "\n",
    "#cat_test['pred_price'] = GBoost.predict(cat_test.drop(['ID'], axis=1))\n",
    "#cat_test['pred_price'] = cat_test['pred_price'].apply((lambda x: max(x, min_price) ))\n",
    "#test_sum = pd.concat([test_sum,cat_test])\n",
    "\n",
    "#test_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current best model \n",
    "start_time = time.time()\n",
    "Final = GradientBoostingRegressor(n_estimators=2200, learning_rate=0.05,\n",
    "                                   max_depth=10, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "Final.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "y_pred_test = Final.predict(test.drop(['ID','price'],axis=1))\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission17.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(y_pred_test.shape[0]):\n",
    "        if y_pred_test[i] < 0:\n",
    "            y_pred_test[i] = 100000 \n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_pred_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with high skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "#print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "#print(skewness.head(10))\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "#print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "#all_data[skewed_features] = np.log1p(all_data[skewed_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, (ay1, ay2) = plt.subplots(2, 1)\n",
    "\n",
    "\n",
    "ay1.scatter(x = X_train['sourceLatitude'], y = y_train, marker = \"+\")\n",
    "ay1.set_title('Price vs sourceLatitude')\n",
    "ay1.set_xlabel('sourceLatitude')\n",
    "ay1.set_ylabel('Price')\n",
    "\n",
    "ay2.scatter(x = X_train['sourceLongitude'], y = y_train, marker = \"+\")\n",
    "ay2.set_title('Price vs sourceLongitude')\n",
    "ay2.set_xlabel('sourceLongitude')\n",
    "ay2.set_ylabel('Price')\n",
    "\n",
    "fig1.set_size_inches(28.5, 10.5)\n",
    "fig1.savefig(\"/Users/mohsenkiskani/Downloads/Ubaar/plots/sourceEffects.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, (ay3, ay4) = plt.subplots(2, 1)\n",
    "\n",
    "\n",
    "ay3.scatter(x = X_train['destinationLatitude'], y = y_train, marker = \"+\")\n",
    "ay3.set_title('Price vs destinationLatitude')\n",
    "ay3.set_xlabel('destinationLatitude')\n",
    "ay3.set_ylabel('Price')\n",
    "\n",
    "ay4.scatter(x = X_train['destinationLongitude'], y = y_train, marker = \"+\")\n",
    "ay4.set_title('Price vs destinationLongitude')\n",
    "ay4.set_xlabel('destinationLongitude')\n",
    "ay4.set_ylabel('Price')\n",
    "\n",
    "fig2.set_size_inches(28.5, 10.5)\n",
    "fig2.savefig(\"/Users/mohsenkiskani/Downloads/Ubaar/plots/destinationEffects.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, (ay3, ay4, ay5) = plt.subplots(3, 1)\n",
    "\n",
    "\n",
    "ay3.scatter(x = X_train['distanceKM'], y = y_train, marker = \"+\")\n",
    "ay3.set_title('Price vs distanceKM')\n",
    "ay3.set_xlabel('distanceKM')\n",
    "ay3.set_ylabel('Price')\n",
    "\n",
    "ay4.scatter(x = X_train['taxiDurationMin'], y = y_train, marker = \"+\")\n",
    "ay4.set_title('Price vs taxiDurationMin')\n",
    "ay4.set_xlabel('taxiDurationMin')\n",
    "ay4.set_ylabel('Price')\n",
    "\n",
    "ay5.scatter(x = X_train['weight'], y = y_train, marker = \"+\")\n",
    "ay5.set_title('Price vs weight')\n",
    "ay5.set_xlabel('weight')\n",
    "ay5.set_ylabel('Price')\n",
    "\n",
    "fig3.set_size_inches(28.5, 10.5)\n",
    "fig3.savefig(\"/Users/mohsenkiskani/Downloads/Ubaar/plots/distance-time-Effects.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a154443c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a153eba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = data.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train , fit=norm);\n",
    "(mu, sigma) = norm.fit(y_train)\n",
    "\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_train, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lp = np.log1p(y_train)\n",
    "\n",
    "sns.distplot(y_train_lp, fit=norm);\n",
    "(mu, sigma) = norm.fit(y_train_lp)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(y_train_lp, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = data['date'].unique()\n",
    "date_price_vec = []\n",
    "\n",
    "for date in all_dates:\n",
    "    date_price_vec.append(np.mean(data.query('date == ' + str(date) ).price))\n",
    "    \n",
    "states = all_data['SourceState_ids'].unique()\n",
    "source_price_vec = []\n",
    "destin_price_vec = []\n",
    "\n",
    "for state in states:\n",
    "    source_price_vec.append(np.mean(data.query('date == ' + str(state) ).price))\n",
    "    destin_price_vec.append(np.mean(data.query('date == ' + str(state) ).price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, (ay1, ay2, ay3, ay4, ay5) = plt.subplots(5, 1)\n",
    "\n",
    "\n",
    "ay1.scatter(data.vehicleType, data.price, marker = \"+\")\n",
    "ay1.plot([0, 1, 2, 3], [np.mean(data.query('vehicleType == 0').price), np.mean(data.query('vehicleType == 1').price),\n",
    "         np.mean(data.query('vehicleType == 2').price), np.mean(data.query('vehicleType == 3').price)], 'r--')\n",
    "\n",
    "ay1.set_title('Price vs vehicle type')\n",
    "ay1.set_xlabel('Vehicle Type')\n",
    "ay1.set_ylabel('Price')\n",
    "\n",
    "\n",
    "ay2.scatter(data.vehicleOption, data.price, marker = \"+\")\n",
    "ay2.plot([0, 1, 2, 3, 4, 5, 6, 7, 8], [np.mean(data.query('vehicleOption == 0').price), \n",
    "                                       np.mean(data.query('vehicleOption == 1').price),\n",
    "                                       np.mean(data.query('vehicleOption == 2').price), \n",
    "                                       np.mean(data.query('vehicleOption == 3').price), \n",
    "                                       np.mean(data.query('vehicleOption == 4').price), \n",
    "                                       np.mean(data.query('vehicleOption == 5').price),\n",
    "                                       np.mean(data.query('vehicleOption == 6').price),\n",
    "                                       np.mean(data.query('vehicleOption == 7').price), \n",
    "                                       np.mean(data.query('vehicleOption == 8').price)], 'r--')\n",
    "\n",
    "\n",
    "ay2.set_title('Price vs vehicle option')\n",
    "ay2.set_xlabel('Vehicle Option')\n",
    "ay2.set_ylabel('Price')\n",
    "\n",
    "ay3.scatter(data.date, data.price, marker = \"+\")\n",
    "ay3.plot(all_dates, date_price_vec, 'r--')\n",
    "ay3.set_title('Price vs date')\n",
    "ay3.set_xlabel('Date')\n",
    "ay3.set_ylabel('Price')\n",
    "\n",
    "ay4.scatter(data.SourceState, data.price, marker = \"+\")\n",
    "ay4.plot(states, source_price_vec, 'r--')\n",
    "ay4.set_title('Price vs source state')\n",
    "ay4.set_xlabel('Date')\n",
    "ay4.set_ylabel('Price')\n",
    "\n",
    "ay5.scatter(data.destinationState, data.price, marker = \"+\")\n",
    "ay5.plot(states, destin_price_vec, 'r--')\n",
    "ay5.set_title('Price vs destination state')\n",
    "ay5.set_xlabel('Date')\n",
    "ay5.set_ylabel('Price')\n",
    "\n",
    "fig1.set_size_inches(28.5, 10.5)\n",
    "fig1.savefig(\"/Users/mohsenkiskani/Downloads/Ubaar/plots/categoryEffects.png\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features are most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.scatter(train[col], train['price'])\n",
    "    plt.title('Price vs '+ col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(train['destinationLatitude'], train['destinationLongitude'], train['price'], c='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(train['sourceLatitude'], train['sourceLongitude'], train['price'], c='g', marker='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['distanceKM'])\n",
    "sns.kdeplot(train['taxiDurationMin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['date_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['vehicleOption_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train['vehicleOption_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['vehicleType_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train['vehicleType_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['source_tuple_ids'])\n",
    "sns.kdeplot(train['destination_tuple_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(train['SourceState_ids'])\n",
    "sns.kdeplot(train['destinationState_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features are the most important in each model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBF = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.05, max_depth=10, \n",
    "                        min_child_weight=1.7817, n_estimators=2200,\n",
    "                        reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                        subsample=0.5213, silent=1, seed = 10,\n",
    "                        random_state =5 , nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBF.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(XGBF.feature_importances_, X_train.columns.values)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBF = lgb.LGBMRegressor(objective='regression',num_leaves=15,\n",
    "                          learning_rate=0.05, n_estimators=15000,\n",
    "                          max_bin = 1000, bagging_fraction = 0.6,\n",
    "                          bagging_freq = 5, feature_fraction = 0.25,\n",
    "                          feature_fraction_seed=9, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBF.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(LGBF.feature_importances_, X_train.columns.values)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBSTF = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBSTF.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(GBSTF.feature_importances_, X_train.columns.values)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
