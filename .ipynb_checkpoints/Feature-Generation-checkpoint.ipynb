{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import datetime\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge, LinearRegression\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_func(labels, preds):\n",
    "    return np.mean(np.abs((preds - labels)/(labels))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data      = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Remove NANs\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "# Remove outliers\n",
    "data.drop([28098])\n",
    "THRESHOLD = 4.5e7\n",
    "Aa = data[data.price > THRESHOLD]\n",
    "data = data.drop(Aa.index.tolist())\n",
    "\n",
    "specific_cols = ['distanceKM', 'taxiDurationMin', 'weight']\n",
    "removed_indices = []\n",
    "for col in specific_cols:\n",
    "    df = data['price']/data[col]\n",
    "    A = df[~df.isin([np.nan, np.inf, -np.inf])]\n",
    "    B = (A - np.mean(A)) / np.std(A)\n",
    "    V = B[B > 5]\n",
    "    removed_indices.extend(V.index.tolist())\n",
    "data = data.drop(set(removed_indices))\n",
    "\n",
    "# Fill test NANs\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "feat_names = all_data.columns.tolist()\n",
    "feat_names.remove('ID')\n",
    "feat_names.remove('price')\n",
    "\n",
    "\n",
    "#train = pd.read_pickle('dataFrames/train_updated_June27.pkl')\n",
    "#test  = pd.read_pickle('dataFrames/test_updated_June27.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(dict)\n",
    "\n",
    "def benchmark(est, name=None, cv=False):\n",
    "    if not name:\n",
    "        name = est.__class__.__name__\n",
    "    print(\"Started benchmarking    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    if not cv:\n",
    "        t0 = time.time()\n",
    "        est.fit(X_train, y_train)\n",
    "        res[name]['train_time'] = (time.time() - t0)/60\n",
    "        t0 = time.time()\n",
    "        pred = est.predict(X_val)\n",
    "        res[name]['test_time'] = (time.time() - t0)/60\n",
    "        res[name]['MAPE'] = mape_func(y_val, pred)\n",
    "    else:\n",
    "        t0 = time.time()\n",
    "        res[name]['cv_score'] = np.mean(model_selection.cross_val_score(est, X, y, scoring=mape_score, cv = 3))\n",
    "        res[name]['cv_time'] = (time.time() - t0)/60\n",
    "    print(\"Done benchmarking       \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_info_train = defaultdict(dict)\n",
    "\n",
    "def train_feat_generate(est, name=None, split_number=5):\n",
    "    if not name:\n",
    "        name = est.__class__.__name__\n",
    "    print(\"Started generating feature    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    global train \n",
    "    train = shuffle(train)\n",
    "    A = np.array_split(train, split_number)\n",
    "    t0 = time.time()\n",
    "    for i in range(split_number):\n",
    "        print('Started count   ', i, '    ',  datetime.datetime.now())\n",
    "        df_train = pd.concat([A[x] for x in range(split_number) if x!=i])\n",
    "        est.fit(df_train[feat_names], df_train.price)\n",
    "        A[i][name] = est.predict(A[i][feat_names])\n",
    "        train = pd.concat([df_train, A[i]])\n",
    "        print('Done with count ', i,'    ', datetime.datetime.now())\n",
    "    generation_info_train[name]['generation_time'] = (time.time() - t0)/60\n",
    "    print(\"Done generating feature       \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    return train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_info_test = defaultdict(dict)\n",
    "\n",
    "def test_feat_generate(est, name=None):\n",
    "    if not name:\n",
    "        name = est.__class__.__name__\n",
    "    print(\"Started generating test feature    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    global train\n",
    "    global test \n",
    "    train = shuffle(train)\n",
    "    t0 = time.time()\n",
    "    est.fit(train[feat_names], train.price)\n",
    "    test[name] = est.predict(test[feat_names])\n",
    "    generation_info_test[name]['generation_time'] = (time.time() - t0)/60\n",
    "    print(\"Done generating test feature       \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    return test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge        = Ridge(alpha=0.0001, normalize=True)\n",
    "knn          = KNeighborsRegressor(2)\n",
    "lasso        = Lasso(fit_intercept = True, random_state=5)\n",
    "enet         = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=5))\n",
    "xgboosting   = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "gboosting    = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 42)\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=800, max_features=17, random_state=5, bootstrap=False, n_jobs=10)\n",
    "extraTree    = ExtraTreesRegressor(n_estimators=3000, max_features=23, random_state=5, bootstrap=False, n_jobs=4)\n",
    "adaBoost     = AdaBoostRegressor(n_estimators=600, learning_rate=0.01, loss='exponential', random_state=5)\n",
    "decTree      = DecisionTreeRegressor( splitter='best', max_depth=16, min_samples_split=20, \n",
    "                             min_samples_leaf=10, min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                             random_state=5, max_leaf_nodes=None,  presort=False)\n",
    "bagging      = BaggingRegressor(n_estimators=600, max_samples=1.0, max_features=0.9, random_state=5, verbose=1)\n",
    "lightgbm     = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.01, n_estimators=60000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "cb_model = CatBoostRegressor(iterations=1200, learning_rate=0.1, depth=15, eval_metric='MAPE', random_seed = 7,\n",
    "                             bagging_temperature = 1.5, od_type='Iter', metric_period = 100, od_wait=20)\n",
    "\n",
    "models = [ridge, knn, lasso, enet, xgboosting, gboosting, lightgbm, bagging, decTree, \n",
    "          adaBoost, extraTree, randomForest, cb_model]\n",
    "\n",
    "models = [cb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    train = train_feat_generate(model)\n",
    "    train.to_pickle('dataFrames/train_updated_June27.pkl')\n",
    "    train.to_csv('dataFrames/train_updated_June27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    test = test_feat_generate(model)\n",
    "    test.to_pickle('dataFrames/test_updated_June27.pkl')\n",
    "    test.to_csv('dataFrames/test_updated_June27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_func(train.price, train.CatBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor#, StackingCVRegressor\n",
    "\n",
    "stack_gen = StackingRegressor(regressors=(randomForest, extraTree, decTree, bagging,  \n",
    "                                          gboosting, xgboosting, lightgbm, cb_model), \n",
    "                               meta_regressor=gboosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(train)\n",
    "split_number=3\n",
    "A = np.array_split(train, split_number)\n",
    "t0 = time.time()\n",
    "\n",
    "name = \"Stack-gen-fewer\"\n",
    "\n",
    "print(\"Started generating feature    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "for i in range(split_number):\n",
    "    print('Started count   ', i, '    ',  datetime.datetime.now())\n",
    "    df_train = pd.concat([A[x] for x in range(split_number) if x!=i])\n",
    "    stack_gen.fit(df_train[feat_names].as_matrix(), df_train.price.as_matrix())\n",
    "    A[i][name] = stack_gen.predict(A[i][feat_names].as_matrix())\n",
    "    train = pd.concat([df_train, A[i]])\n",
    "    print('Done with count ', i,'    ', datetime.datetime.now())\n",
    "    \n",
    "print(\"Done generating feature       \" + name + \"        at time: \", datetime.datetime.now())\n",
    "\n",
    "\n",
    "res_stack_gen = defaultdict(dict)\n",
    "res_stack_gen[name]['train_generation_time'] =  (time.time() - t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Started generating test feature    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "train = shuffle(train)\n",
    "t0 = time.time()\n",
    "stack_gen.fit(train[feat_names].as_matrix(), train.price.as_matrix())\n",
    "test[name] = stack_gen.predict(test[feat_names].as_matrix())\n",
    "res_stack_gen[name]['test_generation_time'] = (time.time() - t0)/60\n",
    "print(\"Done generating test feature       \" + name + \"        at time: \", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('dataFrames/train_updated_June29.pkl')\n",
    "train.to_csv('dataFrames/train_updated_June29.csv')\n",
    "test.to_pickle('dataFrames/test_updated_June29.pkl')\n",
    "test.to_csv('dataFrames/test_updated_June29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_func(train.price, train.StackingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_func(train.price, train.Stack-gen-fewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "res_stack_gen[name]['test_time'] = (time.time() - t0)/60\n",
    "res_stack_gen[name]['MAPE'] = mape_func(y_val, pred)\n",
    "\n",
    "res_stack_gen_df = pd.DataFrame(data=res).T\n",
    "res_stack_gen_df.to_pickle('dataFrames/benchmarking_results_stack_gen.pkl')\n",
    "res_stack_gen_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lgbm_xgb  = StackingAveragedModels(base_models = (lightgbm, xgboosting), meta_model = ridge)\n",
    "\n",
    "train = train_feat_generate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_averaged_models  = StackingAveragedModels(base_models = (xgboosting, randomForest), meta_model = ridge)\n",
    "stacked_averaged_models  = StackingAveragedModels(base_models = (lightgbm, extraTree), meta_model = ridge)\n",
    "stacking_regressor       = StackingRegressor(regressors=[xgboosting, randomForest], meta_regressor = ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
