{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import datetime\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def fitmodel(model, X_tr, y_tr, X_v, y_v):\n",
    "    start_time = time.time()\n",
    "    print(datetime.datetime.now())\n",
    "    model.fit(X_tr,y_tr)\n",
    "    y_pred = model.predict(X_v)\n",
    "    score = np.mean(np.abs((y_v - y_pred) / y_v)) * 100\n",
    "    print( '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "    #return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>SourceState_آذربایجان شرقی</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleType_treili</th>\n",
       "      <th>vehicleOption_bari</th>\n",
       "      <th>vehicleOption_hichkodam</th>\n",
       "      <th>vehicleOption_kafi</th>\n",
       "      <th>vehicleOption_kompressi</th>\n",
       "      <th>vehicleOption_labehdar</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>36.297494</td>\n",
       "      <td>59.605923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.297494</td>\n",
       "      <td>59.605923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2163.545632</td>\n",
       "      <td>2163.545632</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21290</th>\n",
       "      <td>36.301404</td>\n",
       "      <td>59.606267</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>28.502316</td>\n",
       "      <td>53.556507</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1526.484486</td>\n",
       "      <td>2163.791179</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>36.293036</td>\n",
       "      <td>59.604464</td>\n",
       "      <td>615.0</td>\n",
       "      <td>36.839502</td>\n",
       "      <td>54.428057</td>\n",
       "      <td>457.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005.102515</td>\n",
       "      <td>2163.226958</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40708</th>\n",
       "      <td>30.397047</td>\n",
       "      <td>55.996670</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>36.653551</td>\n",
       "      <td>51.497869</td>\n",
       "      <td>754.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1887.579768</td>\n",
       "      <td>1702.133410</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45211</th>\n",
       "      <td>34.796312</td>\n",
       "      <td>46.931152</td>\n",
       "      <td>62.0</td>\n",
       "      <td>34.326654</td>\n",
       "      <td>47.068694</td>\n",
       "      <td>58.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1615.710773</td>\n",
       "      <td>1633.031008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destinationLatitude  destinationLongitude  distanceKM  sourceLatitude  \\\n",
       "3144             36.297494             59.605923         0.0       36.297494   \n",
       "21290            36.301404             59.606267      1451.0       28.502316   \n",
       "19568            36.293036             59.604464       615.0       36.839502   \n",
       "40708            30.397047             55.996670      1066.0       36.653551   \n",
       "45211            34.796312             46.931152        62.0       34.326654   \n",
       "\n",
       "       sourceLongitude  taxiDurationMin  weight       source  destination  \\\n",
       "3144         59.605923              0.0    22.0  2163.545632  2163.545632   \n",
       "21290        53.556507           1031.0     4.0  1526.484486  2163.791179   \n",
       "19568        54.428057            457.0     4.0  2005.102515  2163.226958   \n",
       "40708        51.497869            754.0     2.1  1887.579768  1702.133410   \n",
       "45211        47.068694             58.0    25.0  1615.710773  1633.031008   \n",
       "\n",
       "       SourceState_آذربایجان شرقی           ...             \\\n",
       "3144                            0           ...              \n",
       "21290                           0           ...              \n",
       "19568                           0           ...              \n",
       "40708                           0           ...              \n",
       "45211                           0           ...              \n",
       "\n",
       "       vehicleType_treili  vehicleOption_bari  vehicleOption_hichkodam  \\\n",
       "3144                    1                   0                        0   \n",
       "21290                   0                   0                        0   \n",
       "19568                   0                   0                        1   \n",
       "40708                   0                   0                        0   \n",
       "45211                   1                   0                        0   \n",
       "\n",
       "       vehicleOption_kafi  vehicleOption_kompressi  vehicleOption_labehdar  \\\n",
       "3144                    0                        0                       0   \n",
       "21290                   0                        0                       0   \n",
       "19568                   0                        0                       0   \n",
       "40708                   0                        0                       0   \n",
       "45211                   1                        0                       0   \n",
       "\n",
       "       vehicleOption_mosaghaf_chadori  vehicleOption_mosaghaf_felezi  \\\n",
       "3144                                0                              0   \n",
       "21290                               0                              0   \n",
       "19568                               0                              0   \n",
       "40708                               1                              0   \n",
       "45211                               0                              0   \n",
       "\n",
       "       vehicleOption_transit_chadori  vehicleOption_yakhchali  \n",
       "3144                               1                        0  \n",
       "21290                              0                        1  \n",
       "19568                              0                        0  \n",
       "40708                              0                        0  \n",
       "45211                              0                        0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "# Remove NANs\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "# Remove outliers\n",
    "data.drop([28098])\n",
    "THRESHOLD = 3.5e7\n",
    "Aa = data[data.price > THRESHOLD]\n",
    "data = data.drop(Aa.index.tolist())\n",
    "\n",
    "specific_cols = ['distanceKM', 'taxiDurationMin', 'weight']\n",
    "removed_indices = []\n",
    "for col in specific_cols:\n",
    "    df = data['price']/data[col]\n",
    "    A = df[~df.isin([np.nan, np.inf, -np.inf])]\n",
    "    B = (A - np.mean(A)) / np.std(A)\n",
    "    V = B[B > 5]\n",
    "    removed_indices.extend(V.index.tolist())\n",
    "data = data.drop(set(removed_indices))\n",
    "\n",
    "# Fill test NANs\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "X = train.drop(['ID','price'],axis=1)\n",
    "y = train.price\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm0 = GradientBoostingRegressor(random_state=5, learning_rate=0.1,  min_samples_leaf = 1,  \n",
    "#                                 max_features = 'sqrt', n_estimators = 170, loss='huber')\n",
    "#param_test1 = {'min_samples_split':range(200,1001,200),\n",
    "#              'max_depth':range(40,70,10)}\n",
    "#gsearch1 = GridSearchCV(estimator = gbm0, param_grid = param_test1, cv = 2)\n",
    "#modelfit(gbm0, X_train, y_train , X_val, y_val, printFeatureImportance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb0 = xgb.XGBRegressor(colsample_bytree=.8,  \n",
    "#                        learning_rate=0.1, max_depth=12, \n",
    "#                        n_estimators=200,\n",
    "#                        random_state =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbstf0 = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb0 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb0 = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.01, n_estimators=60000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-14 19:09:20.082256\n",
      "lgb0 5.97 mins, score=  17.33\n",
      "2018-06-14 19:15:17.991234\n",
      "xgb0 24.90 mins, score=  17.36\n"
     ]
    }
   ],
   "source": [
    "LGBF = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.01, n_estimators=60000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "GBSTF = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 42)\n",
    "\n",
    "XGBF = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "\n",
    "BAGF  = BaggingRegressor(n_estimators=100, max_samples=1.0, max_features=1.0, random_state=5, verbose=1)\n",
    "\n",
    "DECF  = DecisionTreeRegressor(max_depth=15)\n",
    "RFSTF = RandomForestRegressor(n_estimators=20, criterion='mae', \n",
    "                              max_depth=4, max_features='sqrt',\n",
    "                              min_samples_leaf=5, min_samples_split =3, random_state = 42)\n",
    "\n",
    "KNNF  = KNeighborsClassifier(2)\n",
    "LASSF = Lasso(fit_intercept = True)\n",
    "ABSTF = AdaBoostRegressor(n_estimators=1000, learning_rate=0.05, loss='linear', random_state=5)\n",
    "\n",
    "SVRF = SVR()\n",
    "RDGF = Ridge()\n",
    "ENTF = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=3))\n",
    "\n",
    "models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF, \"dec_tree\": DECF, \"Random_forest\": RFSTF,\n",
    "          \"knn\": KNNF, \"elasticNet\": ENTF, \"ridge\": RDGF, \"lasso\": LASSF, \"AdaBoost\": ABSTF, \"SVR\": SVRF}\n",
    "\n",
    "#models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF}\n",
    " \n",
    "models = {\"lgb0\": lgb0, \"xgb0\": xgb0, \"gbstf0\": gbstf0}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    start_time = time.time()\n",
    "    print(datetime.datetime.now())\n",
    "    model.fit(X_train, y_train)\n",
    "    train_cols = X_train.columns.tolist()\n",
    "    X_val['y_' + model_name] = model.predict(X_val[train_cols])\n",
    "    score = mean_absolute_precision_error(X_val['y_' + model_name], y_val)\n",
    "    print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "\n",
    "#X_val.to_pickle('dataFrames/One_Hot_X_val.pkl')\n",
    "\n",
    "# Correct outputs are as followed\n",
    "\n",
    "#Gboost        23.55 mins, score=  16.76\n",
    "#xgb           25.40 mins, score=  17.36\n",
    "#bagging       0.83  mins, score=  18.82\n",
    "#lgbm          5.92  mins, score=  17.33\n",
    "#dec_tree      0.01  mins, score=  22.44\n",
    "#Random_forest 5.56  mins, score=  39.04\n",
    "#knn           0.02  mins, score=  24.62\n",
    "#elasticNet    0.01  mins, score=  34.81\n",
    "#ridge         0.00  mins, score=  36.68\n",
    "#lasso         0.10  mins, score=  36.63\n",
    "#AdaBoost      2.58  mins, score=  67.02\n",
    "#SVR           2.94  mins, score=  72.61\n",
    "# KernelRidge and LinearRegression() take more than 1 hour to run! Don't Run them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='huber', max_depth=10,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=15, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=15000,\n",
       "             presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbstf0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb0 157.07 mins, score=  16.76\n"
     ]
    }
   ],
   "source": [
    "train_cols = X_train.columns.tolist()\n",
    "X_val['y_avg_boost'] = gbstf0.predict(X_val[train_cols])\n",
    "score = mean_absolute_precision_error(X_val['y_avg_boost'], y_val)\n",
    "print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['y_gbstf0'] =  gbstf0.predict(X_val[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>SourceState_آذربایجان شرقی</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleOption_kompressi</th>\n",
       "      <th>vehicleOption_labehdar</th>\n",
       "      <th>vehicleOption_mosaghaf_chadori</th>\n",
       "      <th>vehicleOption_mosaghaf_felezi</th>\n",
       "      <th>vehicleOption_transit_chadori</th>\n",
       "      <th>vehicleOption_yakhchali</th>\n",
       "      <th>y_lgb0</th>\n",
       "      <th>y_xgb0</th>\n",
       "      <th>y_avg_boost</th>\n",
       "      <th>y_gbstf0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>35.626900</td>\n",
       "      <td>52.155742</td>\n",
       "      <td>506.0</td>\n",
       "      <td>32.800696</td>\n",
       "      <td>51.699130</td>\n",
       "      <td>327.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1695.767447</td>\n",
       "      <td>1858.147405</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.472644e+06</td>\n",
       "      <td>5.927568e+06</td>\n",
       "      <td>5.826879e+06</td>\n",
       "      <td>5.826879e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15353</th>\n",
       "      <td>31.890439</td>\n",
       "      <td>54.365067</td>\n",
       "      <td>711.0</td>\n",
       "      <td>36.044303</td>\n",
       "      <td>50.537302</td>\n",
       "      <td>456.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1821.581826</td>\n",
       "      <td>1733.725853</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.404189e+06</td>\n",
       "      <td>4.183810e+06</td>\n",
       "      <td>4.119352e+06</td>\n",
       "      <td>4.119352e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20645</th>\n",
       "      <td>33.636871</td>\n",
       "      <td>46.425809</td>\n",
       "      <td>905.0</td>\n",
       "      <td>32.252003</td>\n",
       "      <td>54.014301</td>\n",
       "      <td>700.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1742.069398</td>\n",
       "      <td>1561.618948</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.665581e+07</td>\n",
       "      <td>1.655836e+07</td>\n",
       "      <td>1.611458e+07</td>\n",
       "      <td>1.611458e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32807</th>\n",
       "      <td>29.610726</td>\n",
       "      <td>52.542440</td>\n",
       "      <td>216.0</td>\n",
       "      <td>28.863114</td>\n",
       "      <td>54.160527</td>\n",
       "      <td>168.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1563.241465</td>\n",
       "      <td>1555.819794</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.416599e+06</td>\n",
       "      <td>1.462954e+06</td>\n",
       "      <td>1.409869e+06</td>\n",
       "      <td>1.409869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28418</th>\n",
       "      <td>27.176657</td>\n",
       "      <td>56.275919</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>35.699569</td>\n",
       "      <td>51.395840</td>\n",
       "      <td>836.0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1834.809336</td>\n",
       "      <td>1529.391348</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.866195e+06</td>\n",
       "      <td>6.833764e+06</td>\n",
       "      <td>6.698271e+06</td>\n",
       "      <td>6.698271e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       destinationLatitude  destinationLongitude  distanceKM  sourceLatitude  \\\n",
       "6273             35.626900             52.155742       506.0       32.800696   \n",
       "15353            31.890439             54.365067       711.0       36.044303   \n",
       "20645            33.636871             46.425809       905.0       32.252003   \n",
       "32807            29.610726             52.542440       216.0       28.863114   \n",
       "28418            27.176657             56.275919      1279.0       35.699569   \n",
       "\n",
       "       sourceLongitude  taxiDurationMin  weight       source  destination  \\\n",
       "6273         51.699130            327.0   15.00  1695.767447  1858.147405   \n",
       "15353        50.537302            456.0    3.00  1821.581826  1733.725853   \n",
       "20645        54.014301            700.0   24.00  1742.069398  1561.618948   \n",
       "32807        54.160527            168.0    4.00  1563.241465  1555.819794   \n",
       "28418        51.395840            836.0    8.33  1834.809336  1529.391348   \n",
       "\n",
       "       SourceState_آذربایجان شرقی      ...       vehicleOption_kompressi  \\\n",
       "6273                            0      ...                             0   \n",
       "15353                           0      ...                             0   \n",
       "20645                           0      ...                             0   \n",
       "32807                           0      ...                             0   \n",
       "28418                           0      ...                             0   \n",
       "\n",
       "       vehicleOption_labehdar  vehicleOption_mosaghaf_chadori  \\\n",
       "6273                        0                               0   \n",
       "15353                       0                               1   \n",
       "20645                       0                               0   \n",
       "32807                       0                               0   \n",
       "28418                       0                               0   \n",
       "\n",
       "       vehicleOption_mosaghaf_felezi  vehicleOption_transit_chadori  \\\n",
       "6273                               0                              0   \n",
       "15353                              0                              0   \n",
       "20645                              0                              0   \n",
       "32807                              1                              0   \n",
       "28418                              0                              0   \n",
       "\n",
       "       vehicleOption_yakhchali        y_lgb0        y_xgb0   y_avg_boost  \\\n",
       "6273                         0  6.472644e+06  5.927568e+06  5.826879e+06   \n",
       "15353                        0  4.404189e+06  4.183810e+06  4.119352e+06   \n",
       "20645                        0  1.665581e+07  1.655836e+07  1.611458e+07   \n",
       "32807                        0  1.416599e+06  1.462954e+06  1.409869e+06   \n",
       "28418                        0  6.866195e+06  6.833764e+06  6.698271e+06   \n",
       "\n",
       "           y_gbstf0  \n",
       "6273   5.826879e+06  \n",
       "15353  4.119352e+06  \n",
       "20645  1.611458e+07  \n",
       "32807  1.409869e+06  \n",
       "28418  6.698271e+06  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_e = (X_val['y_lgb0'] + X_val['y_xgb0'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h = ( X_val['y_xgb0'] * X_val['y_gbstf0'])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.805865324960063"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = mean_absolute_precision_error(X_h, y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_pickle('dataFrames/One_Hot_X_val_new.pkl')\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm', 'y_dec_tree', 'y_Random_forest', 'y_knn',\n",
    "             'y_elasticNet', 'y_ridge', 'y_lasso', 'y_AdaBoost', 'y_SVR']\n",
    "\n",
    "best_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm']\n",
    "best_pred = X_val[list(best_cols)]\n",
    "best_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pred_cols:\n",
    "    plt.scatter(X_val[col],y_val)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel(col)\n",
    "    plt.title('Prediction vs Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackingRegressor model 43.59 mins, score=  18.15\n"
     ]
    }
   ],
   "source": [
    "regressors = [lgb0, xgb0]\n",
    "stregr     = StackingRegressor(regressors=regressors, meta_regressor=gbstf0)\n",
    "start_time = time.time()\n",
    "stregr.fit(X_train, y_train)\n",
    "y_pred = stregr.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stackingRegressor model\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "# stackingRegressor model 43.59 mins, score=  18.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=3):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                #instance.fit(X[train_index], y[train_index])\n",
    "                instance.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking Averaged models 79.53 mins, score = 17.95\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "stacked_averaged_models  = StackingAveragedModels(base_models = (lgb0, xgb0), meta_model = gbstf0)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "y_pred = stacked_averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stacking Averaged models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# stacking Averaged models 79.53 mins, score = 17.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average models 30.67 mins, score = 17.01\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "averaged_models = AveragingModels(models = (xgb0, lgb0))\n",
    "averaged_models.fit(X_train, y_train)\n",
    "train_cols = X_train.columns.tolist()\n",
    "y_pred = averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"Average models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# Average models 30.67 mins, score=  17.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current best model \n",
    "start_time = time.time()\n",
    "GBST = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state =5)\n",
    "\n",
    "GBST.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "y_pred_test = GBST.predict(test.drop(['ID','price'],axis=1))\n",
    "\n",
    "print('%.2f' % float((time.time() - start_time)/60 ) +\" mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission32.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(y_pred_test.shape[0]):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_pred_test[i])))+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
