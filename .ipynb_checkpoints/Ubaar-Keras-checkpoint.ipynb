{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE   = 25 \n",
    "EPOCHS       = 1000 \n",
    "LAYER_1_SIZE = 1024\n",
    "LAYER_2_SIZE = 1024\n",
    "LAYER_3_SIZE = 1024\n",
    "LAYER_4_SIZE = 64\n",
    "\n",
    "FEATURE_TYPE = 'pred'  # 'cont' 'pred' 'all'\n",
    "SEED         = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test   = pd.read_pickle('dataFrames/test_OneHotEncoding_new_June14th.pkl')\n",
    "train  = pd.read_pickle('dataFrames/train_OneHotEncoding_new_June14th.pkl')\n",
    "\n",
    "continuous_cols = ['destinationLatitude', 'destinationLongitude', 'distanceKM', 'sourceLatitude', \n",
    "                   'sourceLongitude', 'taxiDurationMin', 'weight', 'source', 'destination', \n",
    "                   'y_avg_lgb_xgb','y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec', 'y_lgb' ]\n",
    "\n",
    "pred_cols = ['y_avg_lgb_xgb','y_gboost','y_xgb','y_bag','y_knn','y_dec','y_lgb']\n",
    "\n",
    "pred_cols = [ 'y_gboost', 'y_xgb', 'y_lgb']\n",
    "\n",
    "categorical_cols = train.columns.drop(continuous_cols + ['ID', 'price']).tolist()\n",
    "\n",
    "NOM = train[categorical_cols].shape[1]\n",
    "renaming_dict = dict(zip(train[categorical_cols].columns, [str(x) for x in list(range(NOM)) ]))\n",
    "\n",
    "train_renamed = train[categorical_cols].rename(columns=renaming_dict)\n",
    "test_renamed  = test[categorical_cols].rename(columns=renaming_dict)\n",
    "\n",
    "for column in continuous_cols:\n",
    "    train_renamed[column] = train[column]\n",
    "    test_renamed[column] = test[column]\n",
    "    \n",
    "test_renamed['ID']   = test['ID']\n",
    "train_renamed['ID'] = train['ID']\n",
    "test_renamed['price'] = test['price']\n",
    "train_renamed['price'] = train['price']\n",
    "\n",
    "X_train, X_val = train_test_split(train_renamed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_TYPE=='all':\n",
    "    X_input_train = X_train.drop(['ID','price'], axis=1)\n",
    "    X_input_val   = X_val.drop(['ID','price'], axis=1)\n",
    "    train_input   = train_renamed.drop(['ID','price'], axis=1)\n",
    "    test_input   = test_renamed.drop(['ID','price'], axis=1)\n",
    "elif FEATURE_TYPE=='cont':\n",
    "    X_input_train = X_train[continuous_cols]\n",
    "    X_input_val   = X_val[continuous_cols]\n",
    "    train_input   = train_renamed[continuous_cols]\n",
    "    test_input    = test_renamed[continuous_cols]\n",
    "elif FEATURE_TYPE=='pred':\n",
    "    X_input_train = X_train[pred_cols]\n",
    "    X_input_val   = X_val[pred_cols]\n",
    "    train_input   = train_renamed[continuous_cols]\n",
    "    test_input    = test_renamed[continuous_cols]\n",
    "\n",
    "INPUT_SHAPE  = X_input_train.shape[1]\n",
    "y_input_train = X_train.price\n",
    "\n",
    "seed = SEED\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(LAYER_1_SIZE, input_dim=INPUT_SHAPE, init='normal', activation='relu'))\n",
    "    model.add(Dense(LAYER_2_SIZE, init='normal', activation='relu'))\n",
    "    model.add(Dense(LAYER_3_SIZE, init='normal', activation='relu'))\n",
    "    model.add(Dense(LAYER_4_SIZE, init='normal', activation='relu'))\n",
    "    #model.add(Dense(LAYER_5_SIZE, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    model.compile(loss=MAPE_loss, optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_val = KerasRegressor(build_fn=base_model,  batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_val.fit(X_input_train,y_input_train)\n",
    "preds_val = clf_val.predict(X_input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_absolute_precision_error(preds_val, X_val.price)\n",
    "print('%.2f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "49534/49534 [==============================] - 28s 561us/step - loss: 17.2582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a201bc7f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE  = train_input.shape[1]\n",
    "clf = KerasRegressor(build_fn=base_model, nb_epoch=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "clf.fit(train_input,train_renamed.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = clf.predict(X_input_val)\n",
    "score  = mean_absolute_precision_error(preds2, X_val.price)\n",
    "print('%.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 86us/step\n"
     ]
    }
   ],
   "source": [
    "preds          = clf.predict(test_input)\n",
    "y_preds_test   = [int(x) for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission51.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
