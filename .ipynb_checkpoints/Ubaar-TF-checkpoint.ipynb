{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 128\n",
    "TRAIN_EPOCHS        = 7000\n",
    "BIN_GRANULARITY     = 100\n",
    "HIDDEN_LAYER_1_SIZE = 256\n",
    "HIDDEN_LAYER_2_SIZE = 256\n",
    "HIDDEN_LAYER_3_SIZE = 16\n",
    "lr                  = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def scale_minmax(col):\n",
    "    return (col-col.min())/(col.max()-col.min())\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the following link:\n",
    "https://www.kaggle.com/mmmarcy/tensorflow-dnn-regressor-with-feature-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>SourceState_ids</th>\n",
       "      <th>destinationState_ids</th>\n",
       "      <th>vehicleType_ids</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23990</th>\n",
       "      <td>18426018643</td>\n",
       "      <td>32.669957</td>\n",
       "      <td>51.670529</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>39.344206</td>\n",
       "      <td>45.064755</td>\n",
       "      <td>766.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1773.037004</td>\n",
       "      <td>1688.073961</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>767</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>68800274778</td>\n",
       "      <td>31.318349</td>\n",
       "      <td>48.681923</td>\n",
       "      <td>467.0</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>32.325773</td>\n",
       "      <td>50.847471</td>\n",
       "      <td>404.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1643.683805</td>\n",
       "      <td>1524.637455</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>273</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>80477779395</td>\n",
       "      <td>38.550434</td>\n",
       "      <td>44.953540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>38.550434</td>\n",
       "      <td>44.953540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1732.978477</td>\n",
       "      <td>1732.978477</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>746</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>28328675917</td>\n",
       "      <td>28.967032</td>\n",
       "      <td>50.843032</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1775000.0</td>\n",
       "      <td>29.614637</td>\n",
       "      <td>51.654930</td>\n",
       "      <td>138.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1529.742001</td>\n",
       "      <td>1472.771735</td>\n",
       "      <td>135</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38351</th>\n",
       "      <td>14704494197</td>\n",
       "      <td>34.092157</td>\n",
       "      <td>49.693226</td>\n",
       "      <td>280.0</td>\n",
       "      <td>5880000.0</td>\n",
       "      <td>35.693633</td>\n",
       "      <td>51.407555</td>\n",
       "      <td>201.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1834.922402</td>\n",
       "      <td>1694.149263</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>512</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  destinationLatitude  destinationLongitude  distanceKM  \\\n",
       "23990  18426018643            32.669957             51.670529      1122.0   \n",
       "8729   68800274778            31.318349             48.681923       467.0   \n",
       "3451   80477779395            38.550434             44.953540         0.0   \n",
       "2628   28328675917            28.967032             50.843032       165.0   \n",
       "38351  14704494197            34.092157             49.693226       280.0   \n",
       "\n",
       "            price  sourceLatitude  sourceLongitude  taxiDurationMin  weight  \\\n",
       "23990  12500000.0       39.344206        45.064755            766.0     5.0   \n",
       "8729    9000000.0       32.325773        50.847471            404.0    22.0   \n",
       "3451    1000000.0       38.550434        44.953540              0.0     2.0   \n",
       "2628    1775000.0       29.614637        51.654930            138.0    10.0   \n",
       "38351   5880000.0       35.693633        51.407555            201.0    18.0   \n",
       "\n",
       "            source  destination  date_ids  SourceState_ids  \\\n",
       "23990  1773.037004  1688.073961        88                1   \n",
       "8729   1643.683805  1524.637455        17               23   \n",
       "3451   1732.978477  1732.978477       178                1   \n",
       "2628   1529.742001  1472.771735       135               15   \n",
       "38351  1834.922402  1694.149263        22                7   \n",
       "\n",
       "       destinationState_ids  vehicleType_ids  vehicleOption_ids  \\\n",
       "23990                     3                3                  7   \n",
       "8729                     11                3                  4   \n",
       "3451                      1                1                  5   \n",
       "2628                      6                2                  3   \n",
       "38351                    20                3                  7   \n",
       "\n",
       "       source_tuple_ids  destination_tuple_ids  \n",
       "23990               767                    374  \n",
       "8729                273                    285  \n",
       "3451                746                    920  \n",
       "2628                128                    130  \n",
       "38351               512                    485  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "\n",
    "min_price = min(all_data['price'])\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "BUCKET_LATI = BIN_GRANULARITY\n",
    "BUCKET_LONG = BIN_GRANULARITY\n",
    "\n",
    "min_source_lat  = min(all_data['sourceLatitude'])\n",
    "min_destin_lat  = min(all_data['destinationLatitude'])\n",
    "min_lat         = min(min_destin_lat, min_source_lat)\n",
    "\n",
    "min_source_long = min(all_data['sourceLongitude'])\n",
    "min_destin_long = min(all_data['destinationLongitude'])\n",
    "min_long        = min(min_destin_long, min_source_long)\n",
    "\n",
    "max_source_lat  = max(all_data['sourceLatitude'])\n",
    "max_destin_lat  = max(all_data['destinationLatitude'])\n",
    "max_lat         = max(max_destin_lat, max_source_lat)\n",
    "\n",
    "max_source_long = max(all_data['sourceLongitude'])\n",
    "max_destin_long = max(all_data['destinationLongitude'])\n",
    "max_long        = max(max_destin_long, max_source_long)\n",
    "\n",
    "d_lati = (max_lat - min_lat)/BUCKET_LATI\n",
    "d_long = (max_long - min_long)/BUCKET_LONG\n",
    "\n",
    "destin_lati_bucket = (all_data['destinationLatitude']  // d_lati).as_matrix().astype(int)\n",
    "destin_long_bucket = (all_data['destinationLongitude'] // d_long).as_matrix().astype(int)\n",
    "\n",
    "all_data['destination_tuple'] = tuple(zip(destin_lati_bucket,destin_long_bucket))\n",
    "\n",
    "source_lati_bucket = (all_data['sourceLatitude']  // d_lati).as_matrix().astype(int)\n",
    "source_long_bucket = (all_data['sourceLongitude'] // d_long).as_matrix().astype(int)\n",
    "\n",
    "all_data['source_tuple'] = tuple(zip(source_lati_bucket,source_long_bucket))\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', \n",
    "                    'vehicleOption', 'source_tuple', 'destination_tuple']\n",
    "\n",
    "# The following two new features are required to achive the best current model \n",
    "all_data['source']      = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination'] = all_data['destinationLatitude']*all_data['destinationLongitude'] \n",
    "\n",
    "#continues_vars   = ['sourceLatitude', 'sourceLongitude', 'destinationLatitude', 'destinationLongitude',\n",
    "#                    'distanceKM', 'taxiDurationMin', 'weight', 'source', 'destination']    \n",
    "    \n",
    "#for cont in continues_vars:\n",
    "#    all_data[cont] = all_data[cont].astype('float32')\n",
    "\n",
    "all_data = all_data.copy()\n",
    "categorical_var_encoders = {}\n",
    "for var in categorical_vars:\n",
    "    le = preprocessing.LabelEncoder().fit(all_data[var])\n",
    "    all_data[var + '_ids']  = le.transform(all_data[var])\n",
    "    all_data[var + '_ids']  = all_data[var + '_ids'].astype(int)\n",
    "    all_data.pop(var)\n",
    "    categorical_var_encoders[var] = le\n",
    "    \n",
    "#all_data[\"distanceKM\"]      = normalize_column(all_data[\"distanceKM\"].values)\n",
    "#all_data[\"taxiDurationMin\"] = normalize_column(all_data[\"taxiDurationMin\"].values)\n",
    "#all_data[\"weight\"]          = normalize_column(all_data[\"weight\"].values)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "train['price']  = train['price'].astype('float32')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train['price'], test_size=0.33, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_longitudes = set(all_data['sourceLongitude'].tolist() + all_data['destinationLongitude'].tolist())\n",
    "all_latitude   = set(all_data['sourceLatitude'].tolist() + all_data['destinationLatitude'].tolist())\n",
    "\n",
    "binned_long = np.linspace(min(all_longitudes), max(all_longitudes), BIN_GRANULARITY).tolist()\n",
    "binned_lat  = np.linspace(min(all_latitude), max(all_latitude), BIN_GRANULARITY).tolist()\n",
    "\n",
    "source_lat_feat         = tf.feature_column.numeric_column(\"sourceLatitude\") \n",
    "source_long_feat        = tf.feature_column.numeric_column(\"sourceLongitude\") \n",
    "destin_lat_feat         = tf.feature_column.numeric_column(\"destinationLatitude\") \n",
    "destin_long_feat        = tf.feature_column.numeric_column(\"destinationLongitude\") \n",
    "\n",
    "binned_source_lat_feat  = tf.feature_column.bucketized_column(\n",
    "                              source_column=source_lat_feat,\n",
    "                              boundaries= binned_lat)\n",
    "binned_source_long_feat = tf.feature_column.bucketized_column(\n",
    "                              source_column=source_long_feat,\n",
    "                              boundaries= binned_long)\n",
    "binned_destin_lat_feat  = tf.feature_column.bucketized_column(\n",
    "                              source_column=destin_lat_feat,\n",
    "                              boundaries= binned_lat)\n",
    "binned_destin_long_feat = tf.feature_column.bucketized_column(\n",
    "                              source_column=destin_long_feat,\n",
    "                              boundaries= binned_long)\n",
    "\n",
    "source_lat_x_long = tf.feature_column.embedding_column(tf.feature_column.crossed_column(\n",
    "                    keys=[binned_source_lat_feat, binned_source_long_feat], \n",
    "                    hash_bucket_size=BIN_GRANULARITY *BIN_GRANULARITY),dimension=BIN_GRANULARITY)\n",
    "\n",
    "destin_lat_x_long = tf.feature_column.embedding_column(tf.feature_column.crossed_column(\n",
    "                    keys=[binned_destin_lat_feat, binned_destin_long_feat], \n",
    "                    hash_bucket_size=BIN_GRANULARITY *BIN_GRANULARITY),dimension=BIN_GRANULARITY)\n",
    "\n",
    "distance_feat = tf.feature_column.numeric_column(\"distanceKM\")\n",
    "taximin_feat  = tf.feature_column.numeric_column(\"taxiDurationMin\")\n",
    "weight_feat   = tf.feature_column.numeric_column(\"weight\")\n",
    "\n",
    "date_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"date_ids\", 186),8)\n",
    "\n",
    "source_state_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"SourceState_ids\", 31),5)\n",
    "\n",
    "destin_state_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"destinationState_ids\", 31),5)\n",
    "\n",
    "veh_type_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"vehicleType_ids\", 4),2)\n",
    "\n",
    "veh_option_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"vehicleOption_ids\", 9),4)\n",
    "\n",
    "source_feat   = tf.feature_column.numeric_column(\"source\")\n",
    "destin_feat   = tf.feature_column.numeric_column(\"destination\")\n",
    "\n",
    "destination_tuple_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"destination_tuple_ids\", 2191),11)\n",
    " \n",
    "source_tuple_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"source_tuple_ids\", 2191),11)\n",
    "\n",
    "feature_columns = {source_lat_x_long, destin_lat_x_long, distance_feat, taximin_feat,\n",
    "                   weight_feat, date_feat, source_state_feat, destin_state_feat,\n",
    "                   veh_type_feat, veh_option_feat, source_feat, destin_feat,\n",
    "                   destination_tuple_feat, source_tuple_feat}\n",
    "\n",
    "#feature_columns = {distance_feat, taximin_feat, weight_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(features, labels, mode, params, config):\n",
    "    input_layer = tf.feature_column.input_layer(features=features, \n",
    "                                                feature_columns=feature_columns)\n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    x = tf.layers.dense(inputs=input_layer,\n",
    "                        units=HIDDEN_LAYER_1_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"first_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dropout(inputs=x,name=\"first_dropout\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_2_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"second_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_3_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"third_fully_connected_layer\")\n",
    "\n",
    "    predictions = tf.contrib.layers.fully_connected(inputs=x, num_outputs=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT :\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss)\n",
    "    else:\n",
    "        #loss = tf.losses.absolute_difference(labels=labels,\n",
    "        #                                    predictions=predictions)\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, \n",
    "                                      global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss, \n",
    "                                          train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, pred = False):\n",
    "        \n",
    "    useful_fueatures = [\n",
    "        np.array(df[\"sourceLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"distanceKM\"].values, dtype=np.float32),\n",
    "        np.array(df[\"taxiDurationMin\"].values, dtype=np.float32),\n",
    "        np.array(df[\"weight\"].values, dtype=np.float32),\n",
    "        np.array(df[\"date_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"SourceState_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"destinationState_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"vehicleType_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"vehicleOption_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"source\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination_tuple_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"source_tuple_ids\"].values, dtype=np.int32)\n",
    "    ]\n",
    "\n",
    "    if pred: \n",
    "        train_number = 1\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        useful_fueatures.append(np.array(df[\"price\"].values, dtype=np.float32))\n",
    "        train_number = TRAIN_EPOCHS\n",
    "        batch_number = BATCH_SIZE\n",
    "        \n",
    "    A = tf.train.slice_input_producer(\n",
    "        tensor_list=useful_fueatures,\n",
    "        num_epochs=train_number,\n",
    "        shuffle= not pred,\n",
    "        capacity=BATCH_SIZE * 5\n",
    "    )\n",
    "    \n",
    "    sourceLatitude        = A[0]\n",
    "    sourceLongitude       = A[1]\n",
    "    destinationLatitude   = A[2]\n",
    "    destinationLongitude  = A[3]\n",
    "    distanceKM            = A[4]\n",
    "    taxiDurationMin       = A[5] \n",
    "    weight                = A[6]\n",
    "    date_ids              = A[7]\n",
    "    SourceState_ids       = A[8]\n",
    "    destinationState_ids  = A[9]\n",
    "    vehicleType_ids       = A[10]\n",
    "    vehicleOption_ids     = A[11]\n",
    "    source                = A[12]\n",
    "    destination           = A[13] \n",
    "    destination_tuple_ids = A[14] \n",
    "    source_tuple_ids      = A[15] \n",
    "    \n",
    "    # Created a dict out of sliced input producers\n",
    "    dataset_dict = dict(\n",
    "        sourceLatitude=sourceLatitude,\n",
    "        sourceLongitude=sourceLongitude,\n",
    "        destinationLatitude=destinationLatitude,\n",
    "        destinationLongitude=destinationLongitude, \n",
    "        distanceKM=distanceKM,\n",
    "        taxiDurationMin=taxiDurationMin,\n",
    "        weight=weight,\n",
    "        date_ids=date_ids,\n",
    "        SourceState_ids=SourceState_ids,\n",
    "        destinationState_ids=destinationState_ids,\n",
    "        vehicleType_ids=vehicleType_ids,\n",
    "        vehicleOption_ids=vehicleOption_ids,\n",
    "        source=source, \n",
    "        destination=destination,\n",
    "        destination_tuple_ids=destination_tuple_ids,\n",
    "        source_tuple_ids=source_tuple_ids,\n",
    "    )\n",
    "\n",
    "    if not pred:\n",
    "        dataset_dict['labels'] = A[16]\n",
    "            \n",
    "    batch_dict = tf.train.batch(\n",
    "        dataset_dict,\n",
    "        batch_number,\n",
    "   )\n",
    "\n",
    "    if pred == False:\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, tf.reshape(batch_labels, [-1, 1]) \n",
    "    else:\n",
    "        return batch_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c2210cd68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.99999386, step = 1\n",
      "INFO:tensorflow:global_step/sec: 35.1473\n",
      "INFO:tensorflow:loss = 0.8892753, step = 101 (2.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0994\n",
      "INFO:tensorflow:loss = 0.49234784, step = 201 (2.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8242\n",
      "INFO:tensorflow:loss = 0.46443456, step = 301 (2.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4988\n",
      "INFO:tensorflow:loss = 0.46888041, step = 401 (2.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1509\n",
      "INFO:tensorflow:loss = 0.37907216, step = 501 (2.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2122\n",
      "INFO:tensorflow:loss = 0.34467983, step = 601 (2.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.5231\n",
      "INFO:tensorflow:loss = 0.3630568, step = 701 (2.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5023\n",
      "INFO:tensorflow:loss = 0.35493594, step = 801 (2.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.9071\n",
      "INFO:tensorflow:loss = 0.34974432, step = 901 (2.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9978\n",
      "INFO:tensorflow:loss = 0.34587774, step = 1001 (2.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4322\n",
      "INFO:tensorflow:loss = 0.31891376, step = 1101 (2.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.9372\n",
      "INFO:tensorflow:loss = 0.30754074, step = 1201 (2.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3323\n",
      "INFO:tensorflow:loss = 0.35732475, step = 1301 (2.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.071\n",
      "INFO:tensorflow:loss = 0.3516218, step = 1401 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.5592\n",
      "INFO:tensorflow:loss = 0.32655197, step = 1501 (2.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3788\n",
      "INFO:tensorflow:loss = 0.28960934, step = 1601 (2.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1769\n",
      "INFO:tensorflow:loss = 0.29033658, step = 1701 (2.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1444\n",
      "INFO:tensorflow:loss = 0.2832492, step = 1801 (2.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6352\n",
      "INFO:tensorflow:loss = 0.27948582, step = 1901 (2.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7189\n",
      "INFO:tensorflow:loss = 0.28507036, step = 2001 (2.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2415\n",
      "INFO:tensorflow:loss = 0.25593507, step = 2101 (2.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3667\n",
      "INFO:tensorflow:loss = 0.26618734, step = 2201 (2.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2136\n",
      "INFO:tensorflow:loss = 0.2339785, step = 2301 (2.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.28\n",
      "INFO:tensorflow:loss = 0.22425151, step = 2401 (2.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2864\n",
      "INFO:tensorflow:loss = 0.2156232, step = 2501 (2.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4316\n",
      "INFO:tensorflow:loss = 0.24244282, step = 2601 (2.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2363\n",
      "INFO:tensorflow:loss = 0.25794673, step = 2701 (2.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1539\n",
      "INFO:tensorflow:loss = 0.21373484, step = 2801 (2.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2515\n",
      "INFO:tensorflow:loss = 0.23154193, step = 2901 (2.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.6639\n",
      "INFO:tensorflow:loss = 0.19668652, step = 3001 (2.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8498\n",
      "INFO:tensorflow:loss = 0.23008463, step = 3101 (2.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0984\n",
      "INFO:tensorflow:loss = 0.20690408, step = 3201 (2.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.0392\n",
      "INFO:tensorflow:loss = 0.22526938, step = 3301 (2.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3393\n",
      "INFO:tensorflow:loss = 0.22453788, step = 3401 (2.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.3461\n",
      "INFO:tensorflow:loss = 0.21077478, step = 3501 (2.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7431\n",
      "INFO:tensorflow:loss = 0.19779812, step = 3601 (2.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2974\n",
      "INFO:tensorflow:loss = 0.21228105, step = 3701 (2.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.4373\n",
      "INFO:tensorflow:loss = 0.20233145, step = 3801 (2.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.3871\n",
      "INFO:tensorflow:loss = 0.19344787, step = 3901 (2.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9315\n",
      "INFO:tensorflow:loss = 0.21382517, step = 4001 (2.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4627\n",
      "INFO:tensorflow:loss = 0.22930157, step = 4101 (2.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.027\n",
      "INFO:tensorflow:loss = 0.19095194, step = 4201 (2.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1006\n",
      "INFO:tensorflow:loss = 0.19641224, step = 4301 (2.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1762\n",
      "INFO:tensorflow:loss = 0.17947976, step = 4401 (2.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.759\n",
      "INFO:tensorflow:loss = 0.22534245, step = 4501 (2.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3784\n",
      "INFO:tensorflow:loss = 0.19563887, step = 4601 (2.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6171\n",
      "INFO:tensorflow:loss = 0.22134593, step = 4701 (2.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0133\n",
      "INFO:tensorflow:loss = 0.19236863, step = 4801 (2.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3869\n",
      "INFO:tensorflow:loss = 0.21808133, step = 4901 (2.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8088\n",
      "INFO:tensorflow:loss = 0.21037142, step = 5001 (2.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.151\n",
      "INFO:tensorflow:loss = 0.20523548, step = 5101 (2.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.3335\n",
      "INFO:tensorflow:loss = 0.21841463, step = 5201 (2.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.0465\n",
      "INFO:tensorflow:loss = 0.19525188, step = 5301 (2.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1245\n",
      "INFO:tensorflow:loss = 0.19503799, step = 5401 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4276\n",
      "INFO:tensorflow:loss = 0.22020864, step = 5501 (2.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.1478\n",
      "INFO:tensorflow:loss = 0.19693431, step = 5601 (2.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9554\n",
      "INFO:tensorflow:loss = 0.18843077, step = 5701 (2.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.64\n",
      "INFO:tensorflow:loss = 0.1925861, step = 5801 (2.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.1873\n",
      "INFO:tensorflow:loss = 0.1806683, step = 5901 (2.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2006291.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1072abf60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "estimator_val = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator_val.train(input_fn=lambda: input_fn(X_train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-08-07:42:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-08-07:42:09\n",
      "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, loss = 0.20563829\n"
     ]
    }
   ],
   "source": [
    "ev = estimator_val.evaluate(input_fn=lambda: input_fn(X_val), steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp1fde86vk/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.53934096988676"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val  = list(estimator_val.predict(input_fn = lambda: input_fn(X_val, pred=True)))\n",
    "preds_val        = [int(x) for x in predictions_val]\n",
    "score            = mean_absolute_percentage_error(preds_val, y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpldih6ys4\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpldih6ys4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a1f579278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpldih6ys4/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.99998283, step = 1\n",
      "INFO:tensorflow:global_step/sec: 33.0723\n",
      "INFO:tensorflow:loss = 0.873107, step = 101 (3.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.636\n",
      "INFO:tensorflow:loss = 0.50621533, step = 201 (2.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6481\n",
      "INFO:tensorflow:loss = 0.45317236, step = 301 (2.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5284\n",
      "INFO:tensorflow:loss = 0.41703588, step = 401 (2.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3582\n",
      "INFO:tensorflow:loss = 0.39708632, step = 501 (2.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4509\n",
      "INFO:tensorflow:loss = 0.37753594, step = 601 (2.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7761\n",
      "INFO:tensorflow:loss = 0.34205848, step = 701 (2.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.286\n",
      "INFO:tensorflow:loss = 0.36764556, step = 801 (2.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.4517\n",
      "INFO:tensorflow:loss = 0.36822408, step = 901 (2.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0296\n",
      "INFO:tensorflow:loss = 0.3348439, step = 1001 (2.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4011\n",
      "INFO:tensorflow:loss = 0.34012538, step = 1101 (2.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4213\n",
      "INFO:tensorflow:loss = 0.35309044, step = 1201 (2.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5436\n",
      "INFO:tensorflow:loss = 0.32601234, step = 1301 (2.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7207\n",
      "INFO:tensorflow:loss = 0.32830632, step = 1401 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2843\n",
      "INFO:tensorflow:loss = 0.29639497, step = 1501 (2.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.579\n",
      "INFO:tensorflow:loss = 0.31168002, step = 1601 (2.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4392\n",
      "INFO:tensorflow:loss = 0.28980172, step = 1701 (2.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2102\n",
      "INFO:tensorflow:loss = 0.2542335, step = 1801 (2.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8955\n",
      "INFO:tensorflow:loss = 0.25875515, step = 1901 (2.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5444\n",
      "INFO:tensorflow:loss = 0.256776, step = 2001 (2.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4066\n",
      "INFO:tensorflow:loss = 0.2747416, step = 2101 (2.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9538\n",
      "INFO:tensorflow:loss = 0.24856597, step = 2201 (2.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.6168\n",
      "INFO:tensorflow:loss = 0.25301743, step = 2301 (2.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.6388\n",
      "INFO:tensorflow:loss = 0.23995338, step = 2401 (2.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2923\n",
      "INFO:tensorflow:loss = 0.20760196, step = 2501 (2.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8261\n",
      "INFO:tensorflow:loss = 0.21332599, step = 2601 (2.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.5808\n",
      "INFO:tensorflow:loss = 0.24477023, step = 2701 (2.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.7529\n",
      "INFO:tensorflow:loss = 0.19881788, step = 2801 (2.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6227\n",
      "INFO:tensorflow:loss = 0.21195665, step = 2901 (2.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.5058\n",
      "INFO:tensorflow:loss = 0.25575376, step = 3001 (2.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8642\n",
      "INFO:tensorflow:loss = 0.23300904, step = 3101 (2.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8931\n",
      "INFO:tensorflow:loss = 0.1943528, step = 3201 (2.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6323\n",
      "INFO:tensorflow:loss = 0.21093613, step = 3301 (2.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9582\n",
      "INFO:tensorflow:loss = 0.22172883, step = 3401 (2.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5264\n",
      "INFO:tensorflow:loss = 0.21429238, step = 3501 (2.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5508\n",
      "INFO:tensorflow:loss = 0.23015322, step = 3601 (2.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4291\n",
      "INFO:tensorflow:loss = 0.22139698, step = 3701 (2.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9907\n",
      "INFO:tensorflow:loss = 0.18564509, step = 3801 (2.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0012\n",
      "INFO:tensorflow:loss = 0.22934769, step = 3901 (2.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5146\n",
      "INFO:tensorflow:loss = 0.19834274, step = 4001 (2.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.128\n",
      "INFO:tensorflow:loss = 0.21697555, step = 4101 (2.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1569\n",
      "INFO:tensorflow:loss = 0.23415816, step = 4201 (2.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.7823\n",
      "INFO:tensorflow:loss = 0.20609045, step = 4301 (2.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8925\n",
      "INFO:tensorflow:loss = 0.19995096, step = 4401 (2.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4739\n",
      "INFO:tensorflow:loss = 0.20227548, step = 4501 (2.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.319\n",
      "INFO:tensorflow:loss = 0.20958899, step = 4601 (2.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7181\n",
      "INFO:tensorflow:loss = 0.20667148, step = 4701 (2.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3914\n",
      "INFO:tensorflow:loss = 0.1668795, step = 4801 (2.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.4441\n",
      "INFO:tensorflow:loss = 0.2009112, step = 4901 (2.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.3409\n",
      "INFO:tensorflow:loss = 0.18958296, step = 5001 (2.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9306\n",
      "INFO:tensorflow:loss = 0.20531823, step = 5101 (2.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8226\n",
      "INFO:tensorflow:loss = 0.20339888, step = 5201 (2.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4391\n",
      "INFO:tensorflow:loss = 0.2079001, step = 5301 (2.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7006\n",
      "INFO:tensorflow:loss = 0.21449253, step = 5401 (2.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6887\n",
      "INFO:tensorflow:loss = 0.19071114, step = 5501 (2.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0315\n",
      "INFO:tensorflow:loss = 0.1976707, step = 5601 (2.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4584\n",
      "INFO:tensorflow:loss = 0.21737157, step = 5701 (2.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4194\n",
      "INFO:tensorflow:loss = 0.2123338, step = 5801 (2.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.988\n",
      "INFO:tensorflow:loss = 0.17934497, step = 5901 (2.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.88\n",
      "INFO:tensorflow:loss = 0.20070025, step = 6001 (2.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2007\n",
      "INFO:tensorflow:loss = 0.20192188, step = 6101 (2.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8984\n",
      "INFO:tensorflow:loss = 0.18065712, step = 6201 (2.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.6312\n",
      "INFO:tensorflow:loss = 0.20693961, step = 6301 (2.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4553\n",
      "INFO:tensorflow:loss = 0.20873687, step = 6401 (2.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9706\n",
      "INFO:tensorflow:loss = 0.20692383, step = 6501 (2.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0294\n",
      "INFO:tensorflow:loss = 0.20471121, step = 6601 (2.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2961\n",
      "INFO:tensorflow:loss = 0.21128468, step = 6701 (2.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.34\n",
      "INFO:tensorflow:loss = 0.17685309, step = 6801 (2.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8323\n",
      "INFO:tensorflow:loss = 0.21282405, step = 6901 (2.449 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpldih6ys4/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.20151755.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a1f579128>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator.train(input_fn=lambda: input_fn(train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpldih6ys4/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions   = list(estimator.predict(input_fn = lambda: input_fn(test, pred=True)))\n",
    "y_preds_test   = [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission18.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
