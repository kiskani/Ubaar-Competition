{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "#from scipy.special import boxcox1p\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "#from mlxtend.regressor import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "# Remove NANs\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "# Remove outliers\n",
    "data.drop([28098])\n",
    "THRESHOLD = 3.5e7\n",
    "Aa = data[data.price > THRESHOLD]\n",
    "data = data.drop(Aa.index.tolist())\n",
    "\n",
    "specific_cols = ['distanceKM', 'taxiDurationMin', 'weight']\n",
    "removed_indices = []\n",
    "for col in specific_cols:\n",
    "    df = data['price']/data[col]\n",
    "    A = df[~df.isin([np.nan, np.inf, -np.inf])]\n",
    "    B = (A - np.mean(A)) / np.std(A)\n",
    "    V = B[B > 5]\n",
    "    removed_indices.extend(V.index.tolist())\n",
    "data = data.drop(set(removed_indices))\n",
    "\n",
    "# Fill test NANs\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "#X = train.drop(['ID','price'],axis=1)\n",
    "#y = train.price\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost_F = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                   max_depth=10, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "xgb_F = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1, nthread = -1)\n",
    "\n",
    "lgb_F = lgb.LGBMRegressor(objective='regression',num_leaves=25,  \n",
    "                          learning_rate=0.01, n_estimators=60000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "avg_model_F = AveragingModels(models = (xgb_F, lgb_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "GBoost_F.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "xgb_F.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "lgb_F.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "avg_model_F.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "\n",
    "test['y_gboost']      = GBoost_F.predict(test.drop(['ID','price'],axis=1))\n",
    "test['y_xgb']         = xgb_F.predict(test.drop(['ID','price','y_gboost'],axis=1))\n",
    "test['y_lgb']         = lgb_F.predict(test.drop(['ID','price','y_gboost', 'y_xgb'],axis=1))\n",
    "test['y_avg_lgb_xgb'] = avg_model_F.predict(test.drop(['ID','price','y_gboost', 'y_xgb', 'y_lgb'],axis=1))\n",
    "\n",
    "test.to_pickle('dataFrames/test_OneHotEncoding_Final_15th.pkl')\n",
    "\n",
    "print( '%.2f' % float((time.time() - start_time)/60 )  + ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission39_Gboost_best.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(test.shape[0]):\n",
    "        outputfile.write(str(test.ID[i])+\",\"+str(int(np.ceil(test.y_gboost[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission40_Avg_best.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(test.shape[0]):\n",
    "        outputfile.write(str(test.ID[i])+\",\"+str(int(np.ceil(test.y_avg_lgb_xgb[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
