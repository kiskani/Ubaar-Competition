{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "      <th>y_lgb</th>\n",
       "      <th>ID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1445.240621</td>\n",
       "      <td>1615.715576</td>\n",
       "      <td>2.001315e+07</td>\n",
       "      <td>20377512.00</td>\n",
       "      <td>20693972.0</td>\n",
       "      <td>4290000.0</td>\n",
       "      <td>1.883525e+07</td>\n",
       "      <td>2.214366e+07</td>\n",
       "      <td>10602550191</td>\n",
       "      <td>19000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28663</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1529.810740</td>\n",
       "      <td>1835.031150</td>\n",
       "      <td>5.602654e+06</td>\n",
       "      <td>7494018.50</td>\n",
       "      <td>4657211.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>4.240625e+06</td>\n",
       "      <td>7.224867e+06</td>\n",
       "      <td>59022077023</td>\n",
       "      <td>8000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19042</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1695.498480</td>\n",
       "      <td>1529.684118</td>\n",
       "      <td>9.197673e+06</td>\n",
       "      <td>9348608.00</td>\n",
       "      <td>9439628.0</td>\n",
       "      <td>8305000.0</td>\n",
       "      <td>9.854376e+06</td>\n",
       "      <td>1.029661e+07</td>\n",
       "      <td>74752147720</td>\n",
       "      <td>10338000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1726.162961</td>\n",
       "      <td>1688.236841</td>\n",
       "      <td>2.536652e+06</td>\n",
       "      <td>2578700.75</td>\n",
       "      <td>2509670.0</td>\n",
       "      <td>2320000.0</td>\n",
       "      <td>2.347938e+06</td>\n",
       "      <td>3.293571e+06</td>\n",
       "      <td>76223312658</td>\n",
       "      <td>2320000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1494.720310</td>\n",
       "      <td>1834.786874</td>\n",
       "      <td>1.737643e+07</td>\n",
       "      <td>17874336.00</td>\n",
       "      <td>17712615.0</td>\n",
       "      <td>16650000.0</td>\n",
       "      <td>1.878682e+07</td>\n",
       "      <td>1.692893e+07</td>\n",
       "      <td>74609642925</td>\n",
       "      <td>18000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9     ...           source  destination  \\\n",
       "40689  0  0  0  0  0  0  1  0  0  0     ...      1445.240621  1615.715576   \n",
       "28663  0  0  0  0  0  0  0  0  0  0     ...      1529.810740  1835.031150   \n",
       "19042  0  0  0  1  0  0  0  0  0  0     ...      1695.498480  1529.684118   \n",
       "21837  0  0  0  0  0  0  0  0  0  0     ...      1726.162961  1688.236841   \n",
       "35006  0  0  0  0  0  0  0  0  0  0     ...      1494.720310  1834.786874   \n",
       "\n",
       "           y_gboost        y_xgb       y_bag       y_knn         y_dec  \\\n",
       "40689  2.001315e+07  20377512.00  20693972.0   4290000.0  1.883525e+07   \n",
       "28663  5.602654e+06   7494018.50   4657211.0   6000000.0  4.240625e+06   \n",
       "19042  9.197673e+06   9348608.00   9439628.0   8305000.0  9.854376e+06   \n",
       "21837  2.536652e+06   2578700.75   2509670.0   2320000.0  2.347938e+06   \n",
       "35006  1.737643e+07  17874336.00  17712615.0  16650000.0  1.878682e+07   \n",
       "\n",
       "              y_lgb           ID       price  \n",
       "40689  2.214366e+07  10602550191  19000000.0  \n",
       "28663  7.224867e+06  59022077023   8000000.0  \n",
       "19042  1.029661e+07  74752147720  10338000.0  \n",
       "21837  3.293571e+06  76223312658   2320000.0  \n",
       "35006  1.692893e+07  74609642925  18000000.0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test  = pd.read_pickle('dataFrames/test_OneHotEncoding.pkl')\n",
    "train = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "\n",
    "continuous_cols = ['destinationLatitude', 'destinationLongitude', 'distanceKM', 'sourceLatitude', \n",
    "                   'sourceLongitude', 'taxiDurationMin', 'weight', 'source', 'destination', \n",
    "                   'y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec', 'y_lgb' ]\n",
    "categorical_cols = train.columns.drop(continuous_cols + ['ID', 'price']).tolist()\n",
    "\n",
    "NOM = train[categorical_cols].shape[1]\n",
    "renaming_dict = dict(zip(train[categorical_cols].columns, [str(x) for x in list(range(NOM)) ]))\n",
    "\n",
    "train_renamed = train[categorical_cols].rename(columns=renaming_dict)\n",
    "test_renamed  = test[categorical_cols].rename(columns=renaming_dict)\n",
    "\n",
    "for column in continuous_cols:\n",
    "    train_renamed[column] = train[column]\n",
    "    test_renamed[column] = test[column]\n",
    "    \n",
    "test_renamed['ID']   = test['ID']\n",
    "train_renamed['ID'] = train['ID']\n",
    "test_renamed['price'] = test['price']\n",
    "train_renamed['price'] = train['price']\n",
    "\n",
    "X_train, X_val = train_test_split(train_renamed, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
       "       '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72',\n",
       "       '73', '74', 'destinationLatitude', 'destinationLongitude', 'distanceKM',\n",
       "       'sourceLatitude', 'sourceLongitude', 'taxiDurationMin', 'weight',\n",
       "       'source', 'destination', 'y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec',\n",
       "       'y_lgb', 'ID', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow combination  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 128\n",
    "TRAIN_EPOCHS        = 1200\n",
    "\n",
    "HIDDEN_LAYER_1_SIZE = 512\n",
    "HIDDEN_LAYER_2_SIZE = 512\n",
    "HIDDEN_LAYER_3_SIZE = 128\n",
    "lr                  = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = set()\n",
    "\n",
    "#for col in categorical_cols:\n",
    "#    col_feat = tf.feature_column.embedding_column(\n",
    "#        tf.feature_column.categorical_column_with_identity(renaming_dict[col], 1),2)\n",
    "#    feature_columns.add(col_feat)\n",
    "\n",
    "for cont in continuous_cols:\n",
    "    col_feat = tf.feature_column.numeric_column(cont)\n",
    "    feature_columns.add(col_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(features, labels, mode, params, config):\n",
    "    input_layer = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    x = tf.layers.dense(inputs=input_layer, units=HIDDEN_LAYER_1_SIZE, activation=tf.nn.relu, name=\"first_layer\")\n",
    "    x = tf.layers.dropout(inputs=x,name=\"first_dropout\")\n",
    "    x = tf.layers.dense(inputs=x, units=HIDDEN_LAYER_2_SIZE, activation=tf.nn.relu, name=\"second_layer\")\n",
    "    x = tf.layers.dense(inputs=x, units=HIDDEN_LAYER_3_SIZE, activation=tf.nn.relu, name=\"third_layer\")\n",
    "    predictions = tf.contrib.layers.fully_connected(inputs=x, num_outputs=1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT :\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss)\n",
    "    else:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, pred = False):\n",
    "        \n",
    "    useful_fueatures = list()\n",
    "    for col in categorical_cols:\n",
    "        useful_fueatures.append(np.array(df[renaming_dict[col]].values, dtype=np.int32))\n",
    "\n",
    "    for cont in continuous_cols:\n",
    "        useful_fueatures.append(np.array(df[cont].values, dtype=np.float32))    \n",
    "    \n",
    "    if pred: \n",
    "        train_number = 1\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        useful_fueatures.append(np.array(df[\"price\"].values, dtype=np.float32))\n",
    "        train_number = TRAIN_EPOCHS\n",
    "        batch_number = BATCH_SIZE\n",
    "        \n",
    "    A = tf.train.slice_input_producer(\n",
    "        tensor_list=useful_fueatures,\n",
    "        num_epochs=train_number,\n",
    "        shuffle= not pred,\n",
    "        capacity=BATCH_SIZE * 5\n",
    "    )\n",
    "\n",
    "    dataset_dict = dict()\n",
    "    for i in range(len(A)):\n",
    "        if i < len(categorical_cols):\n",
    "            #dataset_dict[renaming_dict[categorical_cols[i]]] = A[i]\n",
    "            pass\n",
    "        elif i < len(categorical_cols) + len(continuous_cols):\n",
    "            dataset_dict[continuous_cols[i-len(categorical_cols)]] = A[i]\n",
    "\n",
    "    if not pred:\n",
    "        dataset_dict['labels'] = A[-1]\n",
    "            \n",
    "    batch_dict = tf.train.batch(\n",
    "        dataset_dict,\n",
    "        batch_number,\n",
    "   )\n",
    "\n",
    "    if pred == False:\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, tf.reshape(batch_labels, [-1, 1]) \n",
    "    else:\n",
    "        print(batch_dict)\n",
    "        return batch_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpzmjwse4w\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpzmjwse4w', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c2c219e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpzmjwse4w/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.99225724, step = 1\n",
      "INFO:tensorflow:global_step/sec: 49.8611\n",
      "INFO:tensorflow:loss = 0.1536974, step = 101 (2.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.8855\n",
      "INFO:tensorflow:loss = 0.1838063, step = 201 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7359\n",
      "INFO:tensorflow:loss = 0.13160962, step = 301 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.0367\n",
      "INFO:tensorflow:loss = 0.16624814, step = 401 (1.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3748\n",
      "INFO:tensorflow:loss = 0.17655385, step = 501 (1.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.45\n",
      "INFO:tensorflow:loss = 0.18624057, step = 601 (1.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9284\n",
      "INFO:tensorflow:loss = 0.15863466, step = 701 (2.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.5841\n",
      "INFO:tensorflow:loss = 0.15273544, step = 801 (2.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3886\n",
      "INFO:tensorflow:loss = 0.16726263, step = 901 (1.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.5581\n",
      "INFO:tensorflow:loss = 0.15675664, step = 1001 (2.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1321\n",
      "INFO:tensorflow:loss = 0.13523944, step = 1101 (1.995 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpzmjwse4w/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.16335979.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c2c219cc0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "estimator_val = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator_val.train(input_fn=lambda: input_fn(X_train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destination': <tf.Tensor 'batch:0' shape=(1,) dtype=float32>, 'destinationLatitude': <tf.Tensor 'batch:1' shape=(1,) dtype=float32>, 'destinationLongitude': <tf.Tensor 'batch:2' shape=(1,) dtype=float32>, 'distanceKM': <tf.Tensor 'batch:3' shape=(1,) dtype=float32>, 'source': <tf.Tensor 'batch:4' shape=(1,) dtype=float32>, 'sourceLatitude': <tf.Tensor 'batch:5' shape=(1,) dtype=float32>, 'sourceLongitude': <tf.Tensor 'batch:6' shape=(1,) dtype=float32>, 'taxiDurationMin': <tf.Tensor 'batch:7' shape=(1,) dtype=float32>, 'weight': <tf.Tensor 'batch:8' shape=(1,) dtype=float32>, 'y_bag': <tf.Tensor 'batch:9' shape=(1,) dtype=float32>, 'y_dec': <tf.Tensor 'batch:10' shape=(1,) dtype=float32>, 'y_gboost': <tf.Tensor 'batch:11' shape=(1,) dtype=float32>, 'y_knn': <tf.Tensor 'batch:12' shape=(1,) dtype=float32>, 'y_lgb': <tf.Tensor 'batch:13' shape=(1,) dtype=float32>, 'y_xgb': <tf.Tensor 'batch:14' shape=(1,) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpzmjwse4w/model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.510907101630124"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val   = list(estimator_val.predict(input_fn = lambda: input_fn(X_val, pred=True)))\n",
    "y_preds_val       = [int(x) for x in predictions_val]\n",
    "mean_absolute_precision_error(y_preds_val, X_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpdcis1vro\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpdcis1vro', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c29d169e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpdcis1vro/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.88427734, step = 1\n",
      "INFO:tensorflow:global_step/sec: 49.6923\n",
      "INFO:tensorflow:loss = 0.15713006, step = 101 (2.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.2573\n",
      "INFO:tensorflow:loss = 0.16185367, step = 201 (1.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7456\n",
      "INFO:tensorflow:loss = 0.129284, step = 301 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.354\n",
      "INFO:tensorflow:loss = 0.15110213, step = 401 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.1315\n",
      "INFO:tensorflow:loss = 0.18890181, step = 501 (1.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.8927\n",
      "INFO:tensorflow:loss = 0.19427362, step = 601 (2.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7119\n",
      "INFO:tensorflow:loss = 0.17942514, step = 701 (2.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.807\n",
      "INFO:tensorflow:loss = 0.17282873, step = 801 (1.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.4191\n",
      "INFO:tensorflow:loss = 0.19163269, step = 901 (2.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3515\n",
      "INFO:tensorflow:loss = 0.1655757, step = 1001 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 49.9169\n",
      "INFO:tensorflow:loss = 0.1639243, step = 1101 (2.003 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpdcis1vro/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15520664.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c29d16908>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator.train(input_fn=lambda: input_fn(train_renamed), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'destination': <tf.Tensor 'batch:0' shape=(1,) dtype=float32>, 'destinationLatitude': <tf.Tensor 'batch:1' shape=(1,) dtype=float32>, 'destinationLongitude': <tf.Tensor 'batch:2' shape=(1,) dtype=float32>, 'distanceKM': <tf.Tensor 'batch:3' shape=(1,) dtype=float32>, 'source': <tf.Tensor 'batch:4' shape=(1,) dtype=float32>, 'sourceLatitude': <tf.Tensor 'batch:5' shape=(1,) dtype=float32>, 'sourceLongitude': <tf.Tensor 'batch:6' shape=(1,) dtype=float32>, 'taxiDurationMin': <tf.Tensor 'batch:7' shape=(1,) dtype=float32>, 'weight': <tf.Tensor 'batch:8' shape=(1,) dtype=float32>, 'y_bag': <tf.Tensor 'batch:9' shape=(1,) dtype=float32>, 'y_dec': <tf.Tensor 'batch:10' shape=(1,) dtype=float32>, 'y_gboost': <tf.Tensor 'batch:11' shape=(1,) dtype=float32>, 'y_knn': <tf.Tensor 'batch:12' shape=(1,) dtype=float32>, 'y_lgb': <tf.Tensor 'batch:13' shape=(1,) dtype=float32>, 'y_xgb': <tf.Tensor 'batch:14' shape=(1,) dtype=float32>}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpdcis1vro/model.ckpt-1200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions   = list(estimator.predict(input_fn = lambda: input_fn(test_renamed, pred=True)))\n",
    "y_preds_test   = [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission37.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submission 19 with loss of 15.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_gboost              = A[0]\n",
    "    y_xgb                 = A[1]\n",
    "    y_bag                 = A[2]\n",
    "    y_lgb                 = A[3]\n",
    "    y_knn                 = A[4]\n",
    "    y_dec                 = A[5]\n",
    "    sourceLatitude        = A[6]\n",
    "    sourceLongitude       = A[7]\n",
    "    destinationLatitude   = A[8]\n",
    "    destinationLongitude  = A[9]\n",
    "    distanceKM            = A[10]\n",
    "    taxiDurationMin       = A[11] \n",
    "    weight                = A[12]\n",
    "    source                = A[13]\n",
    "    destination           = A[14] \n",
    "    \n",
    "    \n",
    "    # Created a dict out of sliced input producers\n",
    "    dataset_dict = dict(\n",
    "        y_gboost=y_gboost,\n",
    "        y_xgb=y_xgb,\n",
    "        y_bag=y_bag,\n",
    "        y_lgb=y_lgb,\n",
    "        y_knn=y_knn,\n",
    "        y_dec=y_dec,\n",
    "        sourceLatitude=sourceLatitude,\n",
    "        sourceLongitude=sourceLongitude,\n",
    "        destinationLatitude=destinationLatitude,\n",
    "        destinationLongitude=destinationLongitude, \n",
    "        distanceKM=distanceKM,\n",
    "        taxiDurationMin=taxiDurationMin,\n",
    "        weight=weight,\n",
    "        source=source, \n",
    "        destination=destination\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    [\n",
    "        np.array(df[\"y_gboost\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_xgb\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_bag\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_lgb\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_knn\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_dec\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"distanceKM\"].values, dtype=np.float32),\n",
    "        np.array(df[\"taxiDurationMin\"].values, dtype=np.float32),\n",
    "        np.array(df[\"weight\"].values, dtype=np.float32),\n",
    "        np.array(df[\"source\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination\"].values, dtype=np.float32),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gboost_feat = tf.feature_column.numeric_column(\"y_gboost\")\n",
    "y_xgb_feat    = tf.feature_column.numeric_column(\"y_xgb\")\n",
    "y_bag_feat    = tf.feature_column.numeric_column(\"y_bag\")\n",
    "y_knn_feat    = tf.feature_column.numeric_column(\"y_knn\")\n",
    "y_dec_feat    = tf.feature_column.numeric_column(\"y_dec\")\n",
    "y_lgb_feat    = tf.feature_column.numeric_column(\"y_lgb\")\n",
    "\n",
    "source_lat_feat         = tf.feature_column.numeric_column(\"sourceLatitude\") \n",
    "source_long_feat        = tf.feature_column.numeric_column(\"sourceLongitude\") \n",
    "destin_lat_feat         = tf.feature_column.numeric_column(\"destinationLatitude\") \n",
    "destin_long_feat        = tf.feature_column.numeric_column(\"destinationLongitude\") \n",
    "\n",
    "distance_feat = tf.feature_column.numeric_column(\"distanceKM\")\n",
    "taximin_feat  = tf.feature_column.numeric_column(\"taxiDurationMin\")\n",
    "weight_feat   = tf.feature_column.numeric_column(\"weight\")\n",
    "\n",
    "source_feat   = tf.feature_column.numeric_column(\"source\")\n",
    "destin_feat   = tf.feature_column.numeric_column(\"destination\")\n",
    "\n",
    "feature_columns = {y_gboost_feat, y_xgb_feat, y_bag_feat, y_lgb_feat, y_knn_feat, y_dec_feat,\n",
    "                   source_lat_feat, source_long_feat , destin_lat_feat, destin_long_feat, \n",
    "                   distance_feat, taximin_feat, weight_feat, source_feat, destin_feat}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
