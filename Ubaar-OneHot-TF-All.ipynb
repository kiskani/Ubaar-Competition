{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_precision_error(y_pred, y_true):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal which_model(100, number =30, batch_size=128, l1=512, l2=128, l3=16, lr=1e-4, step_log=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>destination</th>\n",
       "      <th>y_avg_lgb_xgb</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "      <th>y_lgb</th>\n",
       "      <th>ID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1909.126148</td>\n",
       "      <td>2.478849e+07</td>\n",
       "      <td>2.328065e+07</td>\n",
       "      <td>24841406.00</td>\n",
       "      <td>2.457702e+07</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>2.483060e+07</td>\n",
       "      <td>2.434387e+07</td>\n",
       "      <td>52642600134</td>\n",
       "      <td>24500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.413580</td>\n",
       "      <td>1.262995e+07</td>\n",
       "      <td>9.319747e+06</td>\n",
       "      <td>9286450.00</td>\n",
       "      <td>1.573842e+07</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>8.900000e+06</td>\n",
       "      <td>9.594753e+06</td>\n",
       "      <td>52386856932</td>\n",
       "      <td>9000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1835.223732</td>\n",
       "      <td>7.573594e+06</td>\n",
       "      <td>7.651516e+06</td>\n",
       "      <td>7973744.50</td>\n",
       "      <td>7.752710e+06</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>5.318050e+06</td>\n",
       "      <td>7.913213e+06</td>\n",
       "      <td>19056360759</td>\n",
       "      <td>8000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1688.080124</td>\n",
       "      <td>3.345341e+06</td>\n",
       "      <td>2.828410e+06</td>\n",
       "      <td>8076054.00</td>\n",
       "      <td>3.173603e+06</td>\n",
       "      <td>2470000.0</td>\n",
       "      <td>3.644693e+06</td>\n",
       "      <td>3.762905e+06</td>\n",
       "      <td>54034736201</td>\n",
       "      <td>3450000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1748.831805</td>\n",
       "      <td>3.207776e+06</td>\n",
       "      <td>2.005464e+06</td>\n",
       "      <td>2953551.75</td>\n",
       "      <td>2.637220e+06</td>\n",
       "      <td>2915000.0</td>\n",
       "      <td>2.141866e+06</td>\n",
       "      <td>2.794782e+06</td>\n",
       "      <td>64195974128</td>\n",
       "      <td>3300000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9     ...      destination  y_avg_lgb_xgb  \\\n",
       "6987   0  0  0  0  0  0  1  0  0  0     ...      1909.126148   2.478849e+07   \n",
       "42079  0  0  0  0  0  0  0  0  0  1     ...      1550.413580   1.262995e+07   \n",
       "36862  0  0  0  0  0  0  0  0  0  0     ...      1835.223732   7.573594e+06   \n",
       "28387  0  0  0  0  0  0  0  0  0  0     ...      1688.080124   3.345341e+06   \n",
       "35474  0  0  0  0  1  0  0  0  0  0     ...      1748.831805   3.207776e+06   \n",
       "\n",
       "           y_gboost        y_xgb         y_bag      y_knn         y_dec  \\\n",
       "6987   2.328065e+07  24841406.00  2.457702e+07  9000000.0  2.483060e+07   \n",
       "42079  9.319747e+06   9286450.00  1.573842e+07  7500000.0  8.900000e+06   \n",
       "36862  7.651516e+06   7973744.50  7.752710e+06  7000000.0  5.318050e+06   \n",
       "28387  2.828410e+06   8076054.00  3.173603e+06  2470000.0  3.644693e+06   \n",
       "35474  2.005464e+06   2953551.75  2.637220e+06  2915000.0  2.141866e+06   \n",
       "\n",
       "              y_lgb           ID       price  \n",
       "6987   2.434387e+07  52642600134  24500000.0  \n",
       "42079  9.594753e+06  52386856932   9000000.0  \n",
       "36862  7.913213e+06  19056360759   8000000.0  \n",
       "28387  3.762905e+06  54034736201   3450000.0  \n",
       "35474  2.794782e+06  64195974128   3300000.0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test  = pd.read_pickle('dataFrames/test_OneHotEncoding.pkl')\n",
    "#train = pd.read_pickle('dataFrames/train_OneHotEncoding.pkl')\n",
    "test   = pd.read_pickle('dataFrames/test_OneHotEncoding_new_June14th.pkl')\n",
    "train  = pd.read_pickle('dataFrames/train_OneHotEncoding_new_June14th.pkl')\n",
    "\n",
    "#test    = test.drop(['y_avg_lgb_xgb', 'y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec', 'y_lgb'], axis=1)\n",
    "#train   = train.drop(['y_avg_lgb_xgb', 'y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec', 'y_lgb'], axis=1)\n",
    "\n",
    "continuous_cols = ['destinationLatitude', 'destinationLongitude', 'distanceKM', 'sourceLatitude', \n",
    "                   'sourceLongitude', 'taxiDurationMin', 'weight', 'source', 'destination', \n",
    "                   'y_avg_lgb_xgb','y_gboost', 'y_xgb', 'y_bag', 'y_knn', 'y_dec', 'y_lgb' ]\n",
    "\n",
    "#continuous_cols = [ 'y_gboost', 'y_xgb', 'y_lgb', 'y_bag']\n",
    "\n",
    "categorical_cols = train.columns.drop(continuous_cols + ['ID', 'price']).tolist()\n",
    "\n",
    "NOM = train[categorical_cols].shape[1]\n",
    "renaming_dict = dict(zip(train[categorical_cols].columns, [str(x) for x in list(range(NOM)) ]))\n",
    "\n",
    "train_renamed = train[categorical_cols].rename(columns=renaming_dict)\n",
    "test_renamed  = test[categorical_cols].rename(columns=renaming_dict)\n",
    "\n",
    "for column in continuous_cols:\n",
    "    train_renamed[column] = train[column]\n",
    "    test_renamed[column] = test[column]\n",
    "    \n",
    "test_renamed['ID']   = test['ID']\n",
    "train_renamed['ID'] = train['ID']\n",
    "test_renamed['price'] = test['price']\n",
    "train_renamed['price'] = train['price']\n",
    "\n",
    "X_train, X_val = train_test_split(train_renamed, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.80\n",
      "17.98\n",
      "18.39\n",
      "18.49\n",
      "19.83\n",
      "24.41\n",
      "26.86\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_gboost'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_avg_lgb_xgb'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_xgb'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_lgb'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_bag'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_dec'] - train['price']) / train['price'])))\n",
    "print(\"%.2f\" % np.mean(100*np.abs((train['y_knn'] - train['price']) / train['price'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow combination  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 128\n",
    "TRAIN_EPOCHS        = 450\n",
    "HIDDEN_LAYER_1_SIZE = 512\n",
    "HIDDEN_LAYER_2_SIZE = 512\n",
    "HIDDEN_LAYER_3_SIZE = 16\n",
    "lr                  = 1e-4\n",
    "USE_ALL_FEATURES    = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(features, labels, mode, params, config):\n",
    "    input_layer = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    x = tf.layers.dense(inputs=input_layer, units=HIDDEN_LAYER_1_SIZE, activation=tf.nn.relu, name=\"first_layer\")\n",
    "    x = tf.layers.dropout(inputs=x,name=\"first_dropout\")\n",
    "    x = tf.layers.dense(inputs=x, units=HIDDEN_LAYER_2_SIZE, activation=tf.nn.relu, name=\"second_layer\")\n",
    "    x = tf.layers.dropout(inputs=x,name=\"second_dropout\")\n",
    "    x = tf.layers.dense(inputs=x, units=HIDDEN_LAYER_3_SIZE, activation=tf.nn.relu, name=\"third_layer\")\n",
    "    predictions = tf.contrib.layers.fully_connected(inputs=x, num_outputs=1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT :\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss)\n",
    "    else:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "feature_columns = set()\n",
    "\n",
    "if USE_ALL_FEATURES:\n",
    "    for col in categorical_cols:\n",
    "        col_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(renaming_dict[col], 2),2)\n",
    "        feature_columns.add(col_feat)\n",
    "\n",
    "for cont in continuous_cols:\n",
    "    col_feat = tf.feature_column.numeric_column(cont)\n",
    "    feature_columns.add(col_feat)\n",
    "    \n",
    "print(len(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, pred = False, use_all_features = USE_ALL_FEATURES):\n",
    "        \n",
    "    useful_fueatures = list()\n",
    "    \n",
    "    if use_all_features:\n",
    "        for col in categorical_cols:\n",
    "            useful_fueatures.append(np.array(df[renaming_dict[col]].values, dtype=np.int32))\n",
    "\n",
    "    for cont in continuous_cols:\n",
    "        useful_fueatures.append(np.array(df[cont].values, dtype=np.float32))    \n",
    "    \n",
    "    if pred: \n",
    "        train_number = 1\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        useful_fueatures.append(np.array(df[\"price\"].values, dtype=np.float32))\n",
    "        train_number = TRAIN_EPOCHS\n",
    "        batch_number = BATCH_SIZE\n",
    "        \n",
    "    A = tf.train.slice_input_producer(\n",
    "        tensor_list=useful_fueatures,\n",
    "        num_epochs=train_number,\n",
    "        shuffle= not pred,\n",
    "        capacity=BATCH_SIZE * 5\n",
    "    )\n",
    "\n",
    "    dataset_dict = dict()\n",
    "    \n",
    "    if use_all_features:\n",
    "        for i in range(len(A)):\n",
    "            if i < len(categorical_cols):\n",
    "                dataset_dict[renaming_dict[categorical_cols[i]]] = A[i]\n",
    "            elif i < len(categorical_cols) + len(continuous_cols):\n",
    "                dataset_dict[continuous_cols[i-len(categorical_cols)]] = A[i]\n",
    "    else:\n",
    "        for i in range(len(A)):\n",
    "            if i < len(continuous_cols):\n",
    "                dataset_dict[continuous_cols[i]] = A[i]\n",
    "            \n",
    "    if not pred:\n",
    "        dataset_dict['labels'] = A[-1]\n",
    "            \n",
    "    batch_dict = tf.train.batch(\n",
    "        dataset_dict,\n",
    "        batch_number,\n",
    "   )\n",
    "\n",
    "    if pred == False:\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, tf.reshape(batch_labels, [-1, 1]) \n",
    "    else:\n",
    "        return batch_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp6umg3jew\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp6umg3jew', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c2f5e2198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2733\u001b[0m     \u001b[0;31m# introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9562c7920ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_step_count_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_summary_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mestimator_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mestimator_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 856\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-90db3484a0d6>\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_LAYER_1_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first_dropout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[1;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[0;32m--> 277\u001b[0;31m                                trainable, cols_to_vars)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(self, inputs, weight_collections, trainable, state)\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         state=state)\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m   def _get_sequence_dense_tensor(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor_internal\u001b[0;34m(self, inputs, weight_collections, trainable, state)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mcombiner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombiner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s_weights'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         max_norm=self.max_norm)\n\u001b[0m\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m   def _get_dense_tensor(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_safe_embedding_lookup_sparse\u001b[0;34m(embedding_weights, sparse_ids, sparse_weights, combiner, default_id, name, partition_strategy, max_norm)\u001b[0m\n\u001b[1;32m   3147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m     \u001b[0;31m# Prune invalid ids and weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3149\u001b[0;31m     \u001b[0msparse_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prune_invalid_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3151\u001b[0m     \u001b[0;31m# Fill in dummy values for empty features, if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_prune_invalid_ids\u001b[0;34m(sparse_ids, sparse_weights)\u001b[0m\n\u001b[1;32m   3197\u001b[0m     is_id_valid = math_ops.logical_and(\n\u001b[1;32m   3198\u001b[0m         is_id_valid, math_ops.greater(sparse_weights.values, 0))\n\u001b[0;32m-> 3199\u001b[0;31m   \u001b[0msparse_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_retain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_id_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msparse_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m     \u001b[0msparse_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_retain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_id_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36msparse_retain\u001b[0;34m(sp_input, to_retain)\u001b[0m\n\u001b[1;32m   1254\u001b[0m   \u001b[0mwhere_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_retain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m   \u001b[0mnew_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m   \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m   return sparse_tensor.SparseTensor(new_indices, new_values,\n\u001b[1;32m   1258\u001b[0m                                     array_ops.identity(sp_input.dense_shape))\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2734\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, axis, name)\u001b[0m\n\u001b[1;32m   3063\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 3065\u001b[0;31m         \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   3066\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3375\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3377\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3379\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, device, attrs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m   \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m       \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(d, **kw)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterlists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "rconfig = tf.estimator.RunConfig(log_step_count_steps = 10, save_summary_steps = 1)\n",
    "estimator_val = tf.estimator.Estimator(model_fn=make_model, params=hparams, config = rconfig)\n",
    "estimator_val.train(input_fn=lambda: input_fn(X_train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val   = list(estimator_val.predict(input_fn = lambda: input_fn(X_val, pred=True)))\n",
    "y_preds_val       = [int(x) for x in predictions_val]\n",
    "mean_absolute_precision_error(y_preds_val, X_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5', '_tf_random_seed': None, '_save_summary_steps': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c31be1cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.96330464, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.03075\n",
      "INFO:tensorflow:loss = 0.37314478, step = 11 (4.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.566\n",
      "INFO:tensorflow:loss = 0.18713543, step = 21 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6184\n",
      "INFO:tensorflow:loss = 0.16770242, step = 31 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5427\n",
      "INFO:tensorflow:loss = 0.16542837, step = 41 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7096\n",
      "INFO:tensorflow:loss = 0.17354688, step = 51 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7474\n",
      "INFO:tensorflow:loss = 0.1349669, step = 61 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5199\n",
      "INFO:tensorflow:loss = 0.16580014, step = 71 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8177\n",
      "INFO:tensorflow:loss = 0.16278715, step = 81 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6595\n",
      "INFO:tensorflow:loss = 0.15983663, step = 91 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6902\n",
      "INFO:tensorflow:loss = 0.18185878, step = 101 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7645\n",
      "INFO:tensorflow:loss = 0.1487975, step = 111 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7209\n",
      "INFO:tensorflow:loss = 0.16399008, step = 121 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5637\n",
      "INFO:tensorflow:loss = 0.15526162, step = 131 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6918\n",
      "INFO:tensorflow:loss = 0.15164378, step = 141 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6041\n",
      "INFO:tensorflow:loss = 0.16339892, step = 151 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7889\n",
      "INFO:tensorflow:loss = 0.16155116, step = 161 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2991\n",
      "INFO:tensorflow:loss = 0.17029212, step = 171 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6967\n",
      "INFO:tensorflow:loss = 0.14568733, step = 181 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5875\n",
      "INFO:tensorflow:loss = 0.16261101, step = 191 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5185\n",
      "INFO:tensorflow:loss = 0.15523918, step = 201 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7215\n",
      "INFO:tensorflow:loss = 0.2047869, step = 211 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7058\n",
      "INFO:tensorflow:loss = 0.16807266, step = 221 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5903\n",
      "INFO:tensorflow:loss = 0.16620511, step = 231 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6158\n",
      "INFO:tensorflow:loss = 0.15526778, step = 241 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2926\n",
      "INFO:tensorflow:loss = 0.15917684, step = 251 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3613\n",
      "INFO:tensorflow:loss = 0.18192197, step = 261 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.539\n",
      "INFO:tensorflow:loss = 0.16419949, step = 271 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8365\n",
      "INFO:tensorflow:loss = 0.13375373, step = 281 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2275\n",
      "INFO:tensorflow:loss = 0.14952022, step = 291 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6545\n",
      "INFO:tensorflow:loss = 0.19722205, step = 301 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6116\n",
      "INFO:tensorflow:loss = 0.16655493, step = 311 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7553\n",
      "INFO:tensorflow:loss = 0.18043369, step = 321 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7502\n",
      "INFO:tensorflow:loss = 0.14004123, step = 331 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6433\n",
      "INFO:tensorflow:loss = 0.15863004, step = 341 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9226\n",
      "INFO:tensorflow:loss = 0.15605995, step = 351 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5798\n",
      "INFO:tensorflow:loss = 0.1844933, step = 361 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9553\n",
      "INFO:tensorflow:loss = 0.15095773, step = 371 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1349\n",
      "INFO:tensorflow:loss = 0.14430979, step = 381 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0838\n",
      "INFO:tensorflow:loss = 0.17643243, step = 391 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8217\n",
      "INFO:tensorflow:loss = 0.16574878, step = 401 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1019\n",
      "INFO:tensorflow:loss = 0.15643835, step = 411 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1623\n",
      "INFO:tensorflow:loss = 0.15376195, step = 421 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9639\n",
      "INFO:tensorflow:loss = 0.16010371, step = 431 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1806\n",
      "INFO:tensorflow:loss = 0.15034789, step = 441 (0.618 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 450 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15684725.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c31be1ba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=make_model, params=hparams, config = rconfig)\n",
    "estimator.train(input_fn=lambda: input_fn(train_renamed), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5/model.ckpt-450\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.166182405034128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val   = list(estimator.predict(input_fn = lambda: input_fn(X_val, pred=True)))\n",
    "y_preds_val       = [int(x) for x in predictions_val]\n",
    "mean_absolute_precision_error(y_preds_val, X_val.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpwpps5sj5/model.ckpt-450\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions   = list(estimator.predict(input_fn = lambda: input_fn(test_renamed, pred=True)))\n",
    "y_preds_test   = [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission48.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "#rconfig = tf.estimator.RunConfig(log_step_count_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator_val = tf.estimator.DNNRegressor(model_fn=make_model, params=hparams, config = rconfig)\n",
    "#estimator_val.train(input_fn=lambda: input_fn(X_train), steps=TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
