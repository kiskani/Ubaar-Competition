{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(col):\n",
    "    return (col - np.mean(col)) / np.std(col)\n",
    "\n",
    "def get_score(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def scale_minmax(col):\n",
    "    return (col-col.min())/(col.max()-col.min())\n",
    "\n",
    "def mean_absolute_precision_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>SourceState_ids</th>\n",
       "      <th>destinationState_ids</th>\n",
       "      <th>vehicleType_ids</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39085</th>\n",
       "      <td>36.473089</td>\n",
       "      <td>52.349822</td>\n",
       "      <td>184.0</td>\n",
       "      <td>35.700109</td>\n",
       "      <td>51.399743</td>\n",
       "      <td>199.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>124</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1410</td>\n",
       "      <td>1774</td>\n",
       "      <td>1834.976428</td>\n",
       "      <td>1909.359717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>35.704176</td>\n",
       "      <td>51.400280</td>\n",
       "      <td>331.0</td>\n",
       "      <td>37.275731</td>\n",
       "      <td>49.584392</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>118</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1926</td>\n",
       "      <td>1515</td>\n",
       "      <td>1848.294458</td>\n",
       "      <td>1835.204644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45277</th>\n",
       "      <td>35.699924</td>\n",
       "      <td>51.396715</td>\n",
       "      <td>447.0</td>\n",
       "      <td>32.665899</td>\n",
       "      <td>51.663805</td>\n",
       "      <td>285.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>801</td>\n",
       "      <td>1515</td>\n",
       "      <td>1687.644636</td>\n",
       "      <td>1834.858819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>30.199563</td>\n",
       "      <td>53.182966</td>\n",
       "      <td>809.0</td>\n",
       "      <td>35.699078</td>\n",
       "      <td>51.401589</td>\n",
       "      <td>525.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1410</td>\n",
       "      <td>463</td>\n",
       "      <td>1834.989335</td>\n",
       "      <td>1606.102332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>27.180941</td>\n",
       "      <td>56.277756</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>34.643252</td>\n",
       "      <td>50.877469</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1176</td>\n",
       "      <td>72</td>\n",
       "      <td>1762.560980</td>\n",
       "      <td>1529.682365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       destinationLatitude  destinationLongitude  distanceKM  sourceLatitude  \\\n",
       "39085            36.473089             52.349822       184.0       35.700109   \n",
       "30892            35.704176             51.400280       331.0       37.275731   \n",
       "45277            35.699924             51.396715       447.0       32.665899   \n",
       "16398            30.199563             53.182966       809.0       35.699078   \n",
       "13653            27.180941             56.277756      1144.0       34.643252   \n",
       "\n",
       "       sourceLongitude  taxiDurationMin  weight  date_ids  SourceState_ids  \\\n",
       "39085        51.399743            199.0   21.00       124                7   \n",
       "30892        49.584392            254.0    1.67       118               29   \n",
       "45277        51.663805            285.0   19.00        83                3   \n",
       "16398        51.401589            525.0    4.00       151                7   \n",
       "13653        50.877469            750.0    2.00        85               17   \n",
       "\n",
       "       destinationState_ids  vehicleType_ids  vehicleOption_ids  \\\n",
       "39085                    19                3                  2   \n",
       "30892                     7                1                  5   \n",
       "45277                     7                3                  7   \n",
       "16398                    15                1                  5   \n",
       "13653                    21                1                  5   \n",
       "\n",
       "       source_tuple_ids  destination_tuple_ids       source  destination  \n",
       "39085              1410                   1774  1834.976428  1909.359717  \n",
       "30892              1926                   1515  1848.294458  1835.204644  \n",
       "45277               801                   1515  1687.644636  1834.858819  \n",
       "16398              1410                    463  1834.989335  1606.102332  \n",
       "13653              1176                     72  1762.560980  1529.682365  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "data      = data.dropna(axis = 0)\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "all_data = pd.concat((data, test_data)) \n",
    "min_price = min(all_data['price'])\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "BUCKET_LATI = 1000\n",
    "BUCKET_LONG = 1000\n",
    "\n",
    "min_source_lat  = min(all_data['sourceLatitude'])\n",
    "min_destin_lat  = min(all_data['destinationLatitude'])\n",
    "min_lat         = min(min_destin_lat, min_source_lat)\n",
    "min_source_long = min(all_data['sourceLongitude'])\n",
    "min_destin_long = min(all_data['destinationLongitude'])\n",
    "min_long        = min(min_destin_long, min_source_long)\n",
    "max_source_lat  = max(all_data['sourceLatitude'])\n",
    "max_destin_lat  = max(all_data['destinationLatitude'])\n",
    "max_lat         = max(max_destin_lat, max_source_lat)\n",
    "max_source_long = max(all_data['sourceLongitude'])\n",
    "max_destin_long = max(all_data['destinationLongitude'])\n",
    "max_long        = max(max_destin_long, max_source_long)\n",
    "d_lati          = (max_lat - min_lat)/BUCKET_LATI\n",
    "d_long          = (max_long - min_long)/BUCKET_LONG\n",
    "destin_lati_bucket = (all_data['destinationLatitude']  // d_lati).as_matrix().astype(int)\n",
    "destin_long_bucket = (all_data['destinationLongitude'] // d_long).as_matrix().astype(int)\n",
    "source_lati_bucket = (all_data['sourceLatitude']  // d_lati).as_matrix().astype(int)\n",
    "source_long_bucket = (all_data['sourceLongitude'] // d_long).as_matrix().astype(int)\n",
    "\n",
    "all_data['destination_tuple'] = tuple(zip(destin_lati_bucket,destin_long_bucket))\n",
    "all_data['source_tuple'] = tuple(zip(source_lati_bucket,source_long_bucket))\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', \n",
    "                    'vehicleOption', 'source_tuple', 'destination_tuple']\n",
    "\n",
    "all_data = all_data.copy()\n",
    "categorical_var_encoders = {}\n",
    "for var in categorical_vars:\n",
    "    le = preprocessing.LabelEncoder().fit(all_data[var])\n",
    "    all_data[var + '_ids']  = le.transform(all_data[var])\n",
    "    all_data[var + '_ids']  = all_data[var + '_ids'].astype('int32')\n",
    "    all_data.pop(var)\n",
    "    categorical_var_encoders[var] = le\n",
    "\n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "train_1, train_2 = train_test_split(train, test_size=0.5)\n",
    "\n",
    "X = train.drop(['ID','price'],axis=1)\n",
    "y = train.price\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "GBoost_1 = GradientBoostingRegressor(n_estimators=2200, learning_rate=0.05,\n",
    "                                     max_depth=10, max_features='sqrt',\n",
    "                                     min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "GBoost_2 = GradientBoostingRegressor(n_estimators=2200, learning_rate=0.05,\n",
    "                                     max_depth=10, max_features='sqrt',\n",
    "                                     min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "GBoost_1.fit(train_1.drop(['ID','price'],axis=1), train_1.price)\n",
    "GBoost_2.fit(train_2.drop(['ID','price'],axis=1), train_2.price)\n",
    "\n",
    "train_1['y_gboost'] = GBoost_2.predict(train_1.drop(['ID','price'],axis=1))\n",
    "train_2['y_gboost'] = GBoost_1.predict(train_2.drop(['ID','price'],axis=1))\n",
    "\n",
    "train_gboost = pd.concat([train_1, train_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "train_gboost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gboost_1, train_gboost_2 = train_test_split(train_gboost, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "xgb_1 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                         learning_rate=0.05, max_depth=10, \n",
    "                         min_child_weight=1.7817, n_estimators=2200,\n",
    "                         reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "xgb_2 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                         learning_rate=0.05, max_depth=10, \n",
    "                         min_child_weight=1.7817, n_estimators=2200,\n",
    "                         reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "xgb_1.fit(train_gboost_1.drop(['ID','price','y_gboost'],axis=1), train_gboost_1.price)\n",
    "xgb_2.fit(train_gboost_2.drop(['ID','price','y_gboost'],axis=1), train_gboost_2.price)\n",
    "\n",
    "train_gboost_1['y_xgb'] = xgb_2.predict(train_gboost_1.drop(['ID','price','y_gboost'],axis=1))\n",
    "train_gboost_2['y_xgb'] = xgb_1.predict(train_gboost_2.drop(['ID','price','y_gboost'],axis=1))\n",
    "\n",
    "train_xgb = pd.concat([train_gboost_1, train_gboost_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "train_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_1, train_xgb_2 = train_test_split(train_xgb, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "bag_1 = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "bag_2 = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "\n",
    "bag_1.fit(train_xgb_1.drop(['ID','price','y_gboost','y_xgb'],axis=1), train_xgb_1.price)\n",
    "bag_2.fit(train_xgb_2.drop(['ID','price','y_gboost','y_xgb'],axis=1), train_xgb_2.price)\n",
    "\n",
    "train_xgb_1['y_bag'] = bag_2.predict(train_xgb_1.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "train_xgb_2['y_bag'] = bag_1.predict(train_xgb_2.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "\n",
    "train_bag = pd.concat([train_xgb_1, train_xgb_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "train_bag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag.to_pickle('train_bag-gboost-xgb-bag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = pd.read_pickle('train_bag-gboost-xgb-bag.pkl')\n",
    "train_bag_1, train_bag_2 = train_test_split(train_bag, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_1 = KNeighborsClassifier(2)\n",
    "knn_2 = KNeighborsClassifier(2)\n",
    "\n",
    "knn_1.fit(train_bag_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1), train_bag_1.price)\n",
    "knn_2.fit(train_bag_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1), train_bag_2.price)\n",
    "\n",
    "train_bag_1['y_knn'] = knn_2.predict(train_bag_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "train_bag_2['y_knn'] = knn_1.predict(train_bag_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "\n",
    "train_knn = pd.concat([train_bag_1, train_bag_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "\n",
    "train_knn.to_pickle('train_knn-gboost-xgb-bag-knn.pkl')\n",
    "train_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knn = pd.read_pickle('train_knn-gboost-xgb-bag-knn.pkl')\n",
    "train_knn_1, train_knn_2 = train_test_split(train_knn, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25934</th>\n",
       "      <td>49546214185</td>\n",
       "      <td>29.601726</td>\n",
       "      <td>52.536354</td>\n",
       "      <td>903.0</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>35.297113</td>\n",
       "      <td>51.688604</td>\n",
       "      <td>596.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1309</td>\n",
       "      <td>380</td>\n",
       "      <td>1824.458496</td>\n",
       "      <td>1555.166756</td>\n",
       "      <td>3.498251e+06</td>\n",
       "      <td>4258389.00</td>\n",
       "      <td>4062616.0</td>\n",
       "      <td>6550000.0</td>\n",
       "      <td>5.015679e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36502</th>\n",
       "      <td>69190312164</td>\n",
       "      <td>32.684278</td>\n",
       "      <td>51.527953</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>8016000.0</td>\n",
       "      <td>38.554731</td>\n",
       "      <td>44.953984</td>\n",
       "      <td>716.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2134</td>\n",
       "      <td>879</td>\n",
       "      <td>1733.188760</td>\n",
       "      <td>1684.153941</td>\n",
       "      <td>7.401578e+06</td>\n",
       "      <td>8288081.00</td>\n",
       "      <td>8070903.0</td>\n",
       "      <td>5350000.0</td>\n",
       "      <td>7.769278e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>47329920421</td>\n",
       "      <td>30.236457</td>\n",
       "      <td>57.060089</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>15800000.0</td>\n",
       "      <td>38.001867</td>\n",
       "      <td>46.481661</td>\n",
       "      <td>954.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2068</td>\n",
       "      <td>468</td>\n",
       "      <td>1766.389899</td>\n",
       "      <td>1725.294927</td>\n",
       "      <td>1.563040e+07</td>\n",
       "      <td>15397732.00</td>\n",
       "      <td>16612712.0</td>\n",
       "      <td>8010000.0</td>\n",
       "      <td>1.643082e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44950</th>\n",
       "      <td>23430463430</td>\n",
       "      <td>36.552011</td>\n",
       "      <td>52.682001</td>\n",
       "      <td>214.0</td>\n",
       "      <td>3360000.0</td>\n",
       "      <td>35.694043</td>\n",
       "      <td>51.400397</td>\n",
       "      <td>223.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1410</td>\n",
       "      <td>1802</td>\n",
       "      <td>1834.687981</td>\n",
       "      <td>1925.633080</td>\n",
       "      <td>3.417438e+06</td>\n",
       "      <td>3101828.25</td>\n",
       "      <td>3105403.0</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>2.792254e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26718</th>\n",
       "      <td>42151095960</td>\n",
       "      <td>37.281714</td>\n",
       "      <td>49.585223</td>\n",
       "      <td>848.0</td>\n",
       "      <td>6960000.0</td>\n",
       "      <td>36.367480</td>\n",
       "      <td>56.197545</td>\n",
       "      <td>588.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1611</td>\n",
       "      <td>2079</td>\n",
       "      <td>2043.763094</td>\n",
       "      <td>1848.622103</td>\n",
       "      <td>8.382441e+06</td>\n",
       "      <td>6911363.00</td>\n",
       "      <td>8123832.0</td>\n",
       "      <td>9724000.0</td>\n",
       "      <td>6.400944e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  destinationLatitude  destinationLongitude  distanceKM  \\\n",
       "25934  49546214185            29.601726             52.536354       903.0   \n",
       "36502  69190312164            32.684278             51.527953      1056.0   \n",
       "1335   47329920421            30.236457             57.060089      1487.0   \n",
       "44950  23430463430            36.552011             52.682001       214.0   \n",
       "26718  42151095960            37.281714             49.585223       848.0   \n",
       "\n",
       "            price  sourceLatitude  sourceLongitude  taxiDurationMin  weight  \\\n",
       "25934   3700000.0       35.297113        51.688604            596.0     3.5   \n",
       "36502   8016000.0       38.554731        44.953984            716.0    10.0   \n",
       "1335   15800000.0       38.001867        46.481661            954.0    20.0   \n",
       "44950   3360000.0       35.694043        51.400397            223.0     4.5   \n",
       "26718   6960000.0       36.367480        56.197545            588.0    15.0   \n",
       "\n",
       "       date_ids      ...       vehicleOption_ids  source_tuple_ids  \\\n",
       "25934        51      ...                       6              1309   \n",
       "36502       107      ...                       0              2134   \n",
       "1335         33      ...                       7              2068   \n",
       "44950       149      ...                       1              1410   \n",
       "26718       128      ...                       0              1611   \n",
       "\n",
       "       destination_tuple_ids       source  destination      y_gboost  \\\n",
       "25934                    380  1824.458496  1555.166756  3.498251e+06   \n",
       "36502                    879  1733.188760  1684.153941  7.401578e+06   \n",
       "1335                     468  1766.389899  1725.294927  1.563040e+07   \n",
       "44950                   1802  1834.687981  1925.633080  3.417438e+06   \n",
       "26718                   2079  2043.763094  1848.622103  8.382441e+06   \n",
       "\n",
       "             y_xgb       y_bag      y_knn         y_dec  \n",
       "25934   4258389.00   4062616.0  6550000.0  5.015679e+06  \n",
       "36502   8288081.00   8070903.0  5350000.0  7.769278e+06  \n",
       "1335   15397732.00  16612712.0  8010000.0  1.643082e+07  \n",
       "44950   3101828.25   3105403.0  3500000.0  2.792254e+06  \n",
       "26718   6911363.00   8123832.0  9724000.0  6.400944e+06  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dec_1 = DecisionTreeRegressor(max_depth=10)\n",
    "dec_2 = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "dec_1.fit(train_knn_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1), train_knn_1.price)\n",
    "dec_2.fit(train_knn_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1), train_knn_2.price)\n",
    "\n",
    "train_knn_1['y_dec'] = dec_2.predict(train_knn_1.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "train_knn_2['y_dec'] = dec_1.predict(train_knn_2.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "\n",
    "train_dec = pd.concat([train_knn_1, train_knn_2])\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "\n",
    "train_dec.to_pickle('train_dec-gboost-xgb-bag-knn-dec.pkl')\n",
    "train_dec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "GBoost = GradientBoostingRegressor(n_estimators=2200, learning_rate=0.05,\n",
    "                                   max_depth=10, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=10, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1, nthread = -1)\n",
    "\n",
    "bag = BaggingRegressor(n_estimators=1000, max_samples=1.0, max_features=1.0, verbose=1)\n",
    "\n",
    "GBoost.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "xgb_model.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "bag.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "\n",
    "test['y_gboost'] = GBoost.predict(test.drop(['ID','price'],axis=1))\n",
    "test['y_xgb']    = xgb_model.predict(test.drop(['ID','price','y_gboost'],axis=1))\n",
    "test['y_bag']    = bag.predict(test.drop(['ID','price','y_gboost','y_xgb'],axis=1))\n",
    "\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle('test-gboost-xgb-bag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('test-gboost-xgb-bag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleType_ids</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010571124</td>\n",
       "      <td>35.579635</td>\n",
       "      <td>53.384990</td>\n",
       "      <td>684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.297213</td>\n",
       "      <td>59.607970</td>\n",
       "      <td>446.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1594</td>\n",
       "      <td>1477</td>\n",
       "      <td>2163.603184</td>\n",
       "      <td>1899.418459</td>\n",
       "      <td>2.394293e+06</td>\n",
       "      <td>2.257574e+06</td>\n",
       "      <td>2666167.0</td>\n",
       "      <td>2200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031704713</td>\n",
       "      <td>29.605761</td>\n",
       "      <td>52.533588</td>\n",
       "      <td>931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.704695</td>\n",
       "      <td>51.405194</td>\n",
       "      <td>614.0</td>\n",
       "      <td>19.14</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1410</td>\n",
       "      <td>380</td>\n",
       "      <td>1835.406773</td>\n",
       "      <td>1555.296851</td>\n",
       "      <td>9.998914e+06</td>\n",
       "      <td>9.769796e+06</td>\n",
       "      <td>9434639.0</td>\n",
       "      <td>10240000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10040911649</td>\n",
       "      <td>36.299593</td>\n",
       "      <td>59.612010</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.948490</td>\n",
       "      <td>55.583875</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1734</td>\n",
       "      <td>1497.901500</td>\n",
       "      <td>2163.891701</td>\n",
       "      <td>2.003906e+07</td>\n",
       "      <td>1.499457e+07</td>\n",
       "      <td>18011204.0</td>\n",
       "      <td>14750000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047106840</td>\n",
       "      <td>35.248298</td>\n",
       "      <td>58.457567</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.339066</td>\n",
       "      <td>52.075970</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1326</td>\n",
       "      <td>1358</td>\n",
       "      <td>1840.316141</td>\n",
       "      <td>2060.529742</td>\n",
       "      <td>1.754239e+06</td>\n",
       "      <td>2.022942e+06</td>\n",
       "      <td>2639174.0</td>\n",
       "      <td>2750000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10050126039</td>\n",
       "      <td>34.636832</td>\n",
       "      <td>50.874888</td>\n",
       "      <td>281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.579577</td>\n",
       "      <td>53.394403</td>\n",
       "      <td>181.0</td>\n",
       "      <td>23.50</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "      <td>1239</td>\n",
       "      <td>1899.750273</td>\n",
       "      <td>1762.144949</td>\n",
       "      <td>6.099514e+06</td>\n",
       "      <td>5.995565e+06</td>\n",
       "      <td>7125671.0</td>\n",
       "      <td>5200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  destinationLatitude  destinationLongitude  distanceKM  price  \\\n",
       "0  10010571124            35.579635             53.384990       684.0    NaN   \n",
       "1  10031704713            29.605761             52.533588       931.0    NaN   \n",
       "2  10040911649            36.299593             59.612010      1469.0    NaN   \n",
       "3  10047106840            35.248298             58.457567       745.0    NaN   \n",
       "4  10050126039            34.636832             50.874888       281.0    NaN   \n",
       "\n",
       "   sourceLatitude  sourceLongitude  taxiDurationMin  weight  date_ids  \\\n",
       "0       36.297213        59.607970            446.0    2.33       184   \n",
       "1       35.704695        51.405194            614.0   19.14        77   \n",
       "2       26.948490        55.583875           1009.0   22.00        51   \n",
       "3       35.339066        52.075970            496.0    2.50       176   \n",
       "4       35.579577        53.394403            181.0   23.50       142   \n",
       "\n",
       "      ...      vehicleType_ids  vehicleOption_ids  source_tuple_ids  \\\n",
       "0     ...                    1                  5              1594   \n",
       "1     ...                    3                  2              1410   \n",
       "2     ...                    3                  2                33   \n",
       "3     ...                    1                  6              1326   \n",
       "4     ...                    3                  4              1387   \n",
       "\n",
       "   destination_tuple_ids       source  destination      y_gboost  \\\n",
       "0                   1477  2163.603184  1899.418459  2.394293e+06   \n",
       "1                    380  1835.406773  1555.296851  9.998914e+06   \n",
       "2                   1734  1497.901500  2163.891701  2.003906e+07   \n",
       "3                   1358  1840.316141  2060.529742  1.754239e+06   \n",
       "4                   1239  1899.750273  1762.144949  6.099514e+06   \n",
       "\n",
       "          y_xgb       y_bag       y_knn  \n",
       "0  2.257574e+06   2666167.0   2200000.0  \n",
       "1  9.769796e+06   9434639.0  10240000.0  \n",
       "2  1.499457e+07  18011204.0  14750000.0  \n",
       "3  2.022942e+06   2639174.0   2750000.0  \n",
       "4  5.995565e+06   7125671.0   5200000.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "knn = KNeighborsClassifier(2)\n",
    "knn.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "test['y_knn']    = knn.predict(test.drop(['ID','price','y_gboost','y_xgb', 'y_bag'],axis=1))\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "\n",
    "test.to_pickle('test-gboost-xgb-bag-knn.pkl')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('test-gboost-xgb-bag-knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>destinationLatitude</th>\n",
       "      <th>destinationLongitude</th>\n",
       "      <th>distanceKM</th>\n",
       "      <th>price</th>\n",
       "      <th>sourceLatitude</th>\n",
       "      <th>sourceLongitude</th>\n",
       "      <th>taxiDurationMin</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_ids</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleOption_ids</th>\n",
       "      <th>source_tuple_ids</th>\n",
       "      <th>destination_tuple_ids</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>y_gboost</th>\n",
       "      <th>y_xgb</th>\n",
       "      <th>y_bag</th>\n",
       "      <th>y_knn</th>\n",
       "      <th>y_dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010571124</td>\n",
       "      <td>35.579635</td>\n",
       "      <td>53.384990</td>\n",
       "      <td>684.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.297213</td>\n",
       "      <td>59.607970</td>\n",
       "      <td>446.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1594</td>\n",
       "      <td>1477</td>\n",
       "      <td>2163.603184</td>\n",
       "      <td>1899.418459</td>\n",
       "      <td>2.394293e+06</td>\n",
       "      <td>2.257574e+06</td>\n",
       "      <td>2666167.0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>2.582923e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031704713</td>\n",
       "      <td>29.605761</td>\n",
       "      <td>52.533588</td>\n",
       "      <td>931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.704695</td>\n",
       "      <td>51.405194</td>\n",
       "      <td>614.0</td>\n",
       "      <td>19.14</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1410</td>\n",
       "      <td>380</td>\n",
       "      <td>1835.406773</td>\n",
       "      <td>1555.296851</td>\n",
       "      <td>9.998914e+06</td>\n",
       "      <td>9.769796e+06</td>\n",
       "      <td>9434639.0</td>\n",
       "      <td>10240000.0</td>\n",
       "      <td>1.057049e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10040911649</td>\n",
       "      <td>36.299593</td>\n",
       "      <td>59.612010</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.948490</td>\n",
       "      <td>55.583875</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1734</td>\n",
       "      <td>1497.901500</td>\n",
       "      <td>2163.891701</td>\n",
       "      <td>2.003906e+07</td>\n",
       "      <td>1.499457e+07</td>\n",
       "      <td>18011204.0</td>\n",
       "      <td>14750000.0</td>\n",
       "      <td>2.386508e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047106840</td>\n",
       "      <td>35.248298</td>\n",
       "      <td>58.457567</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.339066</td>\n",
       "      <td>52.075970</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1326</td>\n",
       "      <td>1358</td>\n",
       "      <td>1840.316141</td>\n",
       "      <td>2060.529742</td>\n",
       "      <td>1.754239e+06</td>\n",
       "      <td>2.022942e+06</td>\n",
       "      <td>2639174.0</td>\n",
       "      <td>2750000.0</td>\n",
       "      <td>4.030971e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10050126039</td>\n",
       "      <td>34.636832</td>\n",
       "      <td>50.874888</td>\n",
       "      <td>281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.579577</td>\n",
       "      <td>53.394403</td>\n",
       "      <td>181.0</td>\n",
       "      <td>23.50</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "      <td>1239</td>\n",
       "      <td>1899.750273</td>\n",
       "      <td>1762.144949</td>\n",
       "      <td>6.099514e+06</td>\n",
       "      <td>5.995565e+06</td>\n",
       "      <td>7125671.0</td>\n",
       "      <td>5200000.0</td>\n",
       "      <td>5.984402e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  destinationLatitude  destinationLongitude  distanceKM  price  \\\n",
       "0  10010571124            35.579635             53.384990       684.0    NaN   \n",
       "1  10031704713            29.605761             52.533588       931.0    NaN   \n",
       "2  10040911649            36.299593             59.612010      1469.0    NaN   \n",
       "3  10047106840            35.248298             58.457567       745.0    NaN   \n",
       "4  10050126039            34.636832             50.874888       281.0    NaN   \n",
       "\n",
       "   sourceLatitude  sourceLongitude  taxiDurationMin  weight  date_ids  \\\n",
       "0       36.297213        59.607970            446.0    2.33       184   \n",
       "1       35.704695        51.405194            614.0   19.14        77   \n",
       "2       26.948490        55.583875           1009.0   22.00        51   \n",
       "3       35.339066        52.075970            496.0    2.50       176   \n",
       "4       35.579577        53.394403            181.0   23.50       142   \n",
       "\n",
       "       ...       vehicleOption_ids  source_tuple_ids  destination_tuple_ids  \\\n",
       "0      ...                       5              1594                   1477   \n",
       "1      ...                       2              1410                    380   \n",
       "2      ...                       2                33                   1734   \n",
       "3      ...                       6              1326                   1358   \n",
       "4      ...                       4              1387                   1239   \n",
       "\n",
       "        source  destination      y_gboost         y_xgb       y_bag  \\\n",
       "0  2163.603184  1899.418459  2.394293e+06  2.257574e+06   2666167.0   \n",
       "1  1835.406773  1555.296851  9.998914e+06  9.769796e+06   9434639.0   \n",
       "2  1497.901500  2163.891701  2.003906e+07  1.499457e+07  18011204.0   \n",
       "3  1840.316141  2060.529742  1.754239e+06  2.022942e+06   2639174.0   \n",
       "4  1899.750273  1762.144949  6.099514e+06  5.995565e+06   7125671.0   \n",
       "\n",
       "        y_knn         y_dec  \n",
       "0   2200000.0  2.582923e+06  \n",
       "1  10240000.0  1.057049e+07  \n",
       "2  14750000.0  2.386508e+07  \n",
       "3   2750000.0  4.030971e+06  \n",
       "4   5200000.0  5.984402e+06  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "dec = DecisionTreeRegressor(max_depth=10)\n",
    "dec.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "test['y_dec']    = dec.predict(test.drop(['ID','price','y_gboost','y_xgb', 'y_bag', 'y_knn'],axis=1))\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) )\n",
    "\n",
    "test.to_pickle('test-gboost-xgb-bag-knn-dec.pkl')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow combination  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE          = 128\n",
    "TRAIN_EPOCHS        = 1500\n",
    "BIN_GRANULARITY     = 100\n",
    "HIDDEN_LAYER_1_SIZE = 64\n",
    "HIDDEN_LAYER_2_SIZE = 64\n",
    "HIDDEN_LAYER_3_SIZE = 16\n",
    "lr                  = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_longitudes = set(all_data['sourceLongitude'].tolist() + all_data['destinationLongitude'].tolist())\n",
    "all_latitude   = set(all_data['sourceLatitude'].tolist() + all_data['destinationLatitude'].tolist())\n",
    "\n",
    "binned_long = np.linspace(min(all_longitudes), max(all_longitudes), BIN_GRANULARITY).tolist()\n",
    "binned_lat  = np.linspace(min(all_latitude), max(all_latitude), BIN_GRANULARITY).tolist()\n",
    "\n",
    "y_gboost_feat = tf.feature_column.numeric_column(\"y_gboost\")\n",
    "y_xgb_feat    = tf.feature_column.numeric_column(\"y_xgb\")\n",
    "y_bag_feat    = tf.feature_column.numeric_column(\"y_bag\")\n",
    "y_knn_feat    = tf.feature_column.numeric_column(\"y_knn\")\n",
    "y_dec_feat    = tf.feature_column.numeric_column(\"y_dec\")\n",
    "\n",
    "source_lat_feat         = tf.feature_column.numeric_column(\"sourceLatitude\") \n",
    "source_long_feat        = tf.feature_column.numeric_column(\"sourceLongitude\") \n",
    "destin_lat_feat         = tf.feature_column.numeric_column(\"destinationLatitude\") \n",
    "destin_long_feat        = tf.feature_column.numeric_column(\"destinationLongitude\") \n",
    "\n",
    "binned_source_lat_feat  = tf.feature_column.bucketized_column(\n",
    "                              source_column=source_lat_feat,\n",
    "                              boundaries= binned_lat)\n",
    "binned_source_long_feat = tf.feature_column.bucketized_column(\n",
    "                              source_column=source_long_feat,\n",
    "                              boundaries= binned_long)\n",
    "binned_destin_lat_feat  = tf.feature_column.bucketized_column(\n",
    "                              source_column=destin_lat_feat,\n",
    "                              boundaries= binned_lat)\n",
    "binned_destin_long_feat = tf.feature_column.bucketized_column(\n",
    "                              source_column=destin_long_feat,\n",
    "                              boundaries= binned_long)\n",
    "\n",
    "source_lat_x_long = tf.feature_column.embedding_column(tf.feature_column.crossed_column(\n",
    "                    keys=[binned_source_lat_feat, binned_source_long_feat], \n",
    "                    hash_bucket_size=BIN_GRANULARITY *BIN_GRANULARITY),dimension=BIN_GRANULARITY)\n",
    "\n",
    "destin_lat_x_long = tf.feature_column.embedding_column(tf.feature_column.crossed_column(\n",
    "                    keys=[binned_destin_lat_feat, binned_destin_long_feat], \n",
    "                    hash_bucket_size=BIN_GRANULARITY *BIN_GRANULARITY),dimension=BIN_GRANULARITY)\n",
    "\n",
    "distance_feat = tf.feature_column.numeric_column(\"distanceKM\")\n",
    "taximin_feat  = tf.feature_column.numeric_column(\"taxiDurationMin\")\n",
    "weight_feat   = tf.feature_column.numeric_column(\"weight\")\n",
    "\n",
    "date_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"date_ids\", 186),8)\n",
    "\n",
    "source_state_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"SourceState_ids\", 31),5)\n",
    "\n",
    "destin_state_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"destinationState_ids\", 31),5)\n",
    "\n",
    "veh_type_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"vehicleType_ids\", 4),2)\n",
    "\n",
    "veh_option_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"vehicleOption_ids\", 9),4)\n",
    "\n",
    "source_feat   = tf.feature_column.numeric_column(\"source\")\n",
    "destin_feat   = tf.feature_column.numeric_column(\"destination\")\n",
    "\n",
    "destination_tuple_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"destination_tuple_ids\", 2191),20)\n",
    " \n",
    "source_tuple_feat = tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\"source_tuple_ids\", 2191),20)\n",
    "\n",
    "feature_columns = {y_gboost_feat, y_xgb_feat, y_bag_feat, y_knn_feat, source_lat_x_long, destin_lat_x_long, \n",
    "                   distance_feat, taximin_feat,\n",
    "                   weight_feat, date_feat, source_state_feat, destin_state_feat,\n",
    "                   veh_type_feat, veh_option_feat, source_feat, destin_feat}#,\n",
    "\n",
    "feature_columns = {y_gboost_feat, y_xgb_feat, y_bag_feat, y_knn_feat, y_dec_feat}\n",
    "\n",
    "#                   destination_tuple_feat, source_tuple_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(features, labels, mode, params, config):\n",
    "    input_layer = tf.feature_column.input_layer(features=features, \n",
    "                                                feature_columns=feature_columns)\n",
    "    \n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    x = tf.layers.dense(inputs=input_layer,\n",
    "                        units=HIDDEN_LAYER_1_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"first_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dropout(inputs=x,name=\"first_dropout\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_2_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"second_fully_connected_layer\")\n",
    "\n",
    "    x = tf.layers.dense(inputs=x,\n",
    "                        units=HIDDEN_LAYER_3_SIZE,\n",
    "                        activation=tf.nn.relu,\n",
    "                        name=\"third_fully_connected_layer\")\n",
    "\n",
    "    predictions = tf.contrib.layers.fully_connected(inputs=x, num_outputs=1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT :\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss)\n",
    "    else:\n",
    "        #loss = tf.losses.absolute_difference(labels=labels,\n",
    "        #                                    predictions=predictions)\n",
    "        loss  = tf.reduce_mean(tf.abs(tf.divide(predictions-labels,labels))) \n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss, \n",
    "                                      global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                          predictions=predictions,\n",
    "                                          loss=loss, \n",
    "                                          train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, pred = False):\n",
    "        \n",
    "    useful_fueatures = [\n",
    "        np.array(df[\"y_gboost\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_xgb\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_bag\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_knn\"].values, dtype=np.float32),\n",
    "        np.array(df[\"y_dec\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"sourceLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLatitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destinationLongitude\"].values, dtype=np.float32),\n",
    "        np.array(df[\"distanceKM\"].values, dtype=np.float32),\n",
    "        np.array(df[\"taxiDurationMin\"].values, dtype=np.float32),\n",
    "        np.array(df[\"weight\"].values, dtype=np.float32),\n",
    "        np.array(df[\"date_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"SourceState_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"destinationState_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"vehicleType_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"vehicleOption_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"source\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination\"].values, dtype=np.float32),\n",
    "        np.array(df[\"destination_tuple_ids\"].values, dtype=np.int32),\n",
    "        np.array(df[\"source_tuple_ids\"].values, dtype=np.int32)\n",
    "    ]\n",
    "\n",
    "    if pred: \n",
    "        train_number = 1\n",
    "        batch_number = 1\n",
    "    else:\n",
    "        useful_fueatures.append(np.array(df[\"price\"].values, dtype=np.float32))\n",
    "        train_number = TRAIN_EPOCHS\n",
    "        batch_number = BATCH_SIZE\n",
    "        \n",
    "    A = tf.train.slice_input_producer(\n",
    "        tensor_list=useful_fueatures,\n",
    "        num_epochs=train_number,\n",
    "        shuffle= not pred,\n",
    "        capacity=BATCH_SIZE * 5\n",
    "    )\n",
    "    \n",
    "    y_gboost              = A[0]\n",
    "    y_xgb                 = A[1]\n",
    "    y_bag                 = A[2]\n",
    "    y_knn                 = A[3]\n",
    "    y_dec                 = A[4]\n",
    "    sourceLatitude        = A[5]\n",
    "    sourceLongitude       = A[6]\n",
    "    destinationLatitude   = A[7]\n",
    "    destinationLongitude  = A[8]\n",
    "    distanceKM            = A[9]\n",
    "    taxiDurationMin       = A[10] \n",
    "    weight                = A[11]\n",
    "    date_ids              = A[12]\n",
    "    SourceState_ids       = A[13]\n",
    "    destinationState_ids  = A[14]\n",
    "    vehicleType_ids       = A[15]\n",
    "    vehicleOption_ids     = A[16]\n",
    "    source                = A[17]\n",
    "    destination           = A[18] \n",
    "    destination_tuple_ids = A[19] \n",
    "    source_tuple_ids      = A[20] \n",
    "    \n",
    "    # Created a dict out of sliced input producers\n",
    "    dataset_dict = dict(\n",
    "        y_gboost=y_gboost,\n",
    "        y_xgb=y_xgb,\n",
    "        y_bag=y_bag,\n",
    "        y_knn=y_knn,\n",
    "        y_dec=y_dec,\n",
    "        #sourceLatitude=sourceLatitude,\n",
    "        #sourceLongitude=sourceLongitude,\n",
    "        #destinationLatitude=destinationLatitude,\n",
    "        #destinationLongitude=destinationLongitude, \n",
    "        #distanceKM=distanceKM,\n",
    "        #taxiDurationMin=taxiDurationMin,\n",
    "        #weight=weight,\n",
    "        #date_ids=date_ids,\n",
    "        #SourceState_ids=SourceState_ids,\n",
    "        #destinationState_ids=destinationState_ids,\n",
    "        #vehicleType_ids=vehicleType_ids,\n",
    "        #vehicleOption_ids=vehicleOption_ids,\n",
    "        #source=source, \n",
    "        #destination=destination,\n",
    "        #destination_tuple_ids=destination_tuple_ids,\n",
    "        #source_tuple_ids=source_tuple_ids,\n",
    "    )\n",
    "\n",
    "    if not pred:\n",
    "        dataset_dict['labels'] = A[21]\n",
    "            \n",
    "    batch_dict = tf.train.batch(\n",
    "        dataset_dict,\n",
    "        batch_number,\n",
    "   )\n",
    "\n",
    "    if pred == False:\n",
    "        batch_labels = batch_dict.pop('labels')\n",
    "        return batch_dict, tf.reshape(batch_labels, [-1, 1]) \n",
    "    else:\n",
    "        return batch_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag = pd.read_pickle('train_bag-gboost-xgb-bag.pkl')\n",
    "test      = pd.read_pickle('test-gboost-xgb-bag.pkl')\n",
    "X_train_bag, X_val_bag = train_test_split(train_bag, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_knn = pd.read_pickle('train_knn-gboost-xgb-bag-knn.pkl')\n",
    "test      = pd.read_pickle('test-gboost-xgb-bag-knn.pkl')\n",
    "X_train_knn, X_val_knn = train_test_split(train_knn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dec = pd.read_pickle('train_dec-gboost-xgb-bag-knn-dec.pkl')\n",
    "test      = pd.read_pickle('test-gboost-xgb-bag-knn-dec.pkl')\n",
    "X_train_dec, X_val_dec = train_test_split(train_dec, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2e60d208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.67619205, step = 1\n",
      "INFO:tensorflow:global_step/sec: 85.6558\n",
      "INFO:tensorflow:loss = 0.56022644, step = 101 (1.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.2811\n",
      "INFO:tensorflow:loss = 0.4944248, step = 201 (1.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9519\n",
      "INFO:tensorflow:loss = 0.41204786, step = 301 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7872\n",
      "INFO:tensorflow:loss = 0.32849687, step = 401 (1.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7195\n",
      "INFO:tensorflow:loss = 0.2955971, step = 501 (1.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7925\n",
      "INFO:tensorflow:loss = 0.24411264, step = 601 (1.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.8886\n",
      "INFO:tensorflow:loss = 0.22952439, step = 701 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.8828\n",
      "INFO:tensorflow:loss = 0.2222776, step = 801 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.413\n",
      "INFO:tensorflow:loss = 0.19814369, step = 901 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7714\n",
      "INFO:tensorflow:loss = 0.21792194, step = 1001 (1.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.0248\n",
      "INFO:tensorflow:loss = 0.20371622, step = 1101 (1.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.113\n",
      "INFO:tensorflow:loss = 0.21889724, step = 1201 (1.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8752\n",
      "INFO:tensorflow:loss = 0.19389069, step = 1301 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.5514\n",
      "INFO:tensorflow:loss = 0.17305613, step = 1401 (1.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.933\n",
      "INFO:tensorflow:loss = 0.20391166, step = 1501 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9309\n",
      "INFO:tensorflow:loss = 0.20334902, step = 1601 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5347\n",
      "INFO:tensorflow:loss = 0.20186438, step = 1701 (1.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3648\n",
      "INFO:tensorflow:loss = 0.17782669, step = 1801 (1.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8217\n",
      "INFO:tensorflow:loss = 0.17942661, step = 1901 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4766\n",
      "INFO:tensorflow:loss = 0.16913857, step = 2001 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3562\n",
      "INFO:tensorflow:loss = 0.17598832, step = 2101 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2449\n",
      "INFO:tensorflow:loss = 0.15990755, step = 2201 (1.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8202\n",
      "INFO:tensorflow:loss = 0.17521197, step = 2301 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5341\n",
      "INFO:tensorflow:loss = 0.17186166, step = 2401 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3031\n",
      "INFO:tensorflow:loss = 0.16585648, step = 2501 (1.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9266\n",
      "INFO:tensorflow:loss = 0.17340055, step = 2601 (1.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.0298\n",
      "INFO:tensorflow:loss = 0.18698777, step = 2701 (1.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7474\n",
      "INFO:tensorflow:loss = 0.20579089, step = 2801 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9753\n",
      "INFO:tensorflow:loss = 0.16269392, step = 2901 (1.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.074\n",
      "INFO:tensorflow:loss = 0.18827301, step = 3001 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.745\n",
      "INFO:tensorflow:loss = 0.1764122, step = 3101 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5253\n",
      "INFO:tensorflow:loss = 0.13454865, step = 3201 (1.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.4337\n",
      "INFO:tensorflow:loss = 0.16033268, step = 3301 (1.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1232\n",
      "INFO:tensorflow:loss = 0.17468128, step = 3401 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.2936\n",
      "INFO:tensorflow:loss = 0.18724094, step = 3501 (1.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5899\n",
      "INFO:tensorflow:loss = 0.16131972, step = 3601 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7021\n",
      "INFO:tensorflow:loss = 0.18079957, step = 3701 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.2796\n",
      "INFO:tensorflow:loss = 0.17532048, step = 3801 (1.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.6686\n",
      "INFO:tensorflow:loss = 0.19268249, step = 3901 (1.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5659\n",
      "INFO:tensorflow:loss = 0.16813219, step = 4001 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9589\n",
      "INFO:tensorflow:loss = 0.15110382, step = 4101 (1.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7003\n",
      "INFO:tensorflow:loss = 0.14344488, step = 4201 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.8414\n",
      "INFO:tensorflow:loss = 0.17946936, step = 4301 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.5886\n",
      "INFO:tensorflow:loss = 0.15775004, step = 4401 (1.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.2398\n",
      "INFO:tensorflow:loss = 0.17073378, step = 4501 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9466\n",
      "INFO:tensorflow:loss = 0.18913747, step = 4601 (1.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9901\n",
      "INFO:tensorflow:loss = 0.19371817, step = 4701 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1312\n",
      "INFO:tensorflow:loss = 0.17343628, step = 4801 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1889\n",
      "INFO:tensorflow:loss = 0.16711949, step = 4901 (1.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8727\n",
      "INFO:tensorflow:loss = 0.18363073, step = 5001 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.84\n",
      "INFO:tensorflow:loss = 0.18033919, step = 5101 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.6103\n",
      "INFO:tensorflow:loss = 0.19424127, step = 5201 (1.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2203\n",
      "INFO:tensorflow:loss = 0.17909642, step = 5301 (1.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.549\n",
      "INFO:tensorflow:loss = 0.15574029, step = 5401 (1.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8374\n",
      "INFO:tensorflow:loss = 0.18304035, step = 5501 (1.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.6627\n",
      "INFO:tensorflow:loss = 0.15725373, step = 5601 (1.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1982\n",
      "INFO:tensorflow:loss = 0.16516152, step = 5701 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4951\n",
      "INFO:tensorflow:loss = 0.19412968, step = 5801 (1.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8113\n",
      "INFO:tensorflow:loss = 0.18862751, step = 5901 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7059\n",
      "INFO:tensorflow:loss = 0.17369312, step = 6001 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.546\n",
      "INFO:tensorflow:loss = 0.16393249, step = 6101 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1591\n",
      "INFO:tensorflow:loss = 0.19127576, step = 6201 (1.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5003\n",
      "INFO:tensorflow:loss = 0.1691814, step = 6301 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9897\n",
      "INFO:tensorflow:loss = 0.17493911, step = 6401 (1.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9622\n",
      "INFO:tensorflow:loss = 0.14676055, step = 6501 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9746\n",
      "INFO:tensorflow:loss = 0.15646167, step = 6601 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1878\n",
      "INFO:tensorflow:loss = 0.15519743, step = 6701 (1.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0771\n",
      "INFO:tensorflow:loss = 0.15640938, step = 6801 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.108\n",
      "INFO:tensorflow:loss = 0.16083145, step = 6901 (1.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.22769347.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a2e60d0b8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(learning_rate=lr)\n",
    "estimator_val = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator_val.train(input_fn=lambda: input_fn(X_train_dec), steps=7000)#TRAIN_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.103851329561927"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_val   = list(estimator_val.predict(input_fn = lambda: input_fn(X_val_dec, pred=True)))\n",
    "y_preds_val       = [int(x) for x in predictions_val]\n",
    "mean_absolute_precision_error(X_val_dec.price, y_preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp0fpg30a5\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp0fpg30a5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2ccc8ac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp0fpg30a5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7484628, step = 1\n",
      "INFO:tensorflow:global_step/sec: 85.8732\n",
      "INFO:tensorflow:loss = 0.63077515, step = 101 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.4173\n",
      "INFO:tensorflow:loss = 0.49957123, step = 201 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8617\n",
      "INFO:tensorflow:loss = 0.3808717, step = 301 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.442\n",
      "INFO:tensorflow:loss = 0.28849262, step = 401 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0491\n",
      "INFO:tensorflow:loss = 0.19433945, step = 501 (1.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5281\n",
      "INFO:tensorflow:loss = 0.20945725, step = 601 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1094\n",
      "INFO:tensorflow:loss = 0.16452119, step = 701 (1.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.8528\n",
      "INFO:tensorflow:loss = 0.17528467, step = 801 (1.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.2238\n",
      "INFO:tensorflow:loss = 0.1845215, step = 901 (1.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5269\n",
      "INFO:tensorflow:loss = 0.16378039, step = 1001 (1.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1539\n",
      "INFO:tensorflow:loss = 0.17335421, step = 1101 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9942\n",
      "INFO:tensorflow:loss = 0.18314408, step = 1201 (1.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.0377\n",
      "INFO:tensorflow:loss = 0.17377733, step = 1301 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.5297\n",
      "INFO:tensorflow:loss = 0.14504586, step = 1401 (1.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.284\n",
      "INFO:tensorflow:loss = 0.17701608, step = 1501 (1.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.326\n",
      "INFO:tensorflow:loss = 0.20872399, step = 1601 (1.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.7559\n",
      "INFO:tensorflow:loss = 0.1784248, step = 1701 (1.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.882\n",
      "INFO:tensorflow:loss = 0.16234323, step = 1801 (1.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2224\n",
      "INFO:tensorflow:loss = 0.17188784, step = 1901 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4014\n",
      "INFO:tensorflow:loss = 0.18663213, step = 2001 (1.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9708\n",
      "INFO:tensorflow:loss = 0.16936862, step = 2101 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5\n",
      "INFO:tensorflow:loss = 0.17098247, step = 2201 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.3709\n",
      "INFO:tensorflow:loss = 0.21767215, step = 2301 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8688\n",
      "INFO:tensorflow:loss = 0.15876934, step = 2401 (1.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.7157\n",
      "INFO:tensorflow:loss = 0.1511419, step = 2501 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.9213\n",
      "INFO:tensorflow:loss = 0.17069033, step = 2601 (1.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4098\n",
      "INFO:tensorflow:loss = 0.19071782, step = 2701 (1.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.644\n",
      "INFO:tensorflow:loss = 0.1648787, step = 2801 (1.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7383\n",
      "INFO:tensorflow:loss = 0.17512251, step = 2901 (1.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.3144\n",
      "INFO:tensorflow:loss = 0.18516612, step = 3001 (1.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.962\n",
      "INFO:tensorflow:loss = 0.16537774, step = 3101 (1.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2312\n",
      "INFO:tensorflow:loss = 0.14742446, step = 3201 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7178\n",
      "INFO:tensorflow:loss = 0.17436752, step = 3301 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.7216\n",
      "INFO:tensorflow:loss = 0.15461372, step = 3401 (1.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.4146\n",
      "INFO:tensorflow:loss = 0.17251459, step = 3501 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2985\n",
      "INFO:tensorflow:loss = 0.16788273, step = 3601 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.2728\n",
      "INFO:tensorflow:loss = 0.15165025, step = 3701 (1.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3750 into /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmp0fpg30a5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.16725886.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1a2ccc8518>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=make_model, params=hparams)\n",
    "estimator.train(input_fn=lambda: input_fn(train_dec), steps=TRAIN_EPOCHS*2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/hy/j_c72d1x72g_rr58tgrlh3b40000gn/T/tmpbvqd3fxq/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions   = list(estimator_val.predict(input_fn = lambda: input_fn(test, pred=True)))\n",
    "y_preds_test   = [int(x) for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission25.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(len(y_preds_test)):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_preds_test[i])))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submission 19 with loss of 15.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
