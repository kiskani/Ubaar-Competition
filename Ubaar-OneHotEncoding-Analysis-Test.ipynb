{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "import datetime\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingRegressor, StackingCVRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import model_selection \n",
    "from collections import defaultdict\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_func(labels, preds):\n",
    "    return np.mean(np.abs((preds - labels)/(labels))) * 100\n",
    "\n",
    "mape_score = make_scorer(mape_func)#, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39645, 84)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data      = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/train.csv')\n",
    "test_data = pd.read_csv('/Users/mohsenkiskani/.kaggle/competitions/ubaar-competition/test.csv')\n",
    "\n",
    "# Remove NANs\n",
    "data      = data.dropna(axis = 0)\n",
    "\n",
    "# Remove outliers\n",
    "data.drop([28098])\n",
    "THRESHOLD = 4.5e7\n",
    "Aa = data[data.price > THRESHOLD]\n",
    "data = data.drop(Aa.index.tolist())\n",
    "\n",
    "specific_cols = ['distanceKM', 'taxiDurationMin', 'weight']\n",
    "removed_indices = []\n",
    "for col in specific_cols:\n",
    "    df = data['price']/data[col]\n",
    "    A = df[~df.isin([np.nan, np.inf, -np.inf])]\n",
    "    B = (A - np.mean(A)) / np.std(A)\n",
    "    V = B[B > 5]\n",
    "    removed_indices.extend(V.index.tolist())\n",
    "data = data.drop(set(removed_indices))\n",
    "\n",
    "# Fill test NANs\n",
    "test_data.loc[12577, 'distanceKM']      = 52\n",
    "test_data.loc[12577, 'taxiDurationMin'] = 50\n",
    "test_data.loc[13853, 'distanceKM']      = 500\n",
    "test_data.loc[13853, 'taxiDurationMin'] = 380\n",
    "\n",
    "all_data = pd.concat((data, test_data)) \n",
    "all_data['source']           = all_data['sourceLatitude']*all_data['sourceLongitude']\n",
    "all_data['destination']      = all_data['destinationLatitude']*all_data['destinationLongitude']\n",
    "\n",
    "#all_data['dist2']      = all_data['distanceKM']*all_data['distanceKM']\n",
    "#all_data['dist3']      = all_data['dist2']*all_data['distanceKM']\n",
    "#all_data['taxi2']      = all_data['taxiDurationMin']*all_data['taxiDurationMin']\n",
    "#all_data['taxi3']      = all_data['taxi2']*all_data['taxiDurationMin']\n",
    "#all_data['weight2']      = all_data['weight']*all_data['weight']\n",
    "#all_data['weight3']      = all_data['weight2']*all_data['weight']\n",
    "#all_data['source2']      = all_data['source']*all_data['source']\n",
    "#all_data['destination2']      = all_data['destination']*all_data['destination']\n",
    "#all_data['destinationlat2']      = all_data['destinationLatitude']*all_data['destinationLatitude']\n",
    "#all_data['destinationlon2']      = all_data['destinationLongitude']*all_data['destinationLongitude']\n",
    "\n",
    "ntrain = data.shape[0]\n",
    "ntest  = test_data.shape[0]\n",
    "\n",
    "categorical_vars = ['date', 'SourceState', 'destinationState', 'vehicleType', 'vehicleOption']\n",
    "\n",
    "dummies_data = pd.get_dummies(all_data[categorical_vars])\n",
    "all_data[dummies_data.columns] = dummies_data[dummies_data.columns]\n",
    "all_data.drop(categorical_vars, axis=1, inplace=True)\n",
    "\n",
    "train    = all_data[:ntrain]\n",
    "test     = all_data[ntrain:]\n",
    "\n",
    "feat_names = all_data.columns.tolist()\n",
    "feat_names.remove('ID')\n",
    "feat_names.remove('price')\n",
    "\n",
    "X = train.drop(['ID','price'],axis=1)\n",
    "y = train.price\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=3):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                #instance.fit(X[train_index], y[train_index])\n",
    "                instance.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(dict)\n",
    "\n",
    "def benchmark(est, name=None, cv=False):\n",
    "    if not name:\n",
    "        name = est.__class__.__name__\n",
    "    print(\"Started benchmarking    \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    if not cv:\n",
    "        t0 = time.time()\n",
    "        est.fit(X_train, y_train)\n",
    "        res[name]['train_time'] = (time.time() - t0)/60\n",
    "        t0 = time.time()\n",
    "        pred = est.predict(X_val)\n",
    "        res[name]['test_time'] = (time.time() - t0)/60\n",
    "        res[name]['MAPE'] = mape_func(y_val, pred)\n",
    "    else:\n",
    "        t0 = time.time()\n",
    "        res[name]['cv_score'] = np.mean(model_selection.cross_val_score(est, X, y, scoring=mape_score, cv = 3))\n",
    "        res[name]['cv_time'] = (time.time() - t0)/60\n",
    "    print(\"Done benchmarking       \" + name + \"        at time: \", datetime.datetime.now())\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestRegressor(n_estimators=800, max_features=17, random_state=5, bootstrap=False, n_jobs=10)\n",
    "extraTree    = ExtraTreesRegressor(n_estimators=3000, max_features=23, random_state=5, bootstrap=False, n_jobs=4)\n",
    "adaBoost     = AdaBoostRegressor(n_estimators=600, learning_rate=0.01, loss='exponential', random_state=5)\n",
    "decTree      = DecisionTreeRegressor( splitter='best', max_depth=16, min_samples_split=20, \n",
    "                             min_samples_leaf=10, min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                             random_state=5, max_leaf_nodes=None, min_impurity_decrease=0.1, \n",
    "                             min_impurity_split=None, presort=False)\n",
    "bagging      = BaggingRegressor(n_estimators=600, max_samples=1.0, max_features=0.9, random_state=5, verbose=1)\n",
    "ridge        = Ridge(alpha=0.0001, normalize=True)\n",
    "knn          = KNeighborsRegressor(2)\n",
    "lasso        = Lasso(fit_intercept = True, random_state=5)\n",
    "enet         = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=5))\n",
    "xgboosting   = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.1, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=800,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "gboosting    = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 42)\n",
    "lightgbm     = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.01, n_estimators=60000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started benchmarking    GradientBoostingRegressor        at time:  2018-06-30 00:13:36.109671\n",
      "Done benchmarking       GradientBoostingRegressor        at time:  2018-06-30 00:16:03.506403\n"
     ]
    }
   ],
   "source": [
    "models = [gboosting0]\n",
    "\n",
    "for model in models:\n",
    "    benchmark(model, cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE</th>\n",
       "      <th>test_time</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>17.20314</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>2.447549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MAPE  test_time  train_time\n",
       "GradientBoostingRegressor  17.20314   0.009051    2.447549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(xgboosting.feature_importances_, X_train.columns.values)\n",
    "feature_importances.to_pickle('dataFrames/xgboost_feature_importances') \n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "#feature_importances = plt.plot()\n",
    "plt.figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveragingModels(models=(LGBMRegressor(bagging_fraction=0.95, bagging_freq=4, bagging_seed=20,\n",
       "       boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       feature_fraction=0.8, feature_fraction_seed=50, learning_rate=0.01,\n",
       "       max_bin=150, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weig...          presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "             warm_start=False)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_lgb_rfst = AveragingModels(models = (lightgbm0, randomForest, gboosting0))\n",
    "avg_lgb_rfst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = avg_lgb_rfst.predict(X_val)\n",
    "mape_func(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingRegressor(regressors=( lightgbm0, randomForest), \n",
    "                               meta_regressor=ridge )\n",
    "name = stack_gen.__class__.__name__\n",
    "t0 = time.time()\n",
    "stack_gen.fit(X_train.as_matrix(), y_train.as_matrix())\n",
    "res[name]['train_time'] = (time.time() - t0)/60\n",
    "t0 = time.time()\n",
    "pred = stack_gen.predict(X_val.as_matrix())\n",
    "res[name]['test_time'] = (time.time() - t0)/60\n",
    "res[name]['MAPE'] = mape_func(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stackgen results in higher scores. LGBM gives 17.42 and Gboost gives 17.2 yet Stackgen on these two base models with ridge as the meta-model gives 17.808!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = stack_gen.__class__.__name__\n",
    "res[name]['train_time'] =  50\n",
    "t0 = time.time()\n",
    "pred = stack_gen.predict(X_val.as_matrix())\n",
    "res[name]['test_time'] = (time.time() - t0)/60\n",
    "res[name]['MAPE'] = mape_func(y_val, pred)\n",
    "\n",
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df.to_pickle('dataFrames/benchmarking_results_stack_gen.pkl')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack_gen.__class__.__name__\n",
    "#stack_gen.fit(X_train.as_matrix(), y_train.as_matrix())\n",
    "#benchmark(stack_gen, cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked_averaged_models  = StackingAveragedModels(base_models = (xgboosting, randomForest), meta_model = ridge)\n",
    "stacked_averaged_models  = StackingAveragedModels(base_models = (lightgbm, extraTree), meta_model = ridge)\n",
    "stacking_regressor       = StackingRegressor(regressors=[xgboosting, randomForest], meta_regressor = ridge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_pickle('dataFrames/benchmarking_results.plk')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df.to_pickle('dataFrames/benchmarking_results2.plk')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lightgbm, xgboosting, enet, lasso, ridge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lgbm_xgb  = StackingAveragedModels(base_models = (lightgbm, xgboosting), meta_model = ridge)\n",
    "benchmark(avg_lgbm_xgb, name=\"Avg_LGBM_XGB\", cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_regressor       = StackingRegressor(regressors=[lightgbm, xgboosting], meta_regressor = ridge)\n",
    "benchmark(avg_lgbm_xgb, name=\"Stacking_LGBM_XGB\", cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lgbm_gboost  = StackingAveragedModels(base_models = (lightgbm, gboosting), meta_model = ridge)\n",
    "benchmark(avg_lgbm_gboost, name=\"Avg_LGBM_Gboost\", cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df.to_pickle('dataFrames/benchmarking_results2.pkl')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_pickle('dataFrames/benchmarking_results.plk')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally intensive \n",
    "#KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "#KRR.fit(X_train, y_train)\n",
    "#get_score(KRR,X_val,y_val)\n",
    "\n",
    "# score = 33.473933712491295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very computationally expensive\n",
    "#BAYSR = BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, \n",
    "#                      compute_score=True, fit_intercept=True, normalize=True)\n",
    "#BAYSR.fit(X_train, y_train)\n",
    "#get_score(BAYSR,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing stackingRegressor\n",
    "\n",
    "Look at the following link: https://www.kaggle.com/laurenstc/top-2-of-leaderboard-advanced-fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing another stacking method\n",
    "\n",
    "Look at the following link:\n",
    "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_plot(est, X_test, y_test, ax=None, label='', train_color='#2c7bb6', \n",
    "                  test_color='#d7191c', alpha=1.0, ylim=(0, 10)):\n",
    "    \"\"\"Deviance plot for ``est``, use ``X_val`` and ``y_val`` for test error. \"\"\"\n",
    "    n_estimators = len(est.estimators_)\n",
    "    test_dev = np.empty(n_estimators)\n",
    "\n",
    "    for i, pred in enumerate(est.staged_predict(X_test)):\n",
    "        test_dev[i] = est.loss_(y_test, pred)\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=FIGSIZE)\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.plot(np.arange(n_estimators) + 1, test_dev, color=test_color, label='Test %s' % label, \n",
    "             linewidth=2, alpha=alpha)\n",
    "    ax.plot(np.arange(n_estimators) + 1, est.train_score_, color=train_color, \n",
    "             label='Train %s' % label, linewidth=2, alpha=alpha)\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_xlabel('n_estimators')\n",
    "    ax.legend(loc='upper right')\n",
    "    #ax.set_ylim(ylim)\n",
    "    return test_dev, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_params(params):\n",
    "    return \", \".join(\"{0}={1}\".format(key, val) for key, val in params.items())\n",
    "\n",
    "#annotation_kw = {'xycoords': 'data', 'textcoords': 'data',\n",
    "#                 'arrowprops': {'arrowstyle': '->', 'connectionstyle': 'arc'}}\n",
    "\n",
    "\n",
    "\n",
    "FIGSIZE = (20, 10)\n",
    "fig = plt.figure(figsize=FIGSIZE)\n",
    "ax = plt.gca()\n",
    "for params, (test_color, train_color) in [({}, ('#d7191c', '#2c7bb6')),\n",
    "                                          ({'min_samples_leaf': 3}, ('#fdae61', '#abd9e9')),\n",
    "                                          ({'min_samples_leaf': 15}, ('#f12e61', '#12d9e9'))]:\n",
    "    est = GradientBoostingRegressor(n_estimators=200, max_depth=1, \n",
    "                                    learning_rate=1.0)\n",
    "#    est = GradientBoostingRegressor(n_estimators=1500, learning_rate=1.0,\n",
    "#                                     max_depth=10, max_features='sqrt',\n",
    "#                                     min_samples_split=10, loss='huber')\n",
    "    est.set_params(**params)\n",
    "    est.fit(X_train, y_train)\n",
    "    test_dev, ax = deviance_plot(est, X_val, y_val, ax=ax, label=fmt_params(params),\n",
    "                                 train_color=train_color, test_color=test_color)\n",
    "    \n",
    "#ax.annotate('Higher bias', xy=(100, est.train_score_[89]), xytext=(100, 3), **annotation_kw)\n",
    "#ax.annotate('Lower variance', xy=(100, test_dev[89]), xytext=(100, 3.5), **annotation_kw)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dev, ax = deviance_plot(est, X_val, y_val)\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(data=X_train, columns=feat_names)\n",
    "X_df['price_Val'] = y_train\n",
    "_ = X_df.hist(column=['source', 'destination', 'distanceKM', 'weight', \n",
    "                      'destinationLatitude', 'destinationLongitude', \n",
    "                      'sourceLatitude', 'sourceLongitude', 'taxiDurationMin'\n",
    "                     ], figsize=FIGSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_imp = pd.Series(est.feature_importances_, index=names)\n",
    "fx_imp /= fx_imp.max()  # normalize\n",
    "fx_imp.sort_values()\n",
    "fx_imp.plot(kind='barh', figsize=FIGSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['destination', 'source', 'weight', 'distanceKM', 'taxiDurationMin',\n",
    "            ('sourceLatitude', 'sourceLongitude')]\n",
    "fig, axs = plot_partial_dependence(est, X_train, features, feature_names=names, \n",
    "                                   n_cols=2, figsize=FIGSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostRegressor(iterations=5000,\n",
    "                             learning_rate=0.1,\n",
    "                             depth=15,\n",
    "                             eval_metric='MAPE',\n",
    "                             random_seed = 7,\n",
    "                             bagging_temperature = 1.4,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 100,\n",
    "                             \n",
    "                             use_best_model=True,\n",
    "                             od_wait=20)\n",
    "\n",
    "cb_model.fit(X_train, y_train, eval_set=(X_val, y_val),)\n",
    "pred = cb_model.predict(X_val)\n",
    "score = mape_func(y_val, pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(cb_model.feature_importances_, X_train.columns.values)\n",
    "feature_importances.to_pickle('dataFrames/catboost_feature_importances') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "#feature_importances = plt.plot()\n",
    "plt.figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store feature_importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(cb_model, cv= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(data=res).T\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cb_model.fit(X, y,\n",
    "             eval_set=(X_val, y_val),\n",
    "             use_best_model=True,\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostRegressor(rsm=0.8, depth=5, learning_rate=0.037, eval_metric='MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [cb_model]\n",
    "\n",
    "for model in models:\n",
    "    benchmark(model, cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(data=res).T\n",
    "#res_df.to_pickle('dataFrames/benchmarking_results2.pkl')\n",
    "res_df.sort_values('MAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in gbst1.staged_predict(X_train):\n",
    "    plt.plot(X_train.distanceKM, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_esimators = 200\n",
    "test_score = np.empty(len(gbst1.estimators_))\n",
    "for i, pred in enumerate(gbst1.staged_predict(X_val)):\n",
    "    test_score[i] = gbst1.loss_(y_val, pred)\n",
    "plt.plot(np.arange(n_esimators)+1, test_score, label='Val')\n",
    "plt.plot(np.arange(n_esimators)+1, gbst1.train_score_ , label='Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbst2 = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1,\n",
    "                                  max_depth=15, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbst2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in gbst2.staged_predict(X_train):\n",
    "    plt.plot(X_train.distanceKM, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_esimators = 200\n",
    "test_score = np.empty(len(gbst2.estimators_))\n",
    "for i, pred in enumerate(gbst2.staged_predict(X_val)):\n",
    "    test_score[i] = gbst2.loss_(y_val, pred)\n",
    "plt.plot(np.arange(n_esimators)+1, test_score, label='Val')\n",
    "plt.plot(np.arange(n_esimators)+1, gbst2.train_score_ , label='Train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(gbst1.feature_importances_, X_train.columns.values)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "#feature_importances = plt.plot()\n",
    "plt.figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "feature_importances.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train.as_matrix(), label=y_train.as_matrix())\n",
    "dval   = xgb.DMatrix(X_val.as_matrix(), label=y_val.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'colsample_bytree': 0.4603, 'gamma' : 0.0468, 'learning_rate' : 0.01, 'max_depth': 12, \n",
    "         'min_child_weight' : 1.7817, 'n_estimators': 1086, 'reg_alpha' : 0.9640,'reg_lambda' : 0.8571,\n",
    "         'subsample' : 1, 'silent': 1, 'random_state' :5 , 'nthread' : -1}\n",
    "\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "num_round = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPQEobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    grad = (2/(np.square(labels)))*(preds - labels)\n",
    "    hess = (2/(np.square(preds)))\n",
    "    grad = 2*(preds-labels)\n",
    "    hess = 2*np.ones(len(grad))\n",
    "    return grad , hess\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'error', np.sum(np.square(preds-labels)) \n",
    "\n",
    "bst  = xgb.train(param, dtrain , 1200, watchlist, obj = MAPQEobj, feval= mohsen_evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mohsen = 1 \n",
    "\n",
    "def mohsen_obj(preds, dtrain): \n",
    "    labels       = dtrain.get_label()\n",
    "    numb         = dtrain.num_row() \n",
    "    percent_diff = (preds-labels)/labels\n",
    "    grad         = percent_diff / ((numb)*(labels)*(np.sqrt(percent_diff**2 + c_mohsen)))\n",
    "    hess         = c_mohsen / ((numb)*(labels**2)*((percent_diff**2 + c_mohsen)**1.5))\n",
    "    return grad , hess\n",
    "\n",
    "def mohsen_evalerror(preds, dtrain):\n",
    "    labels       = dtrain.get_label()\n",
    "    percent_diff = (preds-labels)/labels\n",
    "    mohsen_error = np.mean(np.sqrt(percent_diff**2+c_mohsen))\n",
    "    return 'error', mohsen_error\n",
    "\n",
    "bst  = xgb.train(param, dtrain , 20, watchlist, obj = mohsen_obj, feval= mohsen_evalerror)\n",
    "\n",
    "#fftf = xgb.cv(param, dtrain)\n",
    "\n",
    "#benchmark(xgboosting2, name=\"XGB_Test\", cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0 - preds)\n",
    "    return grad, hess\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    # return a pair metric_name, result\n",
    "    # since preds are margin(before logistic transformation, cutoff at 0)\n",
    "    return 'error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
    "\n",
    "asbdjfn  = xgb.train(param, dtrain , 20, watchlist,   obj = mohsen_obj, feval= evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm0 = GradientBoostingRegressor(random_state=5, learning_rate=0.1,  min_samples_leaf = 1,  \n",
    "#                                 max_features = 'sqrt', n_estimators = 170, loss='huber')\n",
    "#param_test1 = {'min_samples_split':range(200,1001,200),\n",
    "#              'max_depth':range(40,70,10)}\n",
    "#gsearch1 = GridSearchCV(estimator = gbm0, param_grid = param_test1, cv = 2)\n",
    "#modelfit(gbm0, X_train, y_train , X_val, y_val, printFeatureImportance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "clf_lasso = GridSearchCV(lasso, {'alpha': [1e-3,1e-2,1e-1,1,1e1,1e2,1e3]}, verbose=1)\n",
    "clf_lasso.fit(X_train,y_train)\n",
    "print(clf_lasso.best_params_)\n",
    "get_score(clf_lasso,X_val,y_val)\n",
    "# {'alpha': 100.0}\n",
    "# 40.78453998923231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statsmodel_regression = sm.OLS(y_train, X_train).fit()\n",
    "#statsmodel_regression.summary()\n",
    "# Never try OLS again -----> Super computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "xgb1 = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=18000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "\n",
    "xgb1.fit(X_train, y_train, early_stopping_rounds=5, \n",
    "         eval_set=[(X_val[X_train.columns.tolist()],  y_val)], verbose=True)\n",
    "\n",
    "r = xgb1.predict(X_val[X_train.columns.tolist()])\n",
    "score = mean_absolute_precision_error(r, y_val)\n",
    "print( '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBF = lgb.LGBMRegressor(objective='regression',num_leaves=25, save_binary = True,  \n",
    "                          learning_rate=0.005, n_estimators=120000,\n",
    "                          max_bin = 150, bagging_fraction = 0.95,\n",
    "                          bagging_freq = 4, feature_fraction = 0.8,\n",
    "                          feature_fraction_seed=50, bagging_seed=20,\n",
    "                          min_data_in_leaf = 11, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "GBSTF = GradientBoostingRegressor(n_estimators=15000, learning_rate=0.01,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state = 42)\n",
    "\n",
    "XGBF = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                        learning_rate=0.01, max_depth=12, \n",
    "                        min_child_weight=1.7817, n_estimators=8000,\n",
    "                        reg_alpha=0.9640, reg_lambda=0.8571,\n",
    "                        subsample=1, silent=1,\n",
    "                        random_state =5 , nthread = -1)\n",
    "\n",
    "BAGF  = BaggingRegressor(n_estimators=600, max_samples=1.0, max_features=0.9, random_state=5, verbose=1)\n",
    "\n",
    "DECF  = DecisionTreeRegressor(max_depth=15)\n",
    "\n",
    "RFSTF = RandomForestRegressor(n_estimators=100, criterion='mae', bootstrap=False,\n",
    "                              max_depth=4, max_features=5,#'sqrt',\n",
    "                              min_samples_leaf=5, min_samples_split =3, random_state = 42)\n",
    "\n",
    "KNNF  = KNeighborsClassifier(2)\n",
    "LASSF = Lasso(fit_intercept = True)\n",
    "ABSTF = AdaBoostRegressor(n_estimators=1, learning_rate=0.01, loss='linear', random_state=5)\n",
    "\n",
    "SVRF = SVR()\n",
    "RDGF = Ridge()\n",
    "ENTF = make_pipeline(RobustScaler(), ElasticNet(alpha=0.8, l1_ratio=.9, random_state=3))\n",
    "\n",
    "models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF, \"dec_tree\": DECF, \"Random_forest\": RFSTF,\n",
    "          \"knn\": KNNF, \"elasticNet\": ENTF, \"ridge\": RDGF, \"lasso\": LASSF, \"AdaBoost\": ABSTF, \"SVR\": SVRF}\n",
    "\n",
    "#models = { \"Gboost\": GBSTF, \"xgb\": XGBF, \"bagging\": BAGF, \"lgbm\": LGBF}\n",
    " \n",
    "#models = {\"lgb0\": lgb0, \"xgb0\": xgb0, \"gbstf0\": gbstf0}\n",
    "\n",
    "#models ={ \"bag0\": bag0}\n",
    "\n",
    "#models = {\"RFSTF\": RFSTF}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    start_time = time.time()\n",
    "    print(datetime.datetime.now())\n",
    "    model.fit(X_train, y_train)\n",
    "    train_cols = X_train.columns.tolist()\n",
    "    X_val['y_' + model_name] = model.predict(X_val[train_cols])\n",
    "    score = mape_func(y_val, X_val['y_' + model_name])\n",
    "    print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "\n",
    "#X_val.to_pickle('dataFrames/One_Hot_X_val.pkl')\n",
    "\n",
    "# Correct outputs are as followed\n",
    "\n",
    "#Gboost        23.55 mins, score=  16.76\n",
    "#xgb           25.40 mins, score=  17.36\n",
    "#bagging       7.83  mins, score=  18.61\n",
    "#lgbm          12.65 mins, score=  17.28\n",
    "#dec_tree      4.95  mins, score=  21.45\n",
    "#Random_forest 5.56  mins, score=  39.04\n",
    "#knn           0.02  mins, score=  24.62\n",
    "#elasticNet    0.01  mins, score=  34.81\n",
    "#ridge         0.00  mins, score=  36.68\n",
    "#lasso         0.10  mins, score=  36.63\n",
    "#AdaBoost      0.00  mins, score=  38.60\n",
    "#SVR           2.94  mins, score=  72.61\n",
    "# KernelRidge and LinearRegression() take more than 1 hour to run! Don't Run them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mape_func(y_val, X_val['y_' + model_name])\n",
    "print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = X_train.columns.tolist()\n",
    "X_val['y_avg_boost'] = gbstf0.predict(X_val[train_cols])\n",
    "score = mean_absolute_precision_error(X_val['y_avg_boost'], y_val)\n",
    "print(model_name, '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['y_gbstf0'] =  gbstf0.predict(X_val[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_e = (X_val['y_lgb0'] + X_val['y_xgb0'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h = ( X_val['y_xgb0'] * X_val['y_gbstf0'])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_absolute_precision_error(X_h, y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_pickle('dataFrames/One_Hot_X_val_new.pkl')\n",
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm', 'y_dec_tree', 'y_Random_forest', 'y_knn',\n",
    "             'y_elasticNet', 'y_ridge', 'y_lasso', 'y_AdaBoost', 'y_SVR']\n",
    "\n",
    "best_cols = ['y_Gboost', 'y_xgb', 'y_bagging', 'y_lgbm']\n",
    "best_pred = X_val[list(best_cols)]\n",
    "best_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pred_cols:\n",
    "    plt.scatter(X_val[col],y_val)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel(col)\n",
    "    plt.title('Prediction vs Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [lgb0, xgb0]\n",
    "stregr     = StackingRegressor(regressors=regressors, meta_regressor=gbstf0)\n",
    "start_time = time.time()\n",
    "stregr.fit(X_train, y_train)\n",
    "y_pred = stregr.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stackingRegressor model\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score= \", '%.2f' % score)\n",
    "# stackingRegressor model 43.59 mins, score=  18.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=3):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                #instance.fit(X[train_index], y[train_index])\n",
    "                instance.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "                y_pred = instance.predict(X.iloc[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() \n",
    "stacked_averaged_models  = StackingAveragedModels(base_models = (lgb0, xgb0), meta_model = gbstf0)\n",
    "stacked_averaged_models.fit(X_train, y_train)\n",
    "y_pred = stacked_averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"stacking Averaged models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# stacking Averaged models 79.53 mins, score = 17.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "averaged_models = AveragingModels(models = (xgb0, lgb0))\n",
    "averaged_models.fit(X_train, y_train)\n",
    "train_cols = X_train.columns.tolist()\n",
    "y_pred = averaged_models.predict(X_val[train_cols])\n",
    "score  = mean_absolute_precision_error(y_pred, y_val)\n",
    "print(\"Average models\", '%.2f' % float((time.time() - start_time)/60 ) +\" mins, score =\", '%.2f' % score)\n",
    "# Average models 30.67 mins, score=  17.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current best model \n",
    "start_time = time.time()\n",
    "GBST = GradientBoostingRegressor(n_estimators=3200, learning_rate=0.05,\n",
    "                                  max_depth=10, max_features='sqrt',\n",
    "                                  min_samples_leaf=15, min_samples_split=10, \n",
    "                                  loss='huber', random_state =5)\n",
    "\n",
    "GBST.fit(train.drop(['ID','price'],axis=1), train.price)\n",
    "y_pred_test = GBST.predict(test.drop(['ID','price'],axis=1))\n",
    "\n",
    "print('%.2f' % float((time.time() - start_time)/60 ) +\" mins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/mohsenkiskani/Downloads/Ubaar/submissions/submission32.csv\"\n",
    "with open(filename,\"w+\") as outputfile:\n",
    "    outputfile.write(\"ID,price\\n\")\n",
    "    for i in range(y_pred_test.shape[0]):\n",
    "        outputfile.write(str(test_data.ID[i])+\",\"+str(int(np.ceil(y_pred_test[i])))+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
